Understand the use caseCloudera Docs
Understand the use case
As a basic analytical use case, you can use Streaming Analytics clusters connected to
  the Streams Messaging cluster to build an end-to-end streaming analytics application with Kafka as
  source and sink.
When choosing Kafka as a connector for a Flink application, you can create a scalable
   communication channel. Kafka, as a source and sink, is responsible for delivering input records
   to Flink, and receiving the transformed data from Flink.
This use case details the steps to connect a Streaming Analytics cluster with a Streams
   Messaging cluster, and to submit your Flink jobs and monitor the correct behaviour of your
   application in the Data Hub environment. The Stateful Flink Application Tutorial is used as an
   example to guide you through the basic steps to analyze your data with Kafka in CPD Public
   Cloud.
The Stateful Flink Application Tutorial details an inventory use case for an e-commerce site.
   The business logic in the application includes handling transactions and managing queries that
   are later summarized to monitor the state of the inventory. noteIn the Analyzing data with
    Kafka use case, the steps that are used from the Stateful Flink Application Tutorial are
    highlighted in grey. These steps are not mandatory to use Streaming Analytics in Data Hub, but
    serves as an example for practice.For more information about the tutorial, see the
      Stateful Flink Application Tutorial.

Related informationStateful Flink Application TutorialParent topic: Analyzing your data with Kafka