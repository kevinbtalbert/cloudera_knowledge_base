Migrating Flink jobsCloudera Docs
Migrating Flink jobs
After upgrading the version of the Data Lake in your CDP Public Cloud environment, you
  need to create Data Hub clusters using the Streaming Analytics cluster template that corresponds
  to the new version of the Data Lake. To restart your existing Flink jobs on the upgraded Data Hub
  clusters, you need to migrate your Flink jobs. The migration process depends on the state of the
  Flink jobs.
After creating a new Data Hub cluster using the latest Streaming Analytics cluster template,
   you need to migrate your Flink jobs to the new cluster. The process of migration depends on the
   state of your Flink jobs: if you have stateful jobs, you need to stop your Flink applications
   with creating savepoints. Before starting the job migration, make sure that the job dependies are
   updated based on the latest version of Flink in CDP Public Cloud.

Migrating Flink jobs without stateWhen you run Flink application without state, you only need to stop your currently         running Flink jobs, and restart them on your upgraded Data Hub clusters.Migrating stateful Flink jobsWhen you run Flink application with state, you must stop the Flink jobs with a         savepoint, so you can restart them from the exact point on your upgraded Data Hub clusters.         Based on the version of your original cluster, you can provide the savepoint path either in         HDFS or S3.Updating Flink job dependenciesWhen you migrate your Flink jobs to a cluster that has a new supported version of         Flink, the applications need to use a new version of the artifacts provided by the Flink         deployment in your cluster. To avoid incompabilities between the packaged artifacts of your         application and the artifacts provided by the Flink cluster, ensure that the POM file of the         application is updated to match the Flink version of the new Data Hub cluster.