HBase sink with FlinkCloudera Docs
HBase sink with Flink
Cloudera Streaming Analytics offers HBase connector as a sink. Like this you can store
    the output of a real-time processing application in HBase. You must develop your application
    defining HBase as sink and add HBase dependency to your project.
The HBase Streaming connector has the following key features:
Automatic configuration on the  platform
High throughput buffered operations
Customizable data-driven update/delete logic

To use the HBase integration, add the following dependency to your
   project:<dependency>
  <groupId>org.apache.flink</groupId>
  <artifactId>flink-hbase_${scala.binary.version}</artifactId>
  <version>${flink.version}</version>
</dependency>
The general purpose HBase sink connector is implemented in the
        org.apache.flink.addons.hbase.HBaseSinkFunction class.
This is an abstract class that must be extended to define the interaction logic (mutations)
      with HBase. By using the BufferedMutator instance, you can implement
      arbitrary data driven interactions with HBase. While it is possible to run all mutations
      supported by the BufferedMutator interface, Cloudera strongly recommends that
      users should only use idempotent mutations: Put and Delete.

Creating and configuring the HBaseSinkFunctionYou must configure the HBaseSinkFunction with Table names to have HBase as a sink. The     HBase table needs to be created before the streaming job is submitted. You should also configure     the operation buffering parameters to make sure that every data coming from Flink is buffered     into HBase.Parent topic: DataStream connectors