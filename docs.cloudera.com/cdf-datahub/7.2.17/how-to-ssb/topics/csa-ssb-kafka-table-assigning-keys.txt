Assigning Kafka keys in streaming queriesCloudera Docs
Assigning Kafka keys in streaming queries
Based on the Sticky Partitioning strategy of Kafka, when null keyed events are sent to a
    topic, they are randomly distributed in smaller batches within the partitions.
As the results of the SQL Stream queries by default do not include a key, when written to a
      Kafka table, the Sticky Partitioning strategy is used. In many cases, it is useful to have
      more fine-grained control over how events are distributed within the partitions. You can
      achieve this in SSB by configuring a custom key based on your specific workload.
For
   example:SELECT sensor_name AS _eventKey --sensor_name becomes the key in the output kafka topic
FROM sensors
WHERE eventTimestamp > current_timestamp;
To configure keys in DDL-defined tables (those that are configured using the
    Templates), refer to the official Flink Kafka SQL Connector documentation for more
   information (specifically the key.format and key.fields options).

Parent topic: Configuring Kafka tables