Use Schema RegistryCloudera Docs
Use Schema Registry
You can use a sample Kafka client application written in Java, to produce data to and
  consume data from Kafka topics using schemas stored in the Schema Registry.

Schema Registry provides a shared repository of schemas that allows applications to flexibly
    interact with each other. Applications frequently need a way to share metadata across data
    format, schema, and semantics. Schema Registry addresses these challenges by evolving schemas
    such that a producer and consumer can understand different versions of the schemas but still
    read all information shared between both versions and safely ignore the rest.
For more information on the topics covered in this section,  check the following Cloudera
    online documentation resources:


Connecting Kafka clients to Data Hub provisioned clusters


Schema Registry


Developing Apache Kafka applications


note
In this section, you build a sample Java application. To do this you must have the following
     installed on your local computer:
Java 8 SDK (or later)
Maven
Git




Related informationConnecting Kafka clients to Data Hub provisioned clustersSchema RegistryDeveloping Apache Kafka applicationsGather configuration informationTo produce data to and consume data from Kafka topics using schemas stored in the Schema   Registry, you need to collect some configuration information such as the list of brokers and   Schema Registry endpoint. You must also create TLS truststore.Defining Schema Registry access policiesYou must grant your application certain privileges to use the Schema Registry by         creating the appropriate policies in Ranger. Learn how to define access policies and         permissions for using Schema Registry.Producing data in Avro formatYou can run the sample producer application to produce data to a Kafka topic in Avro         format. You can send data to a Kafka topic in Avro format. Learn how to store a schema in         CDPÊ¼s Schema Registry and   use a simple Java Kafka client to send and read data using that         schema.Checking schema registrationWhen the KafkaAvroSerializer is used to produce data to a Kafka         topic, the serializer first checks with the configured Schema Registry service to ensure         that the schema is compatible with the one registered for that Kafka topic. You can view the         registered schema and its the versions in the Schema Registry web UI.Checking producer activityYou can also use Streams Messaging Manager (SMM) to check the activity generated by         the producer on the Kafka cluster. Learn how to check the producer activity in SMM after you         send data to a Kafka topic in Avro format.Consuming data from Kafka topics using stored schemasYou can consume data from the machine-data-avro topic where you have         produced data in Avro format. You need to create a copy of the consumer properties template         file, replace the values of some properties in that file, and run the consumer         application.