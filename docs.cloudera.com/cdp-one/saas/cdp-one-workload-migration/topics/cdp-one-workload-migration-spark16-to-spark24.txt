Spark 1.6 to Spark 2.4 RefactoringCloudera Docs
Spark 1.6 to Spark 2.4 Refactoring
Because Spark 1.6 is not supported on CDP, you need to refactor Spark workloads from
        Spark 1.6 on CDH or HDP to Spark 2.4 on CDP. 
 This document helps in accelerating the migration process, provides guidance to refactor
            Spark workloads and lists migration. Use this document when the platform is migrated
            from CDH or HDP to CDP.

Handling prerequisitesYou must perform a number of tasks before refactoring workloads.Spark 1.6 to Spark 2.4 changesA description of the change, the type of change, and the     required refactoring provide the information you need for migrating from Spark 1.6 to Spark 2.4. Configuring storage locations To execute the workloads in CDP One, you must modify the references to storage locations.          In CDP, references must be changed from HDFS to a cloud object store such as S3.Querying Hive managed tables from SparkHive-on-Spark is not supported on CDP One. You need to use the Hive Warehouse   Connector (HWC) to query Apache Hive managed tables from Apache Spark. Compiling and running Spark workloadsAfter modifying the workloads, compile and run (or dry run) the refactored workloads on   Spark 2.4.Post-migration tasksAfter the workloads are executed on Spark 2.4, validate the output, and compare the         performance of the jobs with CDH/HDP cluster executions.     Parent topic: Migrating Spark workloads to CDP