HiveServer metadata collectionCloudera Docs
HiveServer metadata collection
Atlas can collect metadata from HiveServer, including queries
    and the data assets the queries affect.
An Atlas hook runs in each HiveServer instance. This hook sends
      metadata to Atlas for both Hive operations and Hive data assets.
      Operations are represented by process and process execution entities in Atlas. 
      Hive databases, tables, views, and columns are represented by entities in Atlas. When a 
      Hive operation involves files, the metadata for the file system and files are represented in 
      Atlas as file system paths.


When an action occurs in the HiveServer instance...
The corresponding Atlas hook collects information for the action into
        metadata entities.
The hook publishes the metadata on a Kafka topic.
Atlas reads the message from the topic and determines what information
        will create new entities and what information updates existing
        entities.
Atlas creates and updates the appropriate entities and determines
        lineage from existing entities to the new entities.

The Atlas bridge for HBase pulls the same metadata as the hook, but
      instead of sending the metadata through Kafka, it passes message in bulk
      in an API call. The bridge creates entities in Atlas for all of the existing HBase namespaces, 
      tables, columns, and column families.

HiveServer actions that produce Atlas entitiesOperations that create, update, or delete Hive metadata will affect   Atlas entities; operations that only affect data do not show up in Atlas.HiveServer entities created in AtlasEach HiveServer entity in Atlas includes detailed metadata     collected from Hive.HiveServer relationshipsAtlas shows the entities related to this entity in the     Relationships tab in the Dashboard.HiveServer lineageAtlas collects metadata from HiveServer to represent the lineage     among data assets.HiveServer audit entriesAtlas lists changes to metadata entities in the Audit tab in the     Dashboard.