Accessing ORC Data in Hive TablesCloudera Docs
Accessing ORC Data in Hive Tables
Apache Spark in CDP supports the Optimized Row Columnar (ORC) file
    format, a self-describing, type-aware, column-based file format that is one
    of the primary file formats supported in Apache Hive. 

ORC reduces I/O overhead by accessing only the columns that are required for the current
            query. It requires significantly fewer seek operations because all columns within a
            single group of row data (known as a "stripe") are stored together on disk.
Spark ORC data source supports ACID transactions, snapshot isolation, built-in indexes,
            and complex data types (such as array, map, and struct), and provides read and write
            access to ORC files. It leverages the Spark SQL Catalyst engine for common optimizations
            such as column pruning, predicate push-down, and partition pruning.
This subsection has several examples of Spark ORC integration, showing how ORC
            optimizations are applied to user programs.


Related informationORC File FormatApache Hive ACID TransactionsAccessing ORC files from SparkUse the following steps to access ORC files from Apache Spark. Predicate push-down optimizationLoading ORC data into DataFrames using predicate push-downOptimizing queries using partition pruningEnabling vectorized query executionReading Hive ORC tables