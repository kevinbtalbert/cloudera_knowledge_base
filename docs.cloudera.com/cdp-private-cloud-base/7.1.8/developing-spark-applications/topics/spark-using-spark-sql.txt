Using Spark SQLCloudera Docs
Using Spark SQL
This section provides information about using Spark SQL. 
Using SQLContext, Apache Spark SQL can read data directly from the file system. This is
        useful when the data you are trying to analyze does not reside in Apache Hive (for example,
        JSON files stored in HDFS).
Using HiveContext, Spark SQL can also read data by interacting with the
        Hive MetaStore. If you already use Hive, you should use HiveContext; it
        supports all Hive data formats and user-defined functions (UDFs), and it
        enables you to have full access to the Hive parser. HiveContext extends
        SQLContext, so HiveContext supports all SQLContext functionality.
There are two ways to interact with Spark SQL:


Interactive access using the Spark shell (see "Accessing Spark SQL through the Spark
            Shell" in this guide).


From an application, operating through one of the following two APIs and the
            HiveServer2:


JDBC, using your own Java code or the Beeline JDBC client


ODBC, through the Simba ODBC driver




The following diagram illustrates the access process, depending on whether you are using
        the Spark shell or business intelligence (BI) application:



The following subsections describe how to access Spark SQL through the Spark shell, and
        through JDBC and ODBC.

Related informationBeeline Command Line ShellSQLContext and HiveContext Beginning in Spark 2.0, all Spark functionality, including Spark     SQL, can be accessed through the SparkSessions class,     available as spark when you launch       spark-shell. You can create a DataFrame from an RDD, a     Hive table, or a data source. Querying files into a DataFrameIf you have data files that are outside of a Hive or Impala table,     you can use SQL to directly read JSON or Parquet files into a     DataFrame.Spark SQL exampleInteracting with Hive viewsPerformance and storage considerations for Spark SQL DROP TABLE PURGETIMESTAMP compatibility for Parquet filesAccessing Spark SQL through the Spark shellUse the following steps to access Spark SQL using the Spark shell. 