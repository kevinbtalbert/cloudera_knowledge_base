Sizing NameNode heap memoryCloudera Docs
Sizing NameNode heap memory
Each workload has a unique byte-distribution profile. Some workloads can use the
    default JVM settings for heap memory and garbage collection, but others require tuning. You can
    size your NameNode JVM if the dynamic heap settings cause a bottleneck.
All Hadoop processes run on a Java Virtual Machine (JVM). Each daemon runs on its own JVM
      across a cluster of hosts.
The legacy NameNode configuration is one active (and primary) NameNode for the entire
      namespace and one Secondary NameNode for checkpoints (but not failover). The recommended
      high-availability configuration replaces the Secondary NameNode with a standby NameNode that
      prevents a single point of failure. Each NameNode uses its own JVM.
noteFor optimal performance, a maximum of 300 million files on the
      NameNode is recommended.

Environment variables for sizing NameNode heap memoryYou can configure the values of HADOOP_HEAPSIZE and       HADOOP_NAMENODE_OPTS to size the NameNode heap memory.Monitoring heap memory usageYou can use several ways to monitor the heap memory usage: Cloudera Manager, NameNode     web UI, or the command line.Files and directoriesPersistence of HDFS metadata is implemented using fsimage file and edits files.Disk space versus namespaceThe HDFS default block size (dfs.blocksize) is set to 128 MB. Each     namespace object on the NameNode consumes approximately 150 bytes. ReplicationThe default block replication factor (dfs.replication) is three.       Replication affects disk space but not memory consumption. Examples of estimating NameNode heap memoryYou can estimate the heap memory by consider either the number of file inodes and     blocks, or the cluster capacity.Parent topic: NameNodes