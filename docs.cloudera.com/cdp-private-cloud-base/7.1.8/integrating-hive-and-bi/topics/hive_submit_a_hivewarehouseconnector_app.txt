Submitting a Scala or Java applicationCloudera Docs
Submitting a Scala or Java application
A step-by-step procedure shows you how to submit an app based on the
        HiveWarehouseConnector library to run on Apache Spark Shell.

Choose a mode, for example JDBC, for your application.

Check that you meet the prerequisites for using JDBC read mode and make the
                    HiveServer (HS2) connection as described for using the JDBC read mode.

Locate the hive-warehouse-connector-assembly jar in the
                        /hive_warehouse_connector/ directory.
For example, find
                        hive-warehouse-connector-assembly-<version>.jar in
                    the following
                    location:/opt/cloudera/parcels/CDH/jars  

Add the connector jar and configurations to the app submission using the
                        --jars option.
Example
                    syntax:spark-shell --jars <path to jars>/hive_warehouse_connector/hive-warehouse-connector-assembly-<version>.jar \
--conf <configuration properties>


Add the path to app you wrote based on the HiveWarehouseConnector API.
Example syntax:  <path to app>  For example:
                    spark-shell --jars /opt/cloudera/parcels/CDH/jars/hive-warehouse-connector-assembly-<version>.jar \
--conf spark.sql.extensions=com.hortonworks.spark.sql.rule.Extensions \
--conf spark.datasource.hive.warehouse.read.mode=JDBC_CLUSTER \
--conf "spark.hadoop.hive.metastore.uris=thrift://172.27.74.137:9083" \
--conf spark.datasource.hive.warehouse.load.staging.dir=<path to directory> \
/home/myapps/myapp.jar                        


Related informationUsing Direct Reader modeUsing JDBC read modeHMS storageParent topic: Introduction to HWC and DataFrame APIs