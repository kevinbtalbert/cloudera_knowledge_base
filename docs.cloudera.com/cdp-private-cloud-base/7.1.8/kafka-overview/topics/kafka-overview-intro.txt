Kafka IntroductionCloudera Docs
Kafka Introduction

Apache Kafka is a high performance, highly available, and redundant streaming message
      platform.
Kafka functions much like a publish/subscribe messaging system, but with better throughput,
      built-in partitioning, replication, and fault tolerance. Kafka is a good solution for large
      scale message processing applications. It is often used in tandem with Apache Hadoop, and
      Spark Streaming.
You might think of a log as a time-sorted file or data table. Newer entries are appended to
      the log over time, from left to right. The log entry number is a convenient replacement for a
      timestamp.
Kafka integrates this unique abstraction with traditional publish/subscribe messaging
      concepts (such as producers, consumers, and brokers), parallelism, and enterprise features for
      improved performance and fault tolerance.
The original use case for Kafka was to track user behavior on websites. Site activity (page
      views, searches, or other actions users might take) is published to central topics, with one
      topic per activity type.
Kafka can be used to monitor operational data, aggregating statistics from distributed
      applications to produce centralized data feeds. It also works well for log aggregation, with
      low latency and convenient support for multiple data sources.
Kafka provides the following:

Persistent messaging with O(1) disk structures, meaning that the execution time of Kafka's
        algorithms is independent of the size of the input. Execution time is constant, even with
        terabytes of stored messages.
High throughput, supporting hundreds of thousands of messages per second, even with modest
        hardware.
Explicit support for partitioning messages over Kafka servers. It distributes consumption
        over a cluster of consumer machines while maintaining the order of the message stream.
Support for parallel data load into Hadoop.


