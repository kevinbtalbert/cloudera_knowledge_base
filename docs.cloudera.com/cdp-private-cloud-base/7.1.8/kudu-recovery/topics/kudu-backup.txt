Kudu backupCloudera Docs
Kudu backup
Kudu supports both full and incremental table backups through a job implemented using
  Apache Spark. 
Kudu backup and restore jobs use Apache Spark. Therefore, ensure that you install Apache Spark
   in your environment. To download Apache Spark, see the Apache Spark documentation.
   You can also review the Submitting Spark applications topics.

Related informationSubmitting Spark applicationsBack up tablesYou can use the KuduBackup Spark job to backup one or more Kudu     tables.gBackup toolsAn additional kudu-backup-tools JAR is available to provide some backup     exploration and garbage collection capabilities. This jar does not use Spark directly, but     instead only requires the Hadoop classpath to run.Generate a table listTo generate a list of tables to backup using the kudu table list tool   along with grep can be useful.Backup directory structureThe backup directory structure in the rootPath is considered an   internal detail and could change in future versions of Kudu. Additionally, the format and content   of the data and metadata files is meant for the backup and restore process only and could change   in future versions of Kudu. That said, understanding the structure of the backup    rootPath and how it is used can be useful when working with Kudu   backups.Physical backups of an entire nodeKudu does not provide a built-in physical backup and restore functionality yet.         However, it is possible to create a physical backup of a Kudu node (either tablet server or         master) and restore it later.