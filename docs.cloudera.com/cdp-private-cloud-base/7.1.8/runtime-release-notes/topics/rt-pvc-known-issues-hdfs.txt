Known Issues in HDFSCloudera Docs
Known Issues in HDFS
Learn about the known issues in HDFS, the impact or changes to the functionality, and
        the workaround.


OPSAPS-60958: The dfs.access.time.precision and dfs.namenode.accesstime.precision parameters are available in Cloudera Manager > HDFS > Configuration.
You must configure both the
                    dfs.access.time.precision and
                    dfs.namenode.accesstime.precision parameters with the
                    same value as Cloudera Manager still sends both the parameters to HDFS service
                    configuration.


ENGESC-19334: After configuring multiple NameNodes, with
                    heavy read and write workloads in the cluster, there are chances of performance
                    impact in terms of slowness on the client side.
This is because of the additional NN retry or probe introduced by the extra NN.
There are two solutions to mitigate the performance
                    impact: 
By reducing the value of the property:
                                    dfs.client.failover.sleep.base.millis //
                                default is 500ms.
By increasing the value of the property
                                    dfs.client.failover.max.attempts // default
                                is 15.
 or 
Using
                                    org.apache.hadoop.hdfs.server.namenode.ha.RequestHedgingProxyProvider
                                instead of
                                    org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
                                in HDFS client failover proxy provider (defined in
                                    dfs.client.failover.proxy.provider).



OPSAPS-64307: 
                    In the case when on a cluster the JournalNodes were restarted recently, the "Add new NameNode" wizard for HDFS service might fail to bootstrap the new NameNode, if there wasn't a new fsImage created since the restart of the JournalNodes, but during restarting them the edit logs were rolled in the system.
If the bootstrap fails during the "Add new NameNode" wizard, then do the following steps:
                
Delete the newly added NameNode and FailoverController
Move the active HDFS NameNode to safe mode
Do a Save Namespace operation on the active HDFS NameNode
Leave safe mode on the active HDFS NameNode
Try to add the new NameNode again

noteNote that entering safe mode will disable writes to HDFS with that it causes a service disruption. If you can not afford to enter safe mode, just delete the newly added NameNode and FailoverController in the HDFS service, and wait until HDFS automatically creates a new fsImage, and try adding the new NameNode again with the wizard.



OPSAPS-64363: Deleting of additional Standby Namenode does not delete the ZKFC role and this has to be done manually.
None


OPSAPS-63558: Snapshot diff based HDFS replications do not provide correct file delete and rename counters through the API.
The number of files deleted and renamed by DistCp for snapshot based replications can be checked in the logs provided by DistCp on the standard error output.


CDPD-28459: After performing an upgrade rollback from CDP
                    7.1.7 to CDH6, you may see the following error when restarting the DataNodes:
                    ERROR datanode.DataNode: Exception in secureMain java.io.IOException: The path
                    component: '/var/run/hdfs-sockets' in '/var/run/hdfs-sockets/dn' has permissions
                    0755 uid 39998 and gid 1006. It is not protected because it is owned by a user
                    who is not root and not the effective user: '0'.
You must run the command described in the error
                    message "chown root /var/run/hdfs-sockets". After this, the DataNode will
                    restart successfully.


CDPD-28390: Rolling restart of the HDFS JournalNodes may time out on Ubuntu20.
If the restart operation times out, you can manually stop and restart the Name Node and Journal Node services one by one.


OPSAPS-60832: When decommission of DN runs for a longer time and when decommission monitor's kerberos ticket expires, it is not auto-renewed.
                    Decommission of DN is not completed in CM as decommission monitor fails to fetch the state of DN after kerberos ticket expiry.
Decommission state of DN can be fetched using CLI command, i.e, hdfs dfsadmin -report.


OPSAPS-55788: WebHDFS is always enabled. The Enable WebHDFS checkbox
                    does not take effect.
None.


OPSAPS-63299: Disable HA command for a nameservice does
                    not work if the nameservice has more than 2 NNs defined.
None


OPSAPS-63301: Deleting nameservice command does not delete
                    all the NNs belonging to the nameservice, if there are more than two NNs that
                    are assigned to the nameservice.
None


CDPD-50044: Data node tab loading issue in the name node UI
When clicking on the data node tab, the message NameNode is still
                        loading. Redirecting to the Startup Progress page appears.
None

Unsupported Features

The following HDFS features are currently not supported in Cloudera Data
                            Platform:
ACLs for the NFS gateway (HADOOP-11004)
Aliyun Cloud Connector (HADOOP-12756)
Allow HDFS block replicas to be provided by an external storage system (HDFS-9806)
Consistent standby Serving reads (HDFS-12943)
Cost-Based RPC FairCallQueue (HDFS-14403)
HDFS Router Based Federation (HDFS-10467)
NameNode Federation (HDFS-1052)
NameNode Port-based Selective Encryption (HDFS-13541)
Non-Volatile Storage Class Memory (SCM) in HDFS Cache Directives
                                    (HDFS-13762)
OpenStack Swift (HADOOP-8545)
SFTP FileSystem (HADOOP-5732)
Storage policy satisfier (HDFS-10285)




Parent topic: Known issues in Cloudera Runtime 7.1.8