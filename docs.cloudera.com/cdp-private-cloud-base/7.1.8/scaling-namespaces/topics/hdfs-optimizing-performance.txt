Optimizing performanceCloudera Docs
Optimizing
      performance
You can consider the following options to optimize the performance of an HDFS
         cluster: swapping disk drives on a DataNode, caching data, specifying racks for hosts,
         customizing HDFS, optimizing NameNode disk space with Hadoop archives, identifying slow
         DataNodes and improving them, optimizing small write operations by using DataNode memory as
         storage, and implementing short-circuit reads. 
Improving performance with centralized cache managementCentralized cache management enables you to specify paths to directories that are             cached by HDFS, thereby improving performance for applications that repeatedly access             the same data.Specifying racks for hostsHDFS uses the network location of your deployment, such as hosts and racks, to place         block replicas more intelligently and trade off performance and resilience. When placing         jobs on hosts, CDP prefers within-rack transfers, where there is more bandwidth available,         to off-rack transfers. These computations are performed with the assistance of rack         awareness scripts. Cloudera Manager includes internal rack awareness scripts, but you must         specify the racks where the hosts in your cluster are located.Customizing HDFSYou can use the dfs.user.home.base.dir property to customize the         HDFS home directory. In addition, you can configure properties to control the size of the         directory that holds the NameNode edits directory.Optimizing NameNode disk space with Hadoop archivesHadoop Archives (HAR) are special format archives that efficiently pack small files             into HDFS blocks.Detecting slow DataNodesSlow DataNodes in a CDP Private Cloud Base cluster can negatively impact the cluster       performance. Therefore, HDFS provides a mechanism to detect and report slow DataNodes that       have a negative impact on the performance of the cluster.Allocating DataNode memory as storageHDFS supports efficient writes of large data sets to durable storage, and also             provides reliable access to the data. This works well for batch jobs that write large             amounts of persistent data. Emerging classes of applications are driving use cases for             writing smaller amounts of temporary data. Using DataNode memory as storage addresses             the use case of applications that want to write relatively small amounts of intermediate             data sets with low latency.Improving performance with short-circuit local readsIn HDFS, reads normally go through the DataNode. Thus, when a client asks the DataNode       to read a file, the DataNode reads that file off of the disk and sends the data to the client       over a TCP socket. "Short-circuit" reads bypass the DataNode, allowing the client to read the       file directly. This is only possible in cases where the client is co-located with the data.       Short-circuit reads provide a substantial performance boost to many applications.Configure mountable HDFSCDP includes a FUSE (Filesystem in UserSpace) interface into HDFS. The             hadoop-hdfs-fuse command enables you to use your HDFS cluster as if it         were a traditional filesystem on Linux. 