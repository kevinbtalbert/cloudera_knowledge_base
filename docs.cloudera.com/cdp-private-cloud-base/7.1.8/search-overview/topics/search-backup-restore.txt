Backing up and restoring data using SearchCloudera Docs
Backing up and restoring data using Search
Cloudera Search includes a backup and restore mechanism primarily designed to provide
      disaster recovery capability for Apache Solr. You can create a backup of a Solr collection by
      creating and exporting a snapshot and restoring from this backup to recover from scenarios,
      such as accidental or malicious data modification or deletion.
importantBacking up and restoring Cloudera Search is based on the SolrCloud
         implementation of Apache Solr. Cloudera Search does not support backups using the Solr
         replication handler.
Cloudera Search includes a backup/restore mechanism primarily designed to provide disaster
         recovery capability for Apache Solr. You can create a backup of a Solr collection and
         restore from this backup if the index is corrupted due to a software bug, or if an
         administrator accidentally or maliciously deletes a collection or a subset of documents.
         This procedure can also be used as part of a cluster migration (for example, if you are
         migrating to a cloud environment), or to recover from a failed upgrade.
At a high level, the steps to back up a Solr collection are as follows:

Create a snapshot.
If you are exporting the snapshot to a remote cluster, prepare the snapshot for
            export.
Export the snapshot to either the local cluster or a remote one. This step uses the
            Hadoop DistCP utility.

The backup operation uses the built-in Solr snapshot capability to capture a point-in-time,
         consistent state of index data for a specified Solr collection. You can then use the Hadoop
         DistCp utility to copy the index files and the associated metadata for that snapshot to a
         specified location in HDFS or a cloud object store (for example, Amazon S3).
The Solr snapshot mechanism is based on the Apache Lucene IndexDeletionPolicy abstraction,
         which enables applications such as Cloudera Search to manage the lifecycle of specific
         index commits. A Solr snapshot assigns a user-specified name to the latest hard-committed
         state. After the snapshot is created, the Lucene index files associated with the commit are
         retained until the snapshot is explicitly deleted. The index files associated with the
         snapshot are preserved regardless of document updates and deletions, segment merges during
         index optimization, and so on.
Creating a snapshot does not take much time because it only preserves the snapshot metadata
         and does not copy the associated index files. A snapshot does have some storage overhead
         corresponding to the size of the index because the index files are retained indefinitely
         until the snapshot is deleted.
Solr snapshots can help you recover from some scenarios, such as accidental or malicious
         data modification or deletion. They are insufficient to address others, such as index
         corruption and accidental or malicious administrative action (for example, deleting a
         collection, changing collection configuration, and so on). To address these situations,
         export snapshots regularly and before performing non-trivial administrative operations such
         as changing the schema, splitting shards, or deleting replicas.
Exporting a snapshot exports the collection metadata as well as the corresponding Lucene
         index files. This operation internally uses the Hadoop DistCp utility to copy the Lucene
         index files and metadata, which creates a full backup at the specified location. After the
         backup is created, the original Solr snapshot can be safely deleted if necessary.
importantIf you create a snapshot and do not export it, you do not have a
         complete backup, and cannot restore index files if they are accidentally or maliciously
         deleted.

Related informationApache Lucene IndexDeletionPolicyBackups using the Solr replication handler