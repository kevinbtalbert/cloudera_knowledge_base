Scheduler performance improvementsCloudera Docs
Scheduler performance
      improvements
Provides information about Global scheduling feature and its test results. 
Improvements brought by Global Scheduling
            Improvements (YARN-5139)
Before the changes of global scheduling, the
            YARN scheduler was under a monolithic lock, which was
            underperforming. Global scheduling largely improved the internal
            locking structure and the thread-model of how the YARN scheduler
            works. The scheduler can now decouple placement decisions and
            change the internal data structure. This can also enable to lookup
            multiple nodes at a time, which is used by auto-scaling and
            bin-packing policies on cloud. For more information, see
            the
               design and implementation notes.

Based on the simulation, the test
            result of using Global Scheduling feature shows:


This is a simulated environment which has 20000 nodes and 47000 running applications.
               For more information about these tests, see the performance report.

Performance test from YARN
            community
Microsoft published Hydra:
            a federated resource manager for data-center scale
            analytics (Carlo, et al) report
            which highlights the scalability (Deployed YARN to more than 250k
            nodes, which includes five large federated cluster, each of them
            having 50k nodes) and scheduling performance (each clusterâ€™s
            scheduler can make more than 40k container allocation per second)
            by using Capacity Scheduler. This is the largest known YARN
            deployment in the world.
We also saw performance numbers
            from other companies in the community in line with what we have
            tested using simulators (thousands of container allocations per
            second for a cluster that has thousands of nodes).
Disclaimer: The performance number discussed above is related to the size of the
            cluster, workloads running on the cluster, queue structure, healthiness (such as node
            manager, disk, and network), container churns, and so on. This typically needs
            fine-tuning efforts for the scheduler and other cluster parameters to reach the ideal
            performance. This is NOT a guaranteed number which can be achieved just by using
            CDP.


Parent topic: Comparison of Fair Scheduler with Capacity Scheduler