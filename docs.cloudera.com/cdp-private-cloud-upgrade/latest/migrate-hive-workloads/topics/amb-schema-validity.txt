Identifying and fixing invalid Hive schema versionsCloudera Docs
Identifying and fixing invalid Hive schema versions
As Administrator, after upgrading from Ambari-managed HDP to CDP Private Cloud Base, you need to identify Hive
  metastore operations that might fail due to Hive schema version incompatibility.
 Incompatibility might exist if the upgrade process failed to make schema updates. You
      need to turn on the Hive Metastore Schema validation process for the metastore during the
      migration of your workloads to CDP. The Hive metastore captures any schema updates that occur
      during the upgrade, and displays issues in the Hive metastore logs. With this information, you
      can use the Apache Hive Schema tool to fix any problems. 

In Cloudera Manager, click 
          Clusters > HIVE > Configuration.

Check the hive.metastore.server.max.message.size.






Set hive.metastore.server.max.message.size to the recommended value:
          10% of the value of your Java heap size for Hive Metastore Server in bytes, but no more
          than 21478364. Recommended value: 214748364 

Click Clusters > HIVE > Configuration, and search for schema.

Check Strict Hive Metastore Schema Validation to set hive.metastore.schema.verification to true.

Check the Hive metastore logs and set a compatible metastore schema for the current Hive version using the Apache Hive Schema Tool.


Related informationApache Hive Schema ToolParent topic: Migrating Hive Workloads from HDP 2.6.5 after an in-place upgrade