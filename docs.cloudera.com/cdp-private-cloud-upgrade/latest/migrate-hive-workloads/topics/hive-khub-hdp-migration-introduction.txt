Migrating Hive Workloads from HDP 2.6.5 after an in-place upgradeCloudera Docs
Migrating Hive Workloads from HDP 2.6.5 after an in-place upgrade
You upgraded from HDP 2.6.5 to CDP Private Cloud Base. The upgrade
  moved the Hive data and schema to CDP Private Cloud Base. As the Hive
  Administrator, you need to make Hive tables available to your users. You need to configure your
  Hive-related services for CDP, and secure access to Hive data.
Assumptions

You are familiar with Apache Hive 3.1 key features and supported interfaces.
You acquired basic information about the CDP platform before you upgraded from HDP.



Related informationApache Hive 3 Key FeaturesApache Hive 3 Architectural OverviewChanges to HDP Hive tablesAs a Data Scientist, Architect, Analyst, or other Hive user you need to locate and use your Apache Hive     3 tables after an upgrade. You also need to understand the changes that occur during the upgrade process.Checking and correcting Hive table locations         As a Data Engineer, you need to understand the relocation of files after the upgrade process. The file         type and other factors affect the relocation during the upgrade.     Configuration changesSecurity tasksAfter an in-place upgrade to CDP, as Administrator, you might need to perform a few   security tasks, depending on the type of security you set up, Ranger or HDFS Access Control Lists   (ACLs), as well as your data encryption requirements and use of clients to access   Hive.Handling syntax changesYou need to modify queries affected by changes to Hive syntax after upgrading to CDP.   Hive has changed the syntax related to `db.table` references, such as CREATE TABLE    `mydb.mytable` â€¦ . Other syntax changes involve the LOCATION clause in CREATE TABLE.   Hive in CDP supports the enhancement to CREATE TABLE that adds the MANAGEDLOCATION   clause.Key semantic changes and workarounds As SQL Developer, Analyst, or other Hive user, you need to know potential problems         with queries due to semantic changes. Some of the operations that changed were not widely         used, so you might not encounter any of the problems associated with the changes. Migrating Spark AppsIdentifying and fixing invalid Hive schema versionsAs Administrator, after upgrading from Ambari-managed HDP to CDP Private Cloud Base, you need to identify Hive   metastore operations that might fail due to Hive schema version incompatibility.Fixing statisticsUpgrading or migrating from Hive 1 or Hive 2 to Hive 3 might result in missing         statistics. In Hive 3, these missing statistics, when detected by the cost-based optimizer         (CBO), could cause datasets to be disregarded. As Data Engineer, you need to fix these         statistics after upgrading.Converting Hive CLI scripts to BeelineIf you have legacy scripts that run Hive queries from edge nodes using the Hive CLI,         you must solve potential incompatibilities with variable substitution in these scripts. CDP         supports Beeline instead of Hive CLI. You can use Beeline to run legacy scripts with a few         caveats.Hive unsupported interfaces and featuresYou need to know the interfaces available in HDP or CDH platforms that are not     supported.