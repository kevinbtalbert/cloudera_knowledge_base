OzoneCloudera Docs
Ozone
You can provision an Ozone cluster for optimal performance based on the desired
      storage capacity.


Node Type
Chasis
CPU
RAM
OS Disk
Meta Disk
Data Disk
Network
Disk Controllers
GPU



Master node (OM and SCM and Recon)
1U
2x 20c
256 GB
2x 480 GB SSD
2x 4 TB NVMe
-
2x 25Gbps
-
-


Datanode (Ozone, no compute)
2U
2x 12c
256 GB
2x 480 GB SSD
2x 1.5 TB NVMe
24x 16TB
2x 25Gbps
2x 12 Gbps (low)
-


Datanode (Ozone, mixed compute)
2U
2x 24c
512 GB
2x 480 GB SSD
2x 3 TB NVMe
24x 16TB
2x 25Gbps
2x 12 Gbps (low)
Optional


Compute node
1U
2x 24c
512 GB
2x 480 GB SSD
1x 4 TB NVMe
-
1x 25Gbps
-
Optional


note

Keyspace: The above configuration can support up to 10B keys because of the 4 TB
               NVMe on the master nodes. 
Network: The network between the datanodes and the compute nodes cannot be
               oversubscribed by more than 2:1. Networking is sized to support the full (real world)
               bandwidth of the drives across the network. More drives require faster networks, both
               at the server level and the switch level.
NVMe: 
NVMe come in RAID1 pairs to provide business continuity for Ozone metadata in
                  case of hardware failure. This is not needed on pure compute nodes which only
                  use them for caching.
The masters and storage datanodes use NVMe to store Ozone metadata. 
The compute nodes use NVMe for shuffle (Spark, MapReduce, Tez) and for caching
                     (llap).
The mixed compute datanodes use NVMe for both Ozone metadata and shuffle
                  (Spark, MapReduce, Tez) plus caching (llap).
Mount Ozone partitions across both drives as RAID1 (800GB), with the remaining
                     space used for shuffle or cache as independant JBOD partitions.
RAID can be done in hardware or in software

The values are minimums and can go higher depending on requirements
Minimum configuration to start is 3 master nodes and 9 datanodes. This will support
               erasure coding rs(6,3) in the future. Additional datanodes can be added in increments
               of 1 to increase storage.


Table 1. Example sizing calculator

Logical (non-raw) capacity needed in TB
2 PB
8 PB
16 PB
-


Number of Data Nodes if using Erasure Coding rs(6,3)
9
32
64
These are calculated based on actual file storage required (See Row
                     1)


Logical data size proposed (TB, EC 6,3)
2304
8192
16384
-


Raw disk capacity (TB)
3456
12288
24576
-


Number of Data Nodes if using triple replication
16
64
128
These are calculated based on actual file storage required (See Row
                     1)


Logical data size - conservative using 3x (TB)
2048
8192
16384
-


Raw disk capacity (TB)
6144
24576
49152
-



Related informationOzone ArchitectureParent topic: Cloudera Runtime