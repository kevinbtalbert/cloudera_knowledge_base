Querying Hive managed tables from SparkCloudera Docs
Querying Hive managed tables from Spark
Hive-on-Spark is not supported on CDP. You need to use the Hive Warehouse
  Connector (HWC) to query Apache Hive managed tables from Apache Spark. 
To read Hive external tables from Spark, you do not need HWC. Spark uses native Spark to read
   external tables. For more information, see the Hive Warehouse Connector documentation.
The following example shows how to query a Hive table from Spark using HWC:
spark-shell --jars /opt/cloudera/parcels/CDH/jars/hive-warehouse-connector-assembly-1.0.0.7.1.4.0-203.jar --conf spark.sql.hive.hiveserver2.jdbc.url=jdbc:hive2://cdhhdp02.uddeepta-bandyopadhyay-s-account.cloud:10000/default --conf spark.sql.hive.hiveserver2.jdbc.url.principal=hive/cdhhdp02.uddeepta-bandyopadhyay-s-account.cloud@Uddeepta-bandyopadhyay-s-Account.CLOUD
scala> val hive = com.hortonworks.hwc.HiveWarehouseSession.session(spark).build()
scala> hive.executeUpdate("UPDATE hive_acid_demo set value=25 where key=4")
scala> val result=hive.execute("select * from default.hive_acid_demo")
scala> result.show()

Parent topic: Spark 2.3 to Spark 2.4 Refactoring