Compiling and running Spark workloadsCloudera Docs
Compiling and running Spark workloads
After modifying the workloads, compile and run (or dry run) the refactored workloads on
  Spark 2.4.
You can write Spark applications using Java, Scala, Python, SparkR, and others. You
   build jars from these scripts using one of the following compilers.


Java (with Maven/Java IDE),


Scala (with sbt),


Python (pip).


SparkR (RStudio)



Compiling and running a Java-based jobYou see by example how to compile a Java-based Spark job using Maven.Compiling and running a Scala-based jobYou see by example how to use sbt software to compile a Scala-based Spark         job.Running a Python-based jobYou can run a Python script to execute a spark-submit or pyspark command. Running a job interactively Parent topic: Spark 1.6 to Spark 2.4 RefactoringParent topic: Spark 2.3 to Spark 2.4 Refactoring