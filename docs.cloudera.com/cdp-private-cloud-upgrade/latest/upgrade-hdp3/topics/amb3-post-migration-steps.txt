Post transition stepsCloudera Docs
Post transition steps
You must complete the post transition steps to start the services in CDP Private Cloud Base.
The AM2CM tool transitions the service configurations. However, you must configure and
      perform additional steps to start the services in CDP Private Cloud Base. 
note

Review configuration warnings for all the services.
Review JVM parameters and configurations for all services as some of the JVM parameters
          and configurations are not transitioned. Most of the heap configurations are
          transitioned.
Review the Log4j configurations. Log4j configurations
          such as logs dir, size, and backup index are transitioned to Cloudera Manager.
Spark Atlas Connector (SAC) is disabled by default. If you enable SAC on HDP, the Spark
          entities are created using the Spark model (spark_db, spark_table). In CDP Private Cloud
          Base, SAC uses HMS and the entities are created using the Hive model (hive_db, hive_table,
          and hive_column). Hence Spark model entities in HDP are not in sync with the Hive model
          entities in CDP Private Cloud Base. In CDP Private Cloud Base, the lineage stitching and
          metadata update is not available on the Spark entities created in HDP. 
In the HDP 3.1.5.x cluster, Hive hook and HBase hook are enabled by default. SAC (Spark
          Atlas Connector or Spark Hook) is disabled by default. Note that, in HDP, SAC is in a
          Technical Preview state. In CDP Private Cloud Base, Hive Hook and HBase hook are enabled
          by default, In the AM2CM upgrade flow, if the Hive Hook and HBase hook are enabled in the
          HDP-3.1.5.x cluster, post-upgrade, it is enabled in CDP Private Cloud Base. HMS Hook
          functionality did not exist in HDP 3.1.5.x, hence it must be manually enabled in CDP
          Private Cloud Base. Similarly SAC in CDP Private Cloud Base must also be manually enabled. 
There are no manual steps required to enable SSO for the services on CDP. SSO is
          available by default on CDP. 


noteIf the cluster is kerberized, you can generate keytabs in Cloudera Manager under
        Security section → Kerberos Credentials →
        Generate Missing Credentials.

Enable Auto Start settingEnsure that you enable Auto Start Settings in Cloudera Manager         for all the components.ZooKeeperYou must complete the following steps to start the ZooKeeper service. Delete ZNodesRemove the ZNode for HDFS, YARN, Hive, HBase, and OozieRangerYou must change the port number for Ranger port numbers on Cloudera         Manager.Ranger KMSYou must add the key and value to Ranger KMS property. This procedure is not required         if you are on Cloudera Manager 7.4.4 and above and CDP 7.1.5 and above.Add Ranger policies for components on the CDP ClusterEnable the default ranger policies on the CDP Private Cloud Base cluster.Set maximum retention days for Ranger auditsYou can now update the solr document expiry         ranger.audit.solr.config.ttl and         ranger.audit.solr.config.delete.trigger parameters from Ranger         configurations in Cloudera Manager and refresh the configurations to get the Solr collection         for Ranger audits updated with ttl and delete trigger.HDFSPerform the following post migration steps. SolrYou must create a Ranger Plug-in audit directory and HDFS Home directory and start the Solr service.KafkaYou must cleanup metadata on broker hosts after migrating the Ambari-managed HDP     cluster to CDP Private Cloud Base.ImpalaAfter transitioning your cluster from HDP 3.1.5.x to CDP Private Cloud Base, you can manually install the Impala         service.YARNPerform the following post migration steps.  SparkYou must initialize a few directories for the Spark service.TezInstall the Tez tar files on HDFS.HiveYou need to complete some post-migration tasks after upgrading to CDP. You need to     activate Ranger services for Hadoop SQL (Hive resources) and HDFS paths to external tables. See     CDP Private Cloud Base Post-Upgrade Migration (link below) for information about several other tasks     and important post-upgrade information.HBasePost-migration, HBase hook for Atlas is not enabled by default on AM2CM migrated         clusters. you must manually enable HBase hook.Installing dependencies for HueHue in CDP 7.1.8 and higher uses Python 3. You must install Python 3.8 on all the Hue     hosts. Additionally, you must install psycopg2 package for PostgreSQL-backed Hue and MySQL     clients for MariaDB and MySQL databases depending on your operating systems.OzoneTo start Ozone service after migrating to the CDP Private Cloud Base cluster with         ranger plugin enabled. Perform the following steps:OoziePerform the following post migration tasks by validating the database URL, installing     the new shared libraries, accessing Oozie Loadbalancer URL, and configuring load     balancer.Atlas advanced configuration snippet (Safety valve)If non-default user names are used, then you must set this parameter. This section is         not applicable if you are upgrading to CDP Private Cloud Base 7.1.7.PhoenixAdd the Apache Phoenix service. If you are using Phoenix Query Server (PQS) in your         source HDP deployment, you must manually add the Apache Phoenix service using Cloudera         Manager to complete the Phoenix upgrade.Starting all servicesYou must now start all the services. KnoxThe following post migration steps are optional. Client ConfigurationsMigrating from Ambari to Cloudera Manager can leave the Ambari-managed HDP artifacts     and links that may not have changed. After everything has been configured, deploy Client     Configuration [Cloudera Manager > Clusters >       Actions > Deploy Client Configurations]. This     fixes any missing configuration references in the cluster. Securing ZooKeeperBy default, the AM2CM tool adds the -Dzookeeper.skipACL=yes     configuration to assist with the migration. You must remove the       -Dzookeeper.skipACL=yes configuration under Java Configuration       Options for Zookeeper Service to secure ZooKeeper and restart the     service.Zeppelin Shiro configurationsIf you had Zeppelin Shiro configurations in the HDP cluster, then you must configure         them manually on the CDP Private Cloud Base cluster. Migrating Spark workloads to CDPMigrating Spark workloads from CDH or HDP to CDP involves learning the Spark semantic     changes in your source cluster and the CDP target cluster. You get details about how to handle     these changes. Apache Hive Changes in CDPYou need to know where your tables are located and the property changes that the upgrade   process makes. You need to perform some post-migration tasks before using Hive tables and handle   semantic changes.Parent topic: Transitioning to Cloudera Manager