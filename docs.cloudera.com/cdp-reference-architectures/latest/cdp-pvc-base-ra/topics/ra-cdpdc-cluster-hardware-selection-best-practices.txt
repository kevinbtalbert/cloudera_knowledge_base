Cluster hardware selection best practicesCloudera Docs
Cluster hardware selection best practices
Read about a high-level overview of how different hardware component selections impact
  the performance of a Hadoop cluster.
See Hardware Requirements for detailed workload-specific practices.

Related informationHardware RequirementsNumber of drivesTraditionally, Hadoop has been thought of as a large I/O platform. While there are many   new types of workloads being run on Cloudera clusters that may not be as I/O bound as traditional   MapReduce applications, it is still useful to consider the I/O performance when designing a   Cloudera cluster.Disk layoutReview the recommended layout for master and worker nodes.Data density per driveHard drives come in many sizes today. Popular drive sizes are 1-4 TB, although larger   drives are more common now. When picking a drive size, consider the cost per TB, replication storm   in case of drive failure, and cluster performance. Number of cores and multithreadingOther than cost, there is no negative for buying more and better CPUs. However, the   return of investment on additional CPU power must be evaluated carefully.RAMMore memory is always good and it is recommended to purchase as much as the budget   allows. Applications such as Impala and Cloudera Search are often configured to use large amounts   of heap, and a mixed workload cluster supporting both services should have sufficient RAM to allow   all required services.Power suppliesHadoop software is designed around the expectation that nodes can fail. Redundant   hot-swap power supplies are not necessary for worker nodes, but should be used for master,   utility, and edge nodes. Parent topic: Infrastructure