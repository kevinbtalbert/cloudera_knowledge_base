Adding Kafka Data SourceCloudera Docs
Adding Kafka Data Source
You need to register Kafka as a Data Source using the Streaming SQL Console to
        create Kafka tables in SQL Stream Builder (SSB).


Make sure that you have Kafka service on your cluster.
Make sure that you have the right permissions set in Ranger.



Navigate to the Streaming SQL Console.


Go to your cluster in Cloudera Manager.


Select SQL Stream Builder from the list of services.


Click SQLStreamBuilder Console.
The Streaming SQL Console opens in a new window.



Open a project from the Projects page of Streaming SQL
            Console.


Select an already existing project from the list by clicking the
                  Open button or Switch button.


Create a new project by clicking the New Project
                button.


Import a project by clicking the Import button.


You are redirected to the Explorer view of the project.

Open Data Sources from the
                        Explorer view.

Click  next to Kafka.

Select New Kafka Source.
The Kafka Source window appears.



Add a Name to your Kafka provider.

Add the broker host name(s) to Brokers.
You need to copy the Kafka broker name(s) from Cloudera Manager.


Go to your cluster in Cloudera Manager.


Click Kafka from the list of services.


Click Instances.


Copy the hostname of the Kafka broker(s) you want to use.


Go back to the Add Kafka Source page.


Paste the broker hostname to the Brokers
                            field.

noteYou can add more than one broker hostname by separating them by
                                commas.



Add the default Kafka port after the hostname(s).
Example:TLS disabledTLS enableddocs-test-1.vpc.cloudera.com:9092, 
docs-test-2.vpc.cloudera.com:9092docs-test-1.vpc.cloudera.com:9093, 
docs-test-2.vpc.cloudera.com:9093



Select the security Protocol.
The connection protocol must be the same as it is configured for the Kafka
                    cluster in Cloudera Manager.You can choose from the following
                    protocols:

PLAINTEXTSSLSASL SSLSASL PLAINTEXT
Click Create.

Provide the path to the Kafka TrustStore and
                                    Kafka KeyStore with their dedicated
                                passwords.
Click Create.

Provide the path to the Kafka TrustStore and
                                    Kafka KeyStore with their dedicated
                                passwords.
Choose an SASL Mechanism.
Provide the Username for SASL.
Provide the Password for SASL.
Click Create.

Choose an SASL Mechanism.
Provide the Username for SASL.
Provide the Password for SASL.
Click Create.



You have registered Kafka as a data source to be able to
            add Kafka as a table in your SQL query. The already existing Kafka topics can be
            selected when adding Kafka as a table.
After registering a Kafka data source, you can edit,
            duplicate and delete it from Streaming SQL Console:
Open Data Sources from the
                        Explorer view.
Click  next to Kafka.
Select Manage.The Kafka Sources
                        tab opens where the registered Kafka providers are listed. You have the
                        following options to manage the Kafka sources:
Click on one of the existing Kafka providers to edit its
                            configurations.
Click  to remove the Kafka
                            provider.
Click  to duplicate the Kafka provider
                            with its configurations.



Parent topic: Registering Data Sources in SSB