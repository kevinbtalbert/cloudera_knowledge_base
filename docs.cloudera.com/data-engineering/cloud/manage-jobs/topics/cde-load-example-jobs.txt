CDE example jobs and sample dataCloudera Docs
CDE example jobs and sample data
Cloudera Data Engineering provides a suite of example jobs that operate on example
        data to showcase its core capabilities and make the onboarding easier. The example jobs are
        a combination of Spark and Airflow jobs, which include scenarios such as reading and writing
        from object storage, running an Airflow DAG, and expanding on Python capabilities with
        custom virtual environments. Once loaded, these jobs can be run on demand or scheduled. The
        sample data will be loaded into the environment's default Data Lake location.

In Cloudera Data Engineering (CDE), jobs are associated with virtual clusters. Before
                you can create a job, you must register a CDP environment and Data Lake, and create
                a CDE Service and virtual cluster. For more information, see Environments, Enabling Cloudera Data Engineering
                    service, and Creating virtual clusters .
importantThe user interface for CDE 1.17 and
                above has been updated. The left-hand menu was updated to provide easy access to
                commonly used pages. The steps below will vary slightly, for example, the
                    Overview page has been replaced with the
                    Home page. You can also load an example job by opening a
                new Virtual Cluster and clicking Load Example Jobs. To view
                CDE Services, click Administration on the left-hand menu. The
                new home page still displays Virtual Clusters, but now includes quick-access links
                located at the top for the following categories: Jobs,
                    Resources, and Download &
                Docs.


Below is the description of the different example jobs:

example-load-data : this will load the sample data onto
                    the environment data lake.note This will need to be run
                        manually first if the sample jobs are loaded in any user defined virtual
                        clusters.
example-virtual-env: demonstrates CDE job configuration
                    that utilizes Python Environment resource type to expand pyspark features via
                    custom virtual env. This example adds pandas support.
example-resources: demonstrates CDE job configuration
                    utilizing file-based resource type. Resources are mounted on Spark driver and
                    executor pods. This example uses an input file as a data source for a word-count
                    Spark app.
example-resources-schedules: demonstrates scheduling
                    functionality for Spark job in CDE. This example schedules a job to run at
                    5:04am UTC each day.
example-spark-pi: demonstrates how to define a CDE job.
                    It runs a SparkPi using a scala example jar located on a s3 bucket.
example-cdeoperator: demonstrates job orchestration
                    using Airflow. This example uses a custom CDE Operator to run two Spark jobs in
                    sequence, mimicking a pipeline composed of data ingestion and data
                    processing.
example-object-store: demonstrates how to access and
                    write data to object store on different form factors: S3, ADLS, and HDFS. This
                    example reads data already staged to object store and makes changes and then
                    saves back the transformed data to object store.
example-iceberg: demonstrates support for iceberg table
                    format. This example reads raw data from object store and saves data in iceberg
                    table format and showcases iceberg metadata info, such as snapshots.



In the Cloudera Data Platform (CDP) management console, click the
                        Data Engineering tile and click
                        Overview.

In the CDE Services  column, select the service
                    containing the virtual cluster where you want to create the job.

In the Virtual Clusters  column on the right, click the
                        View Jobs icon on the virtual cluster where you want
                    to create the application.

Select Load Example Jobs from the two options that
                    appear.
noteYou will see this window only if you have no existing
                        jobs in the virtual cluster.

If you have existing jobs in the virtual cluster, click on the hamburger icon
                    on the jobs page to Load Example Jobs.


A dialog box appears explaining the example jobs and sample data. Click
                        Confirm to load example jobs and sample data.


Example jobs will be loaded in the virtual cluster and
            sample data will be loaded in the environmentâ€™s Data Lake location.

