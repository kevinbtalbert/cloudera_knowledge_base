December 21, 2020Cloudera Docs
December 21, 2020
This release (1.3) of the Cloudera Data Engineering (CDE) service
    on CDP Public Cloud introduces the new features and improvements that are
    described in this topic.
Better scaling

Larger compute instance types to accommodate heavier ETL workloads
          and tweaks to infra services for higher job submission API
          throughput.
Better Spark defaults tuned for Kubernetes, improving scale up and
          stability.


Run profiling analysis on demand for additional tuning
        metrics
Users can trigger additional profiling analysis for any job, providing
        memory and CPU utilization, and stage-level CPU flamegraphs.

Workload Manager integration
CDE services can now share Spark application metadata and metrics with
        Workload Manager for better visibility into aggregate workloads across
        the entire CDP environment, manage SLAs, and identify additional tuning
        opportunities.

Easy log configuration & access

Full logs can now be downloaded as a new download option along with
          a quick bookmark to the S3 location of the Spark application
          logs.
The UI now supports setting the log level from OFF to DEBUG and
          TRACE.


Lightweight backup and restore
You can use the CDE CLI & API to backup and restore jobs from one
        virtual cluster into another virtual cluster within the same CDE service
        or completely new one. Helps support upgrades as it requires enabling a
        new service.

Create/clone job from existing run for easier debugging
CLI now supports cloning job runs, carrying over configs and
        parameters, making it easier to troubleshoot runs with failures.

[Tech Preview] Self-authored Airflow DAGs
DE and ML practitioners can now define their own pipelines packaged as
        an Apache Airflow Python DAG. Currently supported CDP operators include
        running Spark jobs on CDE and Hive jobs on CDW.


Parent topic: Older releases