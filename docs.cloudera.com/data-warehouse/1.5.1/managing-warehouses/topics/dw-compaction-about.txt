Compaction in Cloudera Data WarehouseCloudera Docs
Compaction in Cloudera Data Warehouse
You understand the importance of compaction and the consequences of neglecting to
  perform compaction. Compaction keeps your Data Warehouse healthy.Over time tables belonging to a workload become fragmented due to operations performed on them by
   your workload users. These small, obsolete files might lead to performance degradation and query
   latency problems. Compaction plays a major role in improving response time to workload queries by
   reducing the number of underlying files for a table and eliminating the obsolete ones. Compaction
   runs periodically in the background to maintain the optimal state. 
Running periodic compaction is a best practice for the performance for ACID transactions. ACID
   inserts and deletes generate the problematic files that you might need to monitor and manage. In
   Cloudera Data Warehouse (CDW), compaction is always performed by a Hive Virtual Warehouse. 
How compaction worksWhen data changes are made on Cloudera Data Warehouse (CDW) with inserts, updates, and deletes, delta files are created.    The more changes that are made, the more delta files are created. When a large number of delta    files are created, query performance degrades. Compaction removes these delta files to enhance    query performance.Compactor processesThese background processes run inside the metastore and HiveServer2 in Cloudera Data     Warehouse (CDW) Private Cloud. They support the data modifications made as a result of ACID     transactions.How compaction interacts with CDP BaseIn CDP Base, the initiator and cleaner processes also run in the metastore     as they do in Cloudera Data Warehouse (CDW) Private Cloud. However, the worker process runs in     HiveServer2 as a MapReduce task so its progress can be viewed in YARN.CDW Private Cloud Compaction ArchitectureThis diagram illustrates how the components that perform compaction interact on Cloudera     Data Warehouse (CDW) Private Cloud. In CDW Private Cloud, all compaction tasks for the default     Database Catalog are performed on CDP Base.Considerations for using compaction on CDW Private CloudThe first Hive Virtual Warehouse you create in Cloudera Data Warehouse (CDW) Private    Cloud for a Database Catalog (not including the default Database Catalog) is automatically set as  the compactor and performs all compaction work for subsequent Virtual Warehouses (Hive or Impala)  created under that Database Catalog.Changing compactor configuration for Hive Virtual Warehouses on CDW Private CloudTo enhance performance, the compactor is a set of background processes that compact     delta files, which are created as a by-product of data modifications. When it runs, it     incurs additional load on the Hive Virtual Warehouse assigned as the compactor in Cloudera Data     Warehouse (CDW) Private Cloud. You can change which Hive warehouse performs compaction to load-balance     this workload as necessary.     