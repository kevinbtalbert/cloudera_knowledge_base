Creating a user-defined function in Cloudera Data Warehouse Private CloudCloudera Docs
Creating a user-defined function in Cloudera Data Warehouse Private Cloud
You export user-defined functionality (UDF) to a JAR from a Hadoop- and
        Hive-compatible Java project and store the JAR on your cluster. Using Hive commands, you
        register the UDF based on the JAR, and call the UDF from a Hive query.


You must have access rights to upload the JAR to your cluster. Minimum
                    Required Role: Configurator (also provided by Cluster Administrator, Full
                    Administrator).
Make sure Hive on Tez or Hive LLAP is running on the cluster. 
Make sure that you have installed Java and a Java integrated
                    development environment (IDE) tool on the machine, or virtual machine, where you
                    want to create the UDF.



Setting up the development environmentYou can create a Hive UDF in a development environment using IntelliJ, for example,         and build the UDF. You define the Cloudera Maven Repository in your POM, which accesses         necessary JARS hadoop-common-<version>.jar and hive-exec-<version>.jar.Creating the UDF classYou define the UDF logic in a new class that returns the data type of a selected column     in a table.Building the project and uploading the JARYou compile the UDF code into a JAR and add the JAR to the classpath on the         cluster.Registering the UDFIn Cloudera Data Warehouse (CDW), you run a command from Hue to make the UDF         functional in Hive queries. The UDF persists between HiveServer restarts.Calling the UDF in a queryAfter registration of a UDF, you do not need to restart Hive before using the UDF in         a query. In this example, you call the UDF you created in a SELECT statement, and Hive         returns the data type of a column you specify.