




List of Pages in Category MapReduce (40 pages)
















































Documentation



Products
Services & Support
Solutions






List of Pages in Category MapReduce (40 pages)

MapReduce
A distributed processing framework for processing and generating large data sets and an implementation that runs on large clusters of industry-standard machines.
The processing model defines two types of functions: a map function that processes a key-value pair to generate a set of intermediate key-value pairs, and a reduce function that merges
all intermediate values associated with the same intermediate key.
A MapReduce job partitions the input data set into independent chunks that are processed by the map functions in a parallel manner. The framework sorts the outputs of the maps, which are
then input to the reduce functions. Typically both the input and the output of the job are stored in a distributed filesystem.
The implementation provides an API for configuring and submitting jobs and job scheduling and management services; a library of search, sort, index, inverted index, and word
co-occurrence algorithms; and the runtime. The runtime system partitions the input data, schedules the program's execution across a set of machines, handles machine failures, and manages the required
inter-machine communication.



Start typing to see matching topic titles in the MapReduce category: 
 If this category isn't helpful: List of all categories | Back to navigation tree view


A
B
C
H
I
M
N
O
P
S
T
U
V
Y





*

All Cloudera Documentation Categories

A

(Task) Accessing Table Data with MapReduce  (316 words: )
Attempt Metrics  (367 words: )

B

Batch Indexing Using Cloudera Search  (201 words: )

C

Cloudera Search Tasks and Processes  (1091 words: )
(Task) Configuring Google Cloud Storage Connectivity  (692 words: )
(Task) Configuring Oozie to Enable MapReduce Jobs To Read/Write from Amazon S3  (433 words: )
(Task) Configuring Oozie to Enable MapReduce Jobs To Read/Write from Microsoft Azure (ADLS)  (445 words: )
(Task) Configuring TLS/SSL for HDFS, YARN and MapReduce  (1381 words: )

H

(Task) How to Configure a MapReduce Job to Access S3 with an HDFS Credstore  (460 words: )

I

(Task) Indexing Data Using Cloudera Search  (296 words: )

M

(Task) Managing MapReduce  (857 words: )
(Task) Managing the Sqoop 1 Client  (1129 words: )
(Task) Managing YARN  (3032 words: )
(Task) Managing YARN (MRv2) and MapReduce (MRv1)  (1364 words: )
MapReduce (MRv1) and YARN (MRv2) High Availability  (229 words: )
MapReduce (MRv1) JobTracker High Availability  (638 words: )
MapReduce Indexing  (196 words: )
MapReduce Metrics  (420 words: )
MapReduceIndexerTool  (2968 words: )
(Task) Monitoring MapReduce Jobs  (481 words: )

N

Near Real Time Indexing Using Cloudera Search  (197 words: )

O

(Task) Optimizing Performance in CDH  (1560 words: )

P

Predicate Pushdown in Parquet  (1224 words: )
(Task) Preparing to Index Sample Tweets with Cloudera Search  (879 words: )

S

(Task) Setting HADOOP_MAPRED_HOME for Apache Hive in CDH  (240 words: )
Snappy Compression  (595 words: )
Spark Application Overview  (587 words: )
Spark Indexing  (2166 words: )

T

TaskController Error Codes (MRv1)  (657 words: )
TaskTracker Metrics  (941 words: )
(Task) Tuning YARN  (1422 words: )

U

(Task) Using Apache Avro Data Files with CDH  (1675 words: )
(Task) Using Apache Parquet Data Files with CDH  (5259 words: )
(Task) Using MapReduce Batch Indexing to Index Sample Tweets  (1706 words: )
(Task) Using MapReduce with HBase  (237 words: )
(Task) Using S3 Credentials with YARN, MapReduce, or Spark  (804 words: )

V

(Task) Viewing and Filtering MapReduce Activities  (1496 words: )
(Task) Viewing the Distribution of Task Attempts  (687 words: )

Y

YARN (MRv2) and MapReduce (MRv1) Schedulers  (469 words: )
YARN, MRv1, and Linux OS Security  (939 words: )











About Cloudera
Resources
Contact
Careers
Press
Documentation

United States: +1 888 789 1488
Outside the US: +1 650 362 0488



© 2017 Cloudera, Inc. All rights reserved. Apache Hadoop and associated open source project names are trademarks of the Apache Software Foundation. For a complete list of trademarks, click here.










Terms & Conditions  |  Privacy Policy












