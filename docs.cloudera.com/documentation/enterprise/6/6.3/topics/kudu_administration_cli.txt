



Apache Kudu Administration | 6.3.x | Cloudera Documentation









































 Documentation


Products
Services & Support
Solutions









Cloudera EnterpriseÂ 6.3.x | Other versions





CDH
Component GuidesKudu








View All Categories

Getting Started

Cloudera Personas
Planning a New Cloudera Enterprise Deployment
CDH

Hive
Impala
Kudu
Sentry
Spark
External Documentation


Cloudera Manager

Software Management

Parcels




Navigator

Getting Started
FAQ


Navigator Encryption

Navigator Key Trustee Server
Navigator Key HSM
Navigator HSM KMS
Navigator Encrypt


Proof-of-Concept Installation Guide

Before You Begin
Installing a Proof-of-Concept Cluster

Step 1: Run the Cloudera Manager Installer
Step 2: Install CDH Using the Wizard
Step 3: Set Up a Cluster


Managing the Embedded Database
Migrating Embedded PostgreSQL Database to External PostgreSQL Database


Getting Support
FAQ


Release Notes
Requirements and Supported Versions
Installation

Before You Install

Storage Space Planning for Cloudera Manager
Configure Network Names
Disabling the Firewall
Setting SELinux mode
Enable an NTP Service
Install Python 2.7 on Hue Hosts
Impala Requirements
Required Privileges
Ports

Cloudera Manager and Navigator
Navigator Encryption
CDH Components
DistCp
Third-Party Components


Recommended Role Distribution
Custom Installation Solutions

Configuring a Local Parcel Repository
Configuring a Local Package Repository
Manually Install Cloudera Software Packages
Creating Virtual Images of Cluster Hosts
Configuring a Custom Java Home Location
Creating a CDH Cluster Using a Cloudera Manager Template


Service Dependencies in Cloudera Manager


Installing Cloudera Manager and CDH

Step 1: Configure a Repository
Step 2: Install JDK
Step 3: Install Cloudera Manager Server
Step 4: Install Databases

Install and Configure MariaDB
Install and Configure MySQL
Install and Configure PostgreSQL
Install and Configure Oracle Database


Step 5: Set up the Cloudera Manager Database
Step 6: Install CDH and Other Software
Step 7: Set Up a Cluster


Installing Navigator Data Management
Installing Navigator Encryption

Installing Cloudera Navigator Key Trustee Server
Installing Cloudera Navigator Key HSM
Installing Key Trustee KMS
Installing Navigator HSM KMS Backed by Thales HSM
Installing Navigator HSM KMS Backed by Luna HSM
Installing Cloudera Navigator Encrypt


After Installation

Deploying Clients
Testing the Installation
Installing the GPL Extras Parcel
Migrating from Packages to Parcels
Migrating from Parcels to Packages
Secure Your Cluster


Troubleshooting Installation Problems
Uninstalling Cloudera Software

Uninstalling a CDH Component From a Single Host




Upgrade Guide
Cluster Management

Cloudera Manager

Cloudera Manager Admin Console

Home Page
Documentation
Automatic Logout


FAQ
Cloudera Manager API

Cluster Automation


Cloudera Manager Administration

Starting, Stopping, and Restarting the Cloudera Manager Server
Configuring Cloudera Manager Server Ports
Moving the Cloudera Manager Server to a New Host
Migrating Embedded PostgreSQL Database to External PostgreSQL Database
Migrating from PostgreSQL Database Server to MySQL/Oracle Database Server
Managing the Cloudera Manager Server Log
Cloudera Manager Agents

Starting, Stopping, and Restarting Cloudera Manager Agents
Configuring Cloudera Manager Agents
Managing Cloudera Manager Agent Logs


Configuring Network Settings
Managing Licenses
Sending Usage and Diagnostic Data to Cloudera
Exporting and Importing Cloudera Manager Configuration
Backing Up Cloudera Manager
Other Tasks and Settings
Cloudera Management Service


Extending Cloudera Manager


Cluster Configuration Overview

Modifying Configuration Properties Using Cloudera Manager
Autoconfiguration
Custom Configuration
Stale Configurations
Client Configuration Files
Viewing and Reverting Configuration Changes
Exporting and Importing Cloudera Manager Configuration
Cloudera Manager Configuration Properties Reference


Managing Clusters

Adding and Deleting Clusters
Starting, Stopping, Refreshing, and Restarting a Cluster
Pausing a Cluster in AWS
Renaming a Cluster
Cluster-Wide Configuration
Virtual Private Clusters and Cloudera SDX

Compatibility Considerations for Virtual Private Clusters
Tutorial: Using Impala, Hive and Hue with Virtual Private Clusters
Networking Considerations for Virtual Private Clusters


Managing Services

HBase
HDFS

Data Durability

Enabling Erasure Coding


NameNodes

Backing Up and Restoring HDFS Metadata
Moving NameNode Roles
Sizing NameNode Heap Memory
Backing Up and Restoring NameNode Metadata


DataNodes

Configuring Storage Directories for DataNodes
Configuring Storage Balancing for DataNodes
Performing Disk Hot Swap for DataNodes


JournalNodes
Configuring Short-Circuit Reads
Configuring HDFS Trash
Preventing Inadvertent Deletion of Directories
HDFS Balancers
Enabling WebHDFS
Adding HttpFS
Adding and Configuring an NFS Gateway
Setting HDFS Quotas
Configuring Mountable HDFS
Configuring Centralized Cache Management in HDFS
Configuring Proxy Users to Access HDFS
Using CDH with Isilon Storage
Configuring Heterogeneous Storage in HDFS


Hive
Hue

Adding a Hue Service and Role Instance
Managing Hue Analytics Data Collection
Enabling Hue Applications Using Cloudera Manager


Impala

The Impala Service
Modifying Impala Startup Options
Post-Installation Configuration for Impala
Configuring Impala to Work with ODBC
Configuring Impala to Work with JDBC


Key-Value Store Indexer
Kudu
Solr
Spark

Managing Spark Using Cloudera Manager
Managing the Spark History Server


Sqoop 1 Client
YARN (MRv2) and MapReduce (MRv1)

Managing YARN
Managing YARN ACLs
Managing MapReduce


Managing ZooKeeper
Configuring Services to Use the GPL Extras Parcel




Managing Hosts

Viewing Host Details
Using the Host Inspector
Adding a Host to the Cluster
Specifying Racks for Hosts
Host Templates
Performing Maintenance on a Cluster Host

Tuning and Troubleshooting Host Decommissioning
Maintenance Mode


Changing Hostnames
Deleting Hosts
Moving a Host Between Clusters


Managing Services

Adding a Service
Comparing Configurations for a Service Between Clusters
Add-on Services
Starting, Stopping, and Restarting Services
Rolling Restart
Aborting a Pending Command
Deleting Services
Renaming a Service
Configuring Maximum File Descriptors
Exposing Hadoop Metrics to Graphite
Exposing Hadoop Metrics to Ganglia


Managing Roles

Role Instances
Role Groups


Monitoring and Diagnostics

Introduction to Cloudera Manager Monitoring

Time Line
Health Tests
Home Page
Viewing Charts for Cluster, Service, Role, and Host Instances
Configuring Monitoring Settings


Monitoring Clusters
Inspecting Network Performance
Monitoring Services

Monitoring Service Status
Viewing Service Status
Viewing Service Instance Details
Viewing Role Instance Status

The Processes Tab


Running Diagnostic Commands for Roles
Periodic Stacks Collection
Viewing Running and Recent Commands
Monitoring Resource Management


Monitoring Hosts

Host Details
Host Inspector


Monitoring Activities

Monitoring MapReduce Jobs

Viewing and Filtering MapReduce Activities
Viewing the Jobs in a Pig, Oozie, or Hive Activity
Task Attempts
Viewing Activity Details in a Report Format
Comparing Similar Activities
Viewing the Distribution of Task Attempts


Monitoring Impala Queries

Query Details


Monitoring YARN Applications
Monitoring Spark Applications


Events
Alerts

Managing Alerts

Configuring Alert Email Delivery
Configuring Alert SNMP Delivery
Configuring Custom Alert Scripts




Triggers

Cloudera Manager Trigger Use Cases


Lifecycle and Security Auditing
Charting Time-Series Data

Dashboards
tsquery Language
Metric Aggregation


Logs

Viewing the Cloudera Manager Server Log
Viewing the Cloudera Manager Agent Logs
Managing Disk Space for Log Files


Reports

Directory Usage Report
Disk Usage Reports
Activity, Application, and Query Reports
The File Browser
Downloading HDFS Directory Access Permission Reports


Troubleshooting Cluster Configuration and Operation
Monitoring Reference

Cloudera Manager Entity Types
Cloudera Manager Entity Type Attributes
Cloudera Manager Events

HEALTH_CHECK Category
SYSTEM Category
AUDIT_EVENT Category
HBASE Category
LOG_MESSAGE Category
ACTIVITY_EVENT Category


Cloudera Manager Health Tests

Active Database Health Tests
Active Key Trustee Server Health Tests
Activity Monitor Health Tests
Alert Publisher Health Tests
Authentication Server Health Tests
Authentication Server Load Balancer Health Tests
Authentication Service Health Tests
Cloudera Management Service Health Tests
DataNode Health Tests
Event Server Health Tests
Failover Controller Health Tests
Flume Health Tests
Flume Agent Health Tests
Garbage Collector Health Tests
HBase Health Tests
HBase REST Server Health Tests
HBase Thrift Server Health Tests
HDFS Health Tests
History Server Health Tests
Hive Health Tests
Hive Execution Health Tests
Hive Metastore Server Health Tests
HiveServer2 Health Tests
Host Health Tests
Host Monitor Health Tests
HttpFS Health Tests
Hue Health Tests
Hue Server Health Tests
Impala Health Tests
Impala Catalog Server Health Tests
Impala Daemon Health Tests
Impala Llama ApplicationMaster Health Tests
Impala StateStore Health Tests
JobHistory Server Health Tests
JobTracker Health Tests
JournalNode Health Tests
Kafka Health Tests
Kafka Broker Health Tests
Kafka MirrorMaker Health Tests
Kerberos Ticket Renewer Health Tests
Key Management Server Health Tests
Key Management Server Proxy Health Tests
Key-Value Store Indexer Health Tests
Kudu Health Tests
Lily HBase Indexer Health Tests
Load Balancer Health Tests
MapReduce Health Tests
Master Health Tests
Monitor Health Tests
NFS Gateway Health Tests
NameNode Health Tests
Navigator Audit Server Health Tests
Navigator Luna KMS Metastore Health Tests
Navigator Luna KMS Proxy Health Tests
Navigator Metadata Server Health Tests
Navigator Thales KMS Metastore Health Tests
Navigator Thales KMS Proxy Health Tests
NodeManager Health Tests
Oozie Health Tests
Oozie Server Health Tests
Passive Database Health Tests
Passive Key Trustee Server Health Tests
RegionServer Health Tests
Reports Manager Health Tests
ResourceManager Health Tests
SecondaryNameNode Health Tests
Sentry Health Tests
Sentry Server Health Tests
Service Monitor Health Tests
Solr Health Tests
Solr Server Health Tests
Spark Health Tests
Spark (Standalone) Health Tests
Tablet Server Health Tests
TaskTracker Health Tests
Telemetry Publisher Health Tests
Tracer Health Tests
WebHCat Server Health Tests
Worker Health Tests
YARN (MR2 Included) Health Tests
ZooKeeper Health Tests
ZooKeeper Server Health Tests


Cloudera Manager Metrics

Accumulo Metrics
Active Database Metrics
Active Key Trustee Server Metrics
Activity Metrics
Activity Monitor Metrics
Agent Metrics
Alert Publisher Metrics
Attempt Metrics
Authentication Server Metrics
Authentication Server Load Balancer Metrics
Authentication Service Metrics
Cloudera Management Service Metrics
Cloudera Manager Server Metrics
Cluster Metrics
DSSD DataNode Metrics
DataNode Metrics
Directory Metrics
Disk Metrics
Event Server Metrics
Failover Controller Metrics
Filesystem Metrics
Flume Metrics
Flume Channel Metrics
Flume Sink Metrics
Flume Source Metrics
Garbage Collector Metrics
HBase Metrics
HBase REST Server Metrics
HBase RegionServer Replication Peer Metrics
HBase Thrift Server Metrics
HDFS Metrics
HDFS Cache Directive Metrics
HDFS Cache Pool Metrics
HRegion Metrics
HTable Metrics
History Server Metrics
Hive Metrics
Hive Execution Metrics
Hive Metastore Server Metrics
HiveServer2 Metrics
Host Metrics
Host Monitor Metrics
HttpFS Metrics
Hue Metrics
Hue Server Metrics
Impala Metrics
Impala Catalog Server Metrics
Impala Daemon Metrics
Impala Daemon Resource Pool Metrics
Impala Llama ApplicationMaster Metrics
Impala Pool Metrics
Impala Pool User Metrics
Impala Query Metrics
Impala StateStore Metrics
Isilon Metrics
Java KeyStore KMS Metrics
JobHistory Server Metrics
JobTracker Metrics
JournalNode Metrics
Kafka Metrics
Kafka Broker Metrics
Kafka Broker Topic Metrics
Kafka Broker Topic Partition Metrics
Kafka Consumer Metrics
Kafka Consumer Group Metrics
Kafka MirrorMaker Metrics
Kafka Producer Metrics
Kafka Replica Metrics
Kerberos Ticket Renewer Metrics
Key Management Server Metrics
Key Management Server Proxy Metrics
Key Trustee KMS Metrics
Key Trustee Server Metrics
Key-Value Store Indexer Metrics
Kudu Metrics
Kudu Replica Metrics
Lily HBase Indexer Metrics
Load Balancer Metrics
MapReduce Metrics
Master Metrics
Monitor Metrics
NFS Gateway Metrics
NameNode Metrics
Navigator Audit Server Metrics
Navigator HSM KMS backed by SafeNet Luna HSM Metrics
Navigator HSM KMS backed by Thales HSM Metrics
Navigator Luna KMS Metastore Metrics
Navigator Luna KMS Proxy Metrics
Navigator Metadata Server Metrics
Navigator Thales KMS Metastore Metrics
Navigator Thales KMS Proxy Metrics
Network Interface Metrics
NodeManager Metrics
Oozie Metrics
Oozie Server Metrics
Passive Database Metrics
Passive Key Trustee Server Metrics
RegionServer Metrics
Reports Manager Metrics
ResourceManager Metrics
SecondaryNameNode Metrics
Sentry Metrics
Sentry Server Metrics
Server Metrics
Service Monitor Metrics
Solr Metrics
Solr Replica Metrics
Solr Server Metrics
Solr Shard Metrics
Spark Metrics
Spark (Standalone) Metrics
Sqoop 1 Client Metrics
Tablet Server Metrics
TaskTracker Metrics
Telemetry Publisher Metrics
Time Series Table Metrics
Tracer Metrics
User Metrics
WebHCat Server Metrics
Worker Metrics
YARN (MR2 Included) Metrics
YARN Pool Metrics
YARN Pool User Metrics
ZooKeeper Metrics
Disabling Metrics for Specific Roles






Performance Management

Optimizing Performance in CDH
Choosing and Configuring Data Compression
Tuning the Solr Server
Tuning Spark Applications
Tuning YARN
Tuning JVM Garbage Collection


Resource Management

Static Service Pools

Linux Control Groups (cgroups)


Dynamic Resource Pools
YARN (MRv2) and MapReduce (MRv1) Schedulers

Configuring the Fair Scheduler
Enabling and Disabling Fair Scheduler Preemption


Data Storage for Monitoring Data
Cluster Utilization Reports

Creating a Custom Cluster Utilization Report




High Availability

HDFS High Availability

Introduction to HDFS High Availability
Configuring Hardware for HDFS HA
Enabling HDFS HA
Disabling and Redeploying HDFS HA
Configuring Other CDH Components to Use HDFS HA
Administering an HDFS High Availability Cluster
Changing a Nameservice Name for Highly Available HDFS Using Cloudera Manager


MapReduce (MRv1) and YARN (MRv2) High Availability

YARN (MRv2) ResourceManager High Availability
Work Preserving Recovery for YARN Components
MapReduce (MRv1) JobTracker High Availability


Cloudera Navigator Key Trustee Server High Availability
Enabling Key Trustee KMS High Availability
Enabling Navigator HSM KMS High Availability
High Availability for Other CDH Components

HBase High Availability

HBase Read Replicas


Oozie High Availability
Search High Availability


Navigator Data Management in a High Availability Environment
Configuring Cloudera Manager for High Availability With a Load Balancer

Introduction to Cloudera Manager Deployment Architecture
Prerequisites for Setting up Cloudera Manager High Availability
Cloudera Manager Failover Protection
High-Level Steps to Configure Cloudera Manager High Availability

Step 1: Setting Up Hosts and the Load Balancer
Step 2: Installing and Configuring Cloudera Manager Server for High Availability
Step 3: Installing and Configuring Cloudera Management Service for High Availability
Step 4: Automating Failover with Corosync and Pacemaker


Database High Availability Configuration
TLS and Kerberos Configuration for Cloudera Manager High Availability




Backup and Disaster Recovery

Port Requirements for Backup and Disaster Recovery
Data Replication

Designating a Replication Source
HDFS Replication

Monitoring the Performance of HDFS Replications


Hive/Impala Replication

Monitoring the Performance of Hive/Impala Replications


Replicating Data to Impala Clusters
Using Snapshots with Replication
Enabling Replication Between Clusters with Kerberos Authentication
Replication of Encrypted Data
HBase Replication


Snapshots

Cloudera Manager Snapshot Policies
Managing HBase Snapshots
Managing HDFS Snapshots


BDR Tutorials

How To Back Up and Restore Apache Hive Data Using Cloudera Enterprise BDR
How To Back Up and Restore HDFS Data Using Cloudera Enterprise BDR
BDR Automation Examples


Migrating Data between Clusters Using distcp

Copying Cluster Data Using DistCp
Copying Data between a Secure and an Insecure Cluster using DistCp and WebHDFS
Post-migration Verification




Backing Up Databases
Cloudera Navigator Administration
Accessing Storage Using Amazon S3

Configuring the Amazon S3 Connector

Using S3 Credentials with YARN, MapReduce, or Spark


Using Fast Upload with Amazon S3
Configuring and Managing S3Guard
How to Configure a MapReduce Job to Access S3 with an HDFS Credstore
Importing Data into Amazon S3 Using Sqoop


Accessing Storage Using Microsoft ADLS

Configuring ADLS Access Using Cloudera Manager
Configuring ADLS Gen1 Connectivity
Configuring ADLS Gen2 Connectivity
Importing Data into Microsoft Azure Data Lake Store Using Sqoop


Configuring Google Cloud Storage Connectivity
How To Create a Multitenant Enterprise Data Hub


Security

Overview

Authentication Overview
Encryption Overview

Encryption Mechanisms


Authorization Overview
Auditing and Data Governance


Authentication

Kerberos Security Artifacts Overview
Configuring Authentication in Cloudera Manager

Cloudera Manager User Accounts
Configuring External Authentication and Authorization for Cloudera Manager
Enabling Kerberos Authentication for CDH

Step 1: Install Cloudera Manager and CDH
Step 2: Install JCE Policy Files for AES-256 Encryption
Step 3: Create the Kerberos Principal for Cloudera Manager Server
Step 4: Enabling Kerberos Using the Wizard
Step 5: Create the HDFS Superuser
Step 6: Get or Create a Kerberos Principal for Each User Account
Step 7: Prepare the Cluster for Each User
Step 8: Verify that Kerberos Security is Working
Step 9: (Optional) Enable Authentication for HTTP Web Consoles for Hadoop Roles


Kerberos Authentication for Non-Default Users
Customizing Kerberos Principals
Managing Kerberos Credentials Using Cloudera Manager
Using a Custom Kerberos Keytab Retrieval Script
Adding Trusted Realms to the Cluster
Using Auth-to-Local Rules to Isolate Cluster Users


Configuring Authentication for Cloudera Navigator

Cloudera Navigator and External Authentication

Configuring Cloudera Navigator for Active Directory
Configuring Cloudera Navigator for LDAP
Configuring Cloudera Navigator for SAML


Configuring Groups for Cloudera Navigator


Configuring Authentication for Other Components

Flume Authentication

Configuring Kerberos for Flume Thrift Source and Sink Using Cloudera Manager
Writing to a Secure HBase Cluster
Using Substitution Variables with Flume for Kerberos Artifacts


HBase Authentication

Configuring Kerberos Authentication for HBase
Configuring Secure HBase Replication
Configuring the HBase Client TGT Renewal Period


Hive Authentication

HiveServer2 Security Configuration
Using Hive to Run Queries on a Secure HBase Server


HttpFS Authentication
Hue Authentication

Enable Hue to Use Kerberos for Authentication


Impala Authentication

Enabling Kerberos Authentication for Impala
Enabling LDAP Authentication for Impala
Using Multiple Authentication Methods with Impala
Configuring Impala Delegation for Hue and BI Tools


Cloudera Search Authentication

Using Kerberos with Cloudera Search


Spark Authentication
Sqoop1 Authentication
ZooKeeper Authentication


Configuring a Dedicated MIT KDC for Cross-Realm Trust
Integrating MIT Kerberos and Active Directory
Hadoop Users (user:group) and Kerberos Principals
Mapping Kerberos Principals to Short Names


Authorization

Cloudera Manager User Roles
HDFS Extended ACLs
Authorization for HDFS Web UIs
Configuring LDAP Group Mappings
Authorization With Apache Sentry
Configuring HBase Authorization


Encrypting Data in Transit

Understanding Keystores and Truststores
Configuring TLS Encryption for Cloudera Manager and CDH Using Auto-TLS
Manually Configuring TLS Encryption for Cloudera Manager
Manually Configuring TLS Encryption on the Agent Listening Port
Manually Configuring TLS/SSL Encryption for CDH Services

Configuring TLS/SSL for HDFS, YARN and MapReduce
Configuring TLS/SSL for HBase
Configuring TLS/SSL for Flume
Configuring Encrypted Communication Between HiveServer2 and Client Drivers
Configuring TLS/SSL for Hue
Configuring TLS/SSL for Impala
Configuring TLS/SSL for Oozie
Configuring TLS/SSL for Solr
Spark Encryption
Configuring TLS/SSL for HttpFS


Configuring TLS/SSL for Navigator Audit Server
Configuring TLS/SSL for Navigator Metadata Server
Configuring TLS/SSL for Kafka (Navigator Event Broker)
Configuring Encrypted Transport for HDFS
Configuring Encrypted Transport for HBase


Encrypting Data at Rest

Data at Rest Encryption Reference Architecture
Data at Rest Encryption Requirements
Resource Planning for Data at Rest Encryption
HDFS Transparent Encryption

Optimizing Performance for HDFS Transparent Encryption
Enabling HDFS Encryption Using the Wizard
Managing Encryption Keys and Zones
Configuring the Key Management Server (KMS)
Securing the Key Management Server (KMS)

Configuring KMS Access Control Lists (ACLs)


Migrating from a Key Trustee KMS to an HSM KMS
Migrating Keys from a Java KeyStore to Cloudera Navigator Key Trustee Server
Migrating a Key Trustee KMS Server Role Instance to a New Host
Configuring CDH Services for HDFS Encryption




Cloudera Navigator Key Trustee Server

Backing Up and Restoring Key Trustee Server and Clients
Initializing Standalone Key Trustee Server
Configuring a Mail Transfer Agent for Key Trustee Server
Verifying Cloudera Navigator Key Trustee Server Operations
Managing Key Trustee Server Organizations
Managing Key Trustee Server Certificates


Cloudera Navigator Key HSM

Initializing Navigator Key HSM
HSM-Specific Setup for Cloudera Navigator Key HSM
Validating Key HSM Settings
Managing the Navigator Key HSM Service
Integrating Key HSM with Key Trustee Server


Cloudera Navigator Encrypt

Registering Cloudera Navigator Encrypt with Key Trustee Server
Preparing for Encryption Using Cloudera Navigator Encrypt
Encrypting and Decrypting Data Using Cloudera Navigator Encrypt
Converting from Device Names to UUIDs for Encrypted Devices
Navigator Encrypt Access Control List
Maintaining Cloudera Navigator Encrypt


Configuring Encryption for Data Spills

Configuring Encrypted On-disk File Channels for Flume


Impala Security Overview

Security Guidelines for Impala
Securing Impala Data and Log Files
Installation Considerations for Impala Security
Securing the Hive Metastore Database
Securing the Impala Web User Interface


Kudu Security Overview
How-To Guides

Add Root and Intermediate CAs to Truststore for TLS/SSL
Amazon S3 Security
Authenticate Kerberos Principals Using Java
Check Cluster Security Settings
Configure Antivirus Software on CDH Hosts
Configure Browser-based Interfaces to Require Authentication (SPNEGO)
Configure Browsers for Kerberos Authentication (SPNEGO)
Configure Cluster to Use Kerberos Authentication
Convert DER, JKS, PEM Files for TLS/SSL Artifacts
Configure Authentication for Amazon S3
Configure Encryption for Amazon S3
Configure AWS Credentials
Enable Sensitive Data Redaction
Log a Security Support Case
Obtain and Deploy Keys and Certificates for TLS/SSL
Renew and Redistribute Certificates
Set Up a Gateway Host to Restrict Access to the Cluster
Set Up Access to Cloudera EDH or Altus Director (Microsoft Azure Marketplace)
Use Self-Signed Certificates for TLS


Troubleshooting Security Issues

Error Messages
Authentication and Kerberos Issues
HDFS Encryption Issues
Key Trustee KMS Encryption Issues
TLS/SSL Issues
YARN, MRv1, and Linux OS Security

TaskController Error Codes (MRv1)
ContainerExecutor Error Codes (YARN)






Cloudera Navigator Data Management

Overview
Search

Performing Actions on Entities


Auditing

Using Audit Events to Understand Cluster Activity
Exploring Audit Data
Cloudera Navigator Audit Event Reports


Analytics
Policies
Lineage

Using the Lineage View
Using Lineage to Display Table Schema
Generating Lineage Diagrams


Business Metadata

Defining Managed Properties
Adding and Editing Metadata


Administration (Navigator Console)

Managing Metadata Storage with Purge
Administering Navigator User Roles


Navigator Configuration and Management

Accessing Navigator Data Management Logs
Backing Up Cloudera Navigator Data
Authentication and Authorization
Configuring Cloudera Navigator to work with Hue HA
Cloudera Navigator support for Virtual Private Clusters
Encryption (TLS/SSL) and Cloudera Navigator
Limiting Sensitive Data in Navigator Logs
Preventing Concurrent Logins from the Same User
Navigator Audit Server Management

Setting Up Navigator Audit Server
Enabling Audit and Log Collection for Services
Configuring Service Auditing Properties
Adding Audit Filters
Monitoring Navigator Audit Service Health
Publishing Audit Events
Maintaining Navigator Audit Server


Navigator Metadata Server Management

Setting Up Navigator Metadata Server
Navigator Metadata Server Tuning
Configuring and Managing Extraction
Hive and Impala Lineage Configuration
Configuring the Server for Policy Messages




Cloudera Navigator and the Cloud

Using Cloudera Navigator with Altus Clusters

Configuring Extraction for Altus Clusters on AWS


Using Cloudera Navigator with Amazon S3

Configuring Extraction for Amazon S3




Cloudera Navigator APIs

Navigator APIs Overview
Applying Metadata to HDFS and Hive Entities using the API
Using the Purge APIs for Metadata Maintenance Tasks


Cloudera Navigator Reference

Lineage Diagram Icons
Search Syntax and Properties
Service Audit Events
Service Metadata Entity Types
Metadata Policy Expressions
User Roles and Privileges Reference


Troubleshooting Navigator Data Management


CDH Component Guides

Crunch
Flume

Configuring

Configuring the Flume Properties File
Files Installed by the Flume RPM and Debian Packages
Configuring Flume Security with Kafka


Using & Managing

Running Flume
Supported Sources, Sinks, and Channels
Flume Kudu Sink
Viewing the Flume Documentation




HBase

Configuring

Accessing HBase by using the HBase Shell
HBase Online Merge
Using MapReduce with HBase
Configuring HBase Garbage Collection
Configuring the HBase Canary
Configuring the Blocksize for HBase
Configuring the HBase BlockCache
Configuring Quotas
Configuring the HBase Scanner Heartbeat
Limiting the Speed of Compactions
Configuring and Using the HBase REST API
Configuring HBase MultiWAL Support
Storing Medium Objects (MOBs) in HBase
Configuring the Storage Policy for the Write-Ahead Log (WAL)


Using & Managing

Starting and Stopping HBase
Accessing HBase by using the HBase Shell
Using HBase Command-Line Utilities
Using the HBCK2 Tool to Remediate HBase Clusters
Hedged Reads
Reading Data from HBase
HBase Filtering
Writing Data to HBase
Importing Data Into HBase
Exposing HBase Metrics to a Ganglia Server
Using HashTable and SyncTable Tool


Security
Troubleshooting


Hive

Installation and Upgrade
Configuring

Configuring HiveServer2
File System Permissions
Starting, Stopping, & Using HS2
Using Hive w/HBase
Installing JDBC/ODBC Drivers
Setting HADOOP_MAPRED_HOME


Using & Managing

Managing Hive with Cloudera Manager
Ingesting & Querying Data
Using Parquet Tables
Running Hive on Spark
Using HS2 Web UI
Using Query Plan Graph View
Accessing Table Statistics
Managing UDFs
Hive ETL Jobs on S3
Hive with ADLS
Erasure Coding with Hive
Removing the Hive Compilation Lock
Sqoop HS2 Import


Tuning

Tuning Hive on Spark
Tuning Hive on S3
Configuring HS2 HA
Enabling Query Vectorization


Hive Metastore (HMS)

Configuring

Configuring HMS
Configuring HMS HA
Configuring HMS for HDFS HA
Configuring Shared Amazon RDS as HMS


Using & Managing

Starting the Metastore
Using Metastore Schema Tool




Data Replication
Security
HCatalog

HCatalog Prerequisites
Configuration Change on Hosts Used with HCatalog
Accessing Table Information with the HCatalog Command-line API
Accessing Table Data with MapReduce
Accessing Table Data with Pig
Accessing Table Information with REST
Viewing the HCatalog Documentation


Troubleshooting


Hue

Hue Versions
Reference Architecture
Installation & Upgrade
Using

Enable SQL Editor Autocompleter
Use Governance-Based Data Discovery
Use S3 as Source or Sink in Hue


Administration

Configuring
Customize Hue Web UI
Enable Governance-Based Data Discovery
Enable S3 Cloud Storage
Run Shell Commands
Connecting a Database

Connect to MySQL or MariaDB
Connect to PostgreSQL
Connect to Oracle (Parcel)
Connect to Oracle (Package)
Custom Database Tutorial


Migrate the Database
Populate the Database


Performance Tuning

Add Load Balancer
Configure High Availability
Hue/HDFS High Availability


Security

User Permissions
Create Password Scripts
Authenticate Users with LDAP
Synchronize with LDAP Server
Authenticate Users with SAML
Authorize Groups with Sentry


Troubleshooting

Potential Misconfiguration
Unable to connect to database with provided credential
Unable to view Snappy-compressed files
âUnknown Attribute Nameâ exception while enabling SAML
Invalid query handle
Services backed by Postgres fail or hang
Downloading query results from Hue takes long time
Error validating LDAP user in Hue
502 Proxy Error while accessing Hue from the Load Balancer
Hue Load Balancer does not start after enabling TLS
Unable to kill Hive queries from Job Browser
1040, 'Too many connections' exception
Unable to connect Oracle database to Hue using SCAN
Increasing the maximum number of processes for Oracle database
Unable to authenticate to Hbase when using Hue




Impala

Concepts and Architecture

Components
Developing Applications
Role in the Hadoop Ecosystem


Deployment Planning

Impala Requirements
Designing Schemas


Tutorials
Administration

Setting Timeouts
Load-Balancing Proxy for HA
Managing Disk Space
Auditing
Viewing Lineage Info


SQL Reference

Comments
Data Types

ARRAY Complex Type (CDH 5.5 or higher only)
BIGINT
BOOLEAN
CHAR
DECIMAL
DOUBLE
FLOAT
INT
MAP Complex Type (CDH 5.5 or higher only)
REAL
SMALLINT
STRING
STRUCT Complex Type (CDH 5.5 or higher only)
TIMESTAMP

Customizing Time Zones


TINYINT
VARCHAR
Complex Types (CDH 5.5 or higher only)


Literals
SQL Operators
Schema Objects and Object Names

Aliases
Databases
Functions
Identifiers
Tables
Views


SQL Statements

DDL Statements
DML Statements
ALTER DATABASE
ALTER TABLE
ALTER VIEW
COMMENT
COMPUTE STATS
CREATE DATABASE
CREATE FUNCTION
CREATE ROLE
CREATE TABLE
CREATE VIEW
DELETE
DESCRIBE
DROP DATABASE
DROP FUNCTION
DROP ROLE
DROP STATS
DROP TABLE
DROP VIEW
EXPLAIN
GRANT
INSERT
INVALIDATE METADATA
LOAD DATA
REFRESH
REFRESH AUTHORIZATION
REFRESH FUNCTIONS
REVOKE
SELECT

Joins
ORDER BY Clause
GROUP BY Clause
HAVING Clause
LIMIT Clause
OFFSET Clause
UNION Clause
Subqueries
TABLESAMPLE Clause
WITH Clause
DISTINCT Operator


SET

Query Options for the SET Statement

ABORT_ON_ERROR
ALLOW_ERASURE_CODED_FILES
ALLOW_UNSUPPORTED_FORMATS
APPX_COUNT_DISTINCT
BATCH_SIZE
BUFFER_POOL_LIMIT
COMPRESSION_CODEC
COMPUTE_STATS_MIN_SAMPLE_SIZE
DEBUG_ACTION
DECIMAL_V2
DEFAULT_JOIN_DISTRIBUTION_MODE
DEFAULT_SPILLABLE_BUFFER_SIZE
DISABLE_CODEGEN
DISABLE_CODEGEN_ROWS_THRESHOLD
DISABLE_ROW_RUNTIME_FILTERING
DISABLE_STREAMING_PREAGGREGATIONS
DISABLE_UNSAFE_SPILLS
ENABLE_EXPR_REWRITES
EXEC_SINGLE_NODE_ROWS_THRESHOLD
EXEC_TIME_LIMIT_S
EXPLAIN_LEVEL
HBASE_CACHE_BLOCKS
HBASE_CACHING
IDLE_SESSION_TIMEOUT
KUDU_READ_MODE
LIVE_PROGRESS
LIVE_SUMMARY
MAX_ERRORS
MAX_MEM_ESTIMATE_FOR_ADMISSION
MAX_NUM_RUNTIME_FILTERS
MAX_ROW_SIZE
MAX_SCAN_RANGE_LENGTH
MEM_LIMIT
MIN_SPILLABLE_BUFFER_SIZE
MT_DOP
NUM_NODES
NUM_ROWS_PRODUCED_LIMIT
NUM_SCANNER_THREADS
OPTIMIZE_PARTITION_KEY_SCANS
PARQUET_COMPRESSION_CODEC
PARQUET_ANNOTATE_STRINGS_UTF8
PARQUET_ARRAY_RESOLUTION
PARQUET_DICTIONARY_FILTERING
PARQUET_FALLBACK_SCHEMA_RESOLUTION
PARQUET_FILE_SIZE
PARQUET_READ_STATISTICS
PREFETCH_MODE
QUERY_TIMEOUT_S
REPLICA_PREFERENCE
REQUEST_POOL
RESOURCE_TRACE_RATIO
RUNTIME_BLOOM_FILTER_SIZE
RUNTIME_FILTER_MAX_SIZE
RUNTIME_FILTER_MIN_SIZE
RUNTIME_FILTER_MODE
RUNTIME_FILTER_WAIT_TIME_MS
S3_SKIP_INSERT_STAGING
SCAN_BYTES_LIMIT
SCHEDULE_RANDOM_REPLICA
SCRATCH_LIMIT
SHUFFLE_DISTINCT_EXPRS
SUPPORT_START_OVER
SYNC_DDL
THREAD_RESERVATION_AGGREGATE_LIMIT
THREAD_RESERVATION_LIMIT
TIMEZONE
TOPN_BYTES_LIMIT




SHOW
SHUTDOWN
TRUNCATE TABLE
UPDATE
UPSERT
USE
VALUES
Optimizer Hints


Built-In Functions

Mathematical Functions
Bit Functions
Type Conversion Functions
Date and Time Functions
Conditional Functions
String Functions
Miscellaneous Functions
Aggregate Functions

APPX_MEDIAN
AVG
COUNT
GROUP_CONCAT
MAX
MIN
NDV
STDDEV, STDDEV_SAMP, STDDEV_POP
SUM
VARIANCE, VARIANCE_SAMP, VARIANCE_POP, VAR_SAMP, VAR_POP


Analytic Functions


User-Defined Functions (UDFs)
SQL Differences Between Impala and Hive
Porting SQL


Resource Management

Admission Control and Query Queuing
Configuring Resource Pools and Admission Control
Admission Control Sample Scenario


Performance Tuning

Performance Best Practices
Join Performance
Table and Column Statistics
Benchmarking
Controlling Resource Usage
Runtime Filtering
HDFS Caching
HDFS Block Skew
Data Cache for Remote Reads
Testing Impala Performance
EXPLAIN Plans and Query Profiles


Scalability Considerations

Scaling Limits and Guidelines
Dedicated Coordinators
Metadata Management


Partitioning
File Formats

Text Data Files
Parquet Data Files
ORC Data Files
Avro Data Files
RCFile Data Files
SequenceFile Data Files


Using Impala to Query Kudu Tables
HBase Tables
S3 Tables

Configure with Cloudera Manager
Configure from Command Line


ADLS Tables
Logging
Impala Client Access

The Impala Shell

Configuration Options
Connecting to impalad
Running Commands and SQL Statements
Command Reference


Configuring Impala to Work with ODBC
Configuring Impala to Work with JDBC


Troubleshooting Impala

Web User Interface
Breakpad Minidumps


Ports Used by Impala
Impala Reserved Words
Impala Frequently Asked Questions


Kafka

Setup
Cloudera Manager
Clients
Brokers
Integration

Security
Managing Multiple Kafka Versions
Managing Topics across Multiple Kafka Clusters
Setting up an End-to-End Data Streaming Pipeline
Developing Kafka Clients
Metrics


Administration

Administration Basics
Broker Migration
User Limits for Kafka
Quotas
Kafka Command Line Tools
Disk Management
JBOD

Setup and Migration


Delegation Tokens

Enable Delegation Tokens
Managing Individual Delegation Tokens
Rotating the Master Key/Secret
Client Authentication
Kafka Security Hardening with Zookeeper ACLs


Kafka Streams


Performance Tuning

Handling Large Messages
Cluster Sizing
Broker Configuration
System-Level Broker Tuning
Kafka-ZooKeeper Performance Tuning


Reference

Metrics Reference
Useful Shell Command Reference


Kafka Public APIs
FAQ


Kudu

Concepts and Architecture
Usage Limitations
Installation and Upgrade
Configuration
Administration
Developing Applications with Kudu
Using Apache Impala with Kudu
Using the Hive Metastore with Kudu
Schema Design
Transaction Semantics
Background Tasks
Scaling Guide
Troubleshooting
More Resources


Oozie

Configuration

Configuring an External Database for Oozie
Oozie High Availability
Configuring Oozie to Use HDFS HA
Oozie Authentication
Using Sqoop Actions with Oozie
Configuring Oozie to Enable MapReduce Jobs To Read/Write from Amazon S3
Configuring Oozie to Enable MapReduce Jobs To Read/Write from Microsoft Azure (ADLS)


Oozie

Starting, Stopping, and Accessing the Oozie Server
Adding the Oozie Service Using Cloudera Manager
Redeploying the Oozie ShareLib
Configuring Oozie Data Purge Settings Using Cloudera Manager
Dumping and Loading an Oozie Database Using Cloudera Manager
Adding Schema to Oozie Using Cloudera Manager
Enabling the Oozie Web Console on Managed Clusters
Enabling Oozie SLA with Cloudera Manager
Setting the Oozie Database Timezone
Scheduling in Oozie Using Cron-like Syntax




Phoenix

Release Notes
Prerequisites
Installing Apache Phoenix using Cloudera Manager
Using Apache Phoenix to Store and Access Data

Orchestrating SQL and APIs with Apache Phoenix
Configuring Phoenix Query Server

Connecting to PQS


Creating and Using User-Defined Functions (UDFs) in Phoenix
Mapping Phoenix Schemas to HBase Namespaces
Associating Tables of a Schema to a Namespace
Using Phoenix Client to Load Data
Using the Index in Phoenix


Understanding Apache Phoenix-Spark Connector
Understanding Apache Phoenix-Hive Connector
Performance Tuning
Frequently Asked Questions
Uninstalling Phoenix Parcel


Search

Search

Understanding
Search and Other CDH Components
Architecture
Tasks and Processes


Tutorial

Validating Search Deployment
Preparing to Index Sample Tweets
Using MapReduce Batch Indexing to Index Sample Tweets
Near Real Time (NRT) Indexing Tweets Using Flume
Using Hue with Search


Deployment Planning

Schemaless Mode


Deploying

Using Search through a Proxy for High Availability
Using Custom JAR Files with Search
Cloudera Search Security

Enable Kerberos Authentication in Cloudera Search




Managing

Configuration
Collections
solrctl Reference
Example solrctl Usage
Migrating Solr Replicas
Backing Up and Restoring


ETL with Cloudera Morphlines

Example Morphline Usage


Indexing Data

Near Real Time Indexing

Flume NRT Indexing

Flume MorphlineSolrSink Configuration Options
Flume MorphlineInterceptor Configuration Options
Flume Solr UUIDInterceptor Configuration Options
Flume Solr BlobHandler Configuration Options
Flume Solr BlobDeserializer Configuration Options


Lily HBase NRT Indexing

Using the Lily HBase NRT Indexer Service
Configuring Lily HBase Indexer Security




Batch Indexing

Spark Indexing
MapReduce Indexing

MapReduceIndexerTool
Lily HBase Batch Indexing






FAQ
Troubleshooting

Configuration and Log Files
Identifying Problems
Solr Query Returns no Documents when Executed with a Non-Privileged User




Sentry

Before You Install Sentry
Installing and Upgrading the Sentry Service
Configuring

Sentry High Availability
Enabling Sentry Authorization for Impala
Configuring Sentry Authorization for Cloudera Search


Using & Managing

Synchronizing HDFS ACLs and Sentry Permissions
Authorization Privilege Model for Hive and Impala
Authorization Privilege Model for Cloudera Search
Hive SQL Syntax for Use with Sentry
Object Ownership
Using the Sentry Web Server
Sentry Debugging and Failure Scenarios


Troubleshooting
How-To Guides

Enabling High Availability
Verify HDFS ACL Sync
Managing Table Access in Hue




Spark

Running Your First Spark Application
Troubleshooting for Spark
Frequently Asked Questions about Apache Spark in CDH
Spark Application Overview
Developing Spark Applications

Developing and Running a Spark WordCount Application
Using Spark Streaming
Using Spark SQL
Using Spark MLlib
Accessing External Storage

Accessing Data Stored in Amazon S3 through Spark
Accessing Data Stored in Azure Data Lake Store (ADLS) through Spark
Accessing Avro Data Files From Spark SQL Applications
Accessing Parquet Files From Spark SQL Applications


Building Spark Applications
Configuring Spark Applications


Running Spark Applications

Running Spark Applications on YARN
Using PySpark

Running Spark Python Applications
Spark and IPython and Jupyter Notebooks


Tuning Spark Applications


Spark and Hadoop Integration

Building and Running a Crunch Application with Spark




File Formats and Compression

Parquet

Predicate Pushdown in Parquet


Avro
Data Compression
Snappy Compression




Glossary





To read this documentation, you must turn JavaScript on.




Apache Kudu Administration

This topic describes how to perform common administrative tasks and workflows with Apache Kudu.


Starting and Stopping Kudu Processes

Start Kudu services using the following commands:
sudo service kudu-master start
sudo service kudu-tserver start
To stop Kudu services, use the following commands:
sudo service kudu-master stop
sudo service kudu-tserver stop
Configure the Kudu services to start automatically when the server starts, by adding them to the default runlevel.
sudo chkconfig kudu-master on            # RHEL / CentOS 
sudo chkconfig kudu-tserver on           # RHEL / CentOS 

sudo update-rc.d kudu-master defaults    # Ubuntu 
sudo update-rc.d kudu-tserver defaults   # Ubuntu



Kudu Web Interfaces

Kudu tablet servers and masters expose useful operational information on a built-in web interface.


Kudu Master Web Interface

Kudu master processes serve their web interface on port 8051. The interface exposes several pages with information about the state of the cluster.


A list of tablet servers, their host names, and the time of their last heartbeat.


A list of tables, including schema and tablet location information for each.


SQL code which you can paste into Impala Shell to add an existing table to Impalaâs list of known data sources.





Kudu Tablet Server Web Interface

Each tablet server serves a web interface on port 8050. The interface exposes information about each tablet hosted on the server, its current state, and debugging information about
maintenance background operations.



Common Web Interface Pages

Both Kudu masters and tablet servers expose the following information via their web interfaces:


HTTP access to server logs.


An /rpcz endpoint which lists currently running RPCs via JSON.


Details about the memory usage of different components of the process.


The current set of configuration flags.


Currently running threads and their resource consumption.


A JSON endpoint exposing metrics about the server.


The version number of the daemon deployed on the cluster.


These interfaces are linked from the landing page of each daemonâs web UI.




Kudu Metrics

Kudu daemons expose a large number of metrics. Some metrics are associated with an entire server process, whereas others are associated with a particular tablet replica.


Listing Available Metrics

The full set of available metrics for a Kudu server can be dumped using a special command line flag:
$ kudu-tserver --dump_metrics_json
$ kudu-master --dump_metrics_json
This will output a large JSON document. Each metric indicates its name, label, description, units, and type. Because the output is JSON-formatted, this information can easily be parsed
and fed into other tooling which collects metrics from Kudu servers.
For the complete list of metrics collected by Cloudera Manager for a Kudu service, look for the Kudu metrics listed under Cloudera Manager Metrics .



Collecting Metrics via HTTP

Metrics can be collected from a server process via its HTTP interface by visiting /metrics. The output of this page is JSON for easy parsing by monitoring
services. This endpoint accepts several GET parameters in its query string:


/metrics?metrics=<substring1>,<substring2>,â¦â - Limits the returned metrics to those which contain at least one of the provided substrings. The
substrings also match entity names, so this may be used to collect metrics for a specific tablet.


/metrics?include_schema=1 - Includes metrics schema information such as unit, description, and label in the JSON output. This information is typically
omitted to save space.


/metrics?compact=1 - Eliminates unnecessary whitespace from the resulting JSON, which can decrease bandwidth when fetching this page from a remote
host.


/metrics?include_raw_histograms=1 - Include the raw buckets and values for histogram metrics, enabling accurate aggregation of percentile metrics over time
and across hosts.


/metrics?level=info - Limits the returned metrics based on their severity level. The levels are ordered and lower levels include the levels above them.
If no level is specified, debug is used to include all metrics. The valid values are:

debug - Metrics that are diagnostically helpful but generally not monitored during normal operation.
info - Generally useful metrics that operators always want to have available but may not be monitored under normal circumstances.
warn - Metrics which can often indicate operational oddities, which may need more investigation.




For example:
$ curl -s 'http://example-ts:8050/metrics?include_schema=1&metrics=connections_accepted'
[
    {
        "type": "server",
        "id": "kudu.tabletserver",
        "attributes": {},
        "metrics": [
            {
                "name": "rpc_connections_accepted",
                "label": "RPC Connections Accepted",
                "type": "counter",
                "unit": "connections",
                "description": "Number of incoming TCP connections made to the RPC server",
                "value": 92
            }
        ]
    }
]
$ curl -s 'http://example-ts:8050/metrics?metrics=log_append_latency'
[
    {
        "type": "tablet",
        "id": "c0ebf9fef1b847e2a83c7bd35c2056b1",
        "attributes": {
            "table_name": "lineitem",
            "partition": "hash buckets: (55), range: [(<start>), (<end>))",
            "table_id": ""
        },
        "metrics": [
            {
                "name": "log_append_latency",
                "total_count": 7498,
                "min": 4,
                "mean": 69.3649,
                "percentile_75": 29,
                "percentile_95": 38,
                "percentile_99": 45,
                "percentile_99_9": 95,
                "percentile_99_99": 167,
                "max": 367244,
                "total_sum": 520098
            }
        ]
    }
]


Diagnostics Logging

Kudu may be configured to periodically dump all of its metrics to a local log file using the --metrics_log_interval_msflag. Set this flag to the interval
at which metrics should be written to a diagnostics log file.
The diagnostics log will be written to the same directory as the other Kudu log files, with a similar naming format, substituting diagnostics instead of a
log level like INFO. After any diagnostics log file reaches 64MB uncompressed, the log will be rolled and the previous file will be gzip-compressed.
The log file generated has three space-separated fields. The first field is the word metrics. The second field is the current timestamp in microseconds
since the Unix epoch. The third is the current value of all metrics on the server, using a compact JSON encoding. The encoding is the same as the metrics fetched via HTTP described above.




Rack Awareness (Location Awareness)

Starting in CDH 6.2, Kudu supports a rack awareness feature. Kuduâs ordinary re-replication methods ensure the availability of the cluster in the event of a single node failure. However,
clusters can be vulnerable to correlated failures of multiple nodes. For example, all of the physical hosts on the same rack in a datacenter may become unavailable simultaneously if the top-of-rack
switch fails. Kuduâs rack awareness feature provides protection from certain kinds of correlated failures, such as the failure of a single rack in a datacenter.
The first element of Kuduâs rack awareness feature is location assignment. When a tablet server registers with a master, the master assigns it a location. A location is a /-separated string that begins with a / and where each /-separated component consists of characters from the set
[a-zA-Z0-9_-.]. For example, /dc-0/rack-09 is a valid location, while rack-04 and /rack=1 are not valid locations. Thus location strings resemble absolute UNIX file paths where characters in directory and file names are restricted to the set [a-zA-Z0-9_-.]. Presently, Kudu does not use the hierarchical structure of locations, but it may in the future. Location assignment is done by a user-provided command, whose path
should be specified using the --location_mapping_cmd master flag. The command should take a single argument, the IP address or hostname of a tablet server, and return
the location for the tablet server. Make sure that all Kudu masters are using the same location mapping command.
The second element of Kuduâs rack awareness feature is the placement policy: Do not place a majority of replicas of a tablet on tablet servers in the same location.
The leader master, when placing newly created replicas on tablet servers and when re-replicating existing tablets, will attempt to place the replicas in a way that complies with the
placement policy. For example, in a cluster with five tablet servers A, B, C, D, and E, with respective locations /L0, /L0, /L1,
/L1, /L2, to comply with the placement policy a new 3x replicated tablet could have its replicas placed on A, C, and E, but not on A, B, and C, because then the tablet would have 2/3 replicas in location /L0. As another example, if a tablet has replicas on tablet servers A, C, and E, and then C fails, the replacement replica must be placed on D in order to comply with the placement policy.
In the case where it is impossible to place replicas in a way that complies with the placement policy, Kudu will violate the policy and place a replica anyway. For example, using the
setup described in the previous paragraph, if a tablet has replicas on tablet servers A, C, and E, and
then E fails, Kudu will re-replicate the tablet onto one of B or D, violating the placement policy, rather
than leaving the tablet under-replicated indefinitely. The kudu cluster rebalance tool can reestablish the placement policy if it is possible to do so. The kudu cluster rebalance tool can also be used to reimpose the placement policy on a cluster if the cluster has just been configured to use the rack awareness feature and existing
replicas need to be moved to comply with the placement policy. See Running Tablet Rebalancing Tool on Rack-Aware
Cluster for more information.



Backup and Restore

Logical backup and restore

As of Kudu 1.10.0, Kudu supports both full and incremental table backups via a job implemented using Apache Spark. Additionally, it supports restoring tables from full and incremental
backups via a restore job implemented using Apache Spark.
Kudu backup and restore jobs use Apache Spark. Therefore, ensure that you install Apache Spark in your environment. To download Apache Spark, see the Apache Spark documentation. You can also review the Submitting Spark Applications topics.


Backing up tables

You can use the KuduBackup Spark job to backup one or more Kudu tables. When you first run the job for a table, a full backup is run. Additional runs will
perform incremental backups which will only contain the rows that have changed since the initial full backup. A new set of full backups can be forced at anytime by passing the --forceFull flag to the backup job.
Following are some of the common flags that you can use while taking a backup:


--rootPath: The root path is used to output backup data. It accepts any Spark-compatible path.


--kuduMasterAddresses: Is used to specify comma-separated addresses of Kudu masters. The default value is localhost.


<table>â¦â: Used to indicate a list of tables that you want to back up.



Note: You can obtain a full list of Job options by entering the --help flag.
Here is a full example of a KuduBackup job execution which backs up the tables foo and bar
to the HDFS directory kudu-backups:
spark-submit --class org.apache.kudu.backup.KuduBackup kudu-backup2_2.11-1.10.0.jar \
  --kuduMasterAddresses master1-host,master-2-host,master-3-host \
  --rootPath hdfs:///kudu-backups \
  foo bar



Restoring Tables from Backups

You can use the KuduRestore Spark job to restore one or more Kudu tables. For each backed up table, the KuduRestore job
restores the full backup and each associated incremental backup until the full table state is restored. Restoring a complete series of full and incremental backups is possible because the backups are
linked via the from_ms and to_ms fields in the backup metadata. By default, the restore job creates tables with the same name as the
table that was backed up. If you want to side-load the tables without affecting the existing tables, you can specify the --tableSuffix parameter to append a suffix to
each restored table.
Some of the common flags that you can use to restore tables are:


--rootPath: It is the root path to the backup data. It accepts any Spark-compatible path.


--kuduMasterAddresses: Is used to specify comma-separated addresses of Kudu masters. The default value is localhost


--tableSuffix: It is used to add a suffix to the restored table names. It can only be used when createTables is set to
true.


--timestampMs: It is a UNIX timestamp in milliseconds that defines the latest time to use when selecting restore candidates. Default: System.currentTimeMillis()


<table>â¦â: It is used to specify a list of tables to be backed up.


Note: You can obtain a full list of Job options by entering the --help flag.
Here is a full example of a KuduRestore job execution which restores the tables foo and bar
from the HDFS directory kudu-backups:
spark-submit --class org.apache.kudu.backup.KuduRestore kudu-backup2_2.11-1.10.0.jar \
  --kuduMasterAddresses master1-host,master-2-host,master-3-host \
  --rootPath hdfs:///kudu-backups \
  foo bar



Backup Tools

An additional backup-tools jar is available to provide some backup exploration and garbage collection capabilities. This jar does not use Spark directly,
but instead only requires the Hadoop classpath to run.
Commands:

list: Lists the backups in the rootPath
clean: Cleans up old backed up data in the rootPath


Note: You can obtain a full list of Job options by entering the --help flag.
Following is an example execution which prints the command options:
java -cp $(hadoop classpath):kudu-backup-tools-1.10.0.jar org.apache.kudu.backup.KuduBackupCLI --help



Backup Directory Structure

The backup directory structure in the rootPath is considered an internal detail and could change in future versions of Kudu. Additionally, the format and
content of the data and metadata files is meant for the backup and restore process only and could change in future versions of Kudu. That said, understanding the structure of the backup rootPath and how it is used can be useful when working with Kudu backups.
The backup directory structure in the rootPath is as follows:
/<rootPath>/<tableId>-<tableName>/<backup-id>/
   .kudu-metadata.json
   part-*.<format>


rootPath: Can be used to distinguish separate backup groups, jobs, or concerns.


tableId: Is the unique internal ID of the table being backed up.


tableName: Is the name of the table being backed up.
Note: Table names are URL encoded to prevent pathing issues.


backup-id: Is a way to uniquely identify/group the data for a single backup run.


.kudu-metadata.json: It contains all of the metadata to support recreating the table, linking backups by time, and handling data format changes.
It is written last so that the failed backups will not have a metadata file and will not be considered at the restore time or at the backup linking time.


part-*.<format>: Is used to indicate the data files containing the tables data.


Currently, 1 part file per Kudu partition.


Incremental backups contain an additional âRowActionâ byte column at the end.


Currently, the only supported format/suffix is parquet










Physical backups of an entire node

Kudu does not provide a built-in physical backup and restore functionality yet. However, it is possible to create a physical backup of a Kudu node (either tablet server or master) and
restore it later.
Warning:
The node to be backed up must be offline during the procedure, or else the backed up (or restored) data will be inconsistent.
Certain aspects of the Kudu node (such as its hostname) are embedded in the on-disk data. As such, itâs not yet possible to restore a physical backup of a node onto another machine.


Stop all Kudu processes in the cluster. This prevents the tablets on the backed up node from being rereplicated elsewhere unnecessarily.
If creating a backup, make a copy of the WAL, metadata, and data directories on each node to be backed up. It is important that this copy preserve all file attributes as well as
sparseness.
If restoring from a backup, delete the existing WAL, metadata, and data directories, then restore the backup via move or copy. As with creating a backup, it is important that the
restore preserve all file attributes and sparseness.
Start all Kudu processes in the cluster.





Common Kudu Workflows


Migrating to Multiple Kudu Masters

To provide high availability and to avoid a single point of failure, Kudu clusters should be created with multiple masters. Many Kudu clusters were created with just a single master,
either for simplicity or because Kudu multi-master support was still experimental at the time. This workflow demonstrates how to migrate to a multi-master configuration. It can also be used to
migrate from two masters to three with straightforward modifications.
Important:


This workflow is unsafe for adding new masters to an existing multi-master configuration that already has three or more masters. Do not use it for that purpose.


An even number of masters doesn't provide any benefit over having one fewer masters. This guide should always be used for migrating to three masters.


This workflow presumes you are familiar with Kudu configuration management, with or without Cloudera Manager.


All of the command line steps below should be executed as the Kudu UNIX user. The example commands assume the Kudu Unix user is kudu, which is typical.





Prepare for the migration


Establish a maintenance window (one hour should be sufficient). During this time the Kudu cluster will be unavailable.
Decide how many masters to use. The number of masters should be odd. Three or five node master configurations are recommended; they can tolerate one or two failures respectively.
Perform the following preparatory steps for the existing master:


Identify and record the directories where the masterâs write-ahead log (WAL) and data live. If using Kudu system packages, their default locations are /var/lib/kudu/master, but they may be customized using the fs_wal_dir and fs_data_dirs configuration parameters. The
command below assume that fs_wal_dir is /data/kudu/master/wal and fs_data_dirs is /data/kudu/master/data. Your configuration may differ. For more information on configuring these directories, see the Kudu Configuration docs.


Identify and record the port the master is using for RPCs. The default port value is 7051, but it may have been customized using the rpc_bind_addresses
configuration parameter.


Identify the masterâs UUID. It can be fetched using the following command:
$ sudo -u kudu kudu fs dump uuid --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] 2>/dev/null

master_data_dir

The location of the existing masterâs previously recorded data directory.
For example:
$ sudo -u kudu kudu fs dump uuid --fs_wal_dir=/var/lib/kudu/master 2>/dev/null
4aab798a69e94fab8d77069edff28ce0




(Optional) Configure a DNS alias for the master. The alias could be a DNS cname (if the machine already has an A record in DNS), an A record (if the machine
is only known by its IP address), or an alias in /etc/hosts. The alias should be an abstract representation of the master (e.g. master-1).
Important: Without DNS aliases, it is not possible to recover from permanent master failures without bringing the cluster down for
maintenance. t is highly recommended that you use DNS aliases.



If you have Kudu tables that are accessed from Impala, you must update the master addresses in the Apache Hive Metastore (HMS) database.

If you set up the DNS aliases, run the following statement in impala-shell, replacing master-1, master-2, and master-3 with your actual aliases.
ALTER TABLE table_name
SET TBLPROPERTIES
('kudu.master_addresses' = 'master-1,master-2,master-3');
If you do not have DNS aliases set up, see Step #11 in the Performing the migration section for updating HMS.


Perform the following preparatory steps for each new master:


Choose an unused machine in the cluster. The master generates very little load so it can be collocated with other data services or load-generating processes, though not with another Kudu
master from the same configuration.


Ensure Kudu is installed on the machine, either using system packages (in which case the kudu and kudu-master packages
should be installed), or some other means.


Choose and record the directory where the masterâs data will live.


Choose and record the port the master should use for RPCs.


(Optional) Configure a DNS alias for the master (e.g. master-2, master-3, etc).







Perform the migration


Stop all the Kudu processes in the entire cluster.
Format the data directory on each new master machine, and record the generated UUID. Use the following commands:
$ sudo -u kudu kudu fs format --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>]
$ sudo -u kudu kudu fs dump uuid --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] 2>/dev/null

master_data_dir

The new masterâs previously recorded data directory.
For example:
$ sudo -u kudu kudu fs format --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data
sudo -u kudu kudu fs dump uuid --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data 2>/dev/null
f5624e05f40649b79a757629a69d061e



If you are using Cloudera Manager, add the new Kudu master roles now, but do not start them.


If using DNS aliases, override the empty value of the Master Address parameter for each role (including the existing master role) with that masterâs
alias.


Add the port number (separated by a colon) if using a non-default RPC port value.



Rewrite the masterâs Raft configuration with the following command, executed on the existing master:
$ sudo -u kudu kudu local_replica cmeta rewrite_raft_config --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] <tablet_id> <all_masters>

master_data_dir

The existing masterâs previously recorded data directory

tablet_id

This must be set to the string, 00000000000000000000000000000000.

all_masters

A space-separated list of masters, both new and existing. Each entry in the list must be a string of the form <uuid>:<hostname>:<port>.

uuid

The masterâs previously recorded UUID.

hostname

The masterâs previously recorded hostname or alias.

port

The masterâs previously recorded RPC port number.



For example:

$ sudo -u kudu kudu local_replica cmeta rewrite_raft_config --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data 00000000000000000000000000000000 4aab798a69e94fab8d77069edff28ce0:master-1:7051 f5624e05f40649b79a757629a69d061e:master-2:7051 988d8ac6530f426cbe180be5ba52033d:master-3:7051

Important: If you are using Cloudera Manager, skip the next step.

Modify the value of the master_addresses configuration parameter for both existing master and new masters. The new value must be a comma-separated list
of all of the masters. Each entry is a string of the form, <hostname>:<port>.

hostname

The master's previously recorded hostname or alias.

port

The master's previously recorded RPC port number.



Start the existing master.
Copy the master data to each new master with the following command, executed on each new master machine.
Important: If your Kudu cluster is secure, in addition to running as the Kudu UNIX user, you must authenticate as the Kudu service user prior
to running this command.
$ sudo -u kudu kudu local_replica copy_from_remote --fs_wal_dir=<master_data_dir> <tablet_id> <existing_master>

master_data_dir

The new master's previously recorded data directory.

tablet_id

Must be set to the string, 00000000000000000000000000000000.

existing_master

RPC address of the existing master. It must be a string of the form <hostname>:<port>.

hostname

The existing master's previously recorded hostname or alias.

port

The existing master's previously recorded RPC port number.



Example

$ sudo -u kudu kudu local_replica copy_from_remote --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data  00000000000000000000000000000000 master-1:7051


Start all the new masters.
Important: If you are using Cloudera Manager, skip the next step.

Modify the value of the tserver_master_addrs configuration parameter for each tablet server. The new value must be a comma-separated list of masters
where each entry is a string of the form <hostname>:<port>

hostname

The master's previously recorded hostname or alias

port

The master's previously recorded RPC port number



Start all the tablet servers.
If you have Kudu tables that are accessed from Impala and you didnât set up DNS aliases, update the HMS database manually in the underlying database that provides the storage for HMS.

The following is an example SQL statement you would run in the HMS database:
UPDATE TABLE_PARAMS
SET PARAM_VALUE =
  'master-1.example.com,master-2.example.com,master-3.example.com'
WHERE PARAM_KEY = 'kudu.master_addresses' AND PARAM_VALUE = 'old-master';
Invalidate the metadata by running the command in impala-shell:
INVALIDATE METADATA;



To verify that all masters are working properly, consider performing the following sanity checks:


Using a browser, visit each masterâs web UI and navigate to the /masters page. All the masters should now be listed there with one master in the
LEADER role and the others in the FOLLOWER role. The contents of /masters on each master should be the
same.


Run a Kudu system check (ksck) on the cluster using the kudu command line tool. For more details, see Monitoring Cluster Health with ksck.







Recovering from a Dead Kudu Master in a Multi-Master Deployment

Kudu multi-master deployments function normally in the event of a master loss. However, it is important to replace the dead master. Otherwise a second failure may lead to a loss of
availability, depending on the number of available masters. This workflow describes how to replace the dead master.
Due to KUDU-1620, it is not possible to perform this workflow without also restarting the live
masters. As such, the workflow requires a maintenance window, albeit a potentially brief one if the cluster was set up with DNS aliases.
Important:


Kudu does not yet support live Raft configuration changes for masters. As such, it is only possible to replace a master if the deployment was created with DNS aliases or if every node in
the cluster is first shut down. See the previous multi-master migration workflow for more details on
deploying with DNS aliases.


The workflow presupposes at least basic familiarity with Kudu configuration management. If using Cloudera Manager, the workflow also presupposes familiarity with it.


All of the command line steps below should be executed as the Kudu UNIX user, typically kudu.





Prepare for the recovery



If the cluster was configured without DNS aliases perform the following steps. Otherwise move on to step 2:

Establish a maintenance window (one hour should be sufficient). During this time the Kudu cluster will be unavailable.
Shut down all Kudu tablet server processes in the cluster.


Ensure that the dead master is well and truly dead. Take whatever steps needed to prevent it from accidentally restarting; this can be quite dangerous for the cluster
post-recovery.
Choose one of the remaining live masters to serve as a basis for recovery. The rest of this workflow will refer to this master as the "reference" master.
Choose an unused machine in the cluster where the new master will live. The master generates very little load so it can be co-located with other data services or load-generating
processes, though not with another Kudu master from the same configuration. The rest of this workflow will refer to this master as the "replacement" master.
Perform the following preparatory steps for the replacement master:


Ensure Kudu is installed on the machine, either via system packages (in which case the kudu and kudu-master packages should
be installed), or via some other means.


Choose and record the directory where the masterâs data will live.



Perform the following preparatory steps for each live master:


Identify and record the directory where the masterâs data lives. If using Kudu system packages, the default value is /var/lib/kudu/master, but it may be customized via the fs_wal_dir and fs_data_dirs configuration parameter. Please note if youâve set fs_data_dirs to some directories other
than the value of fs_wal_dir, it should be explicitly included in every command below where fs_wal_dir is also included. For more
information on configuring these directories, see the Kudu
Configuration docs.


Identify and record the masterâs UUID. It can be fetched using the following command:
$ sudo -u kudu kudu fs dump uuid --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] 2>/dev/null

master_data_dir

live masterâs previously recorded data directory

Example

$ sudo -u kudu kudu fs dump uuid --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data 2>/dev/null
80a82c4b8a9f4c819bab744927ad765c




Perform the following preparatory steps for the reference master:


Identify and record the directory where the masterâs data lives. If using Kudu system packages, the default value is /var/lib/kudu/master, but it may be
customized using the fs_wal_dir and fs_data_dirs configuration parameter. If you have set fs_data_dirs to
some directories other than the value of fs_wal_dir, it should be explicitly included in every command below where fs_wal_dir is also
included. For more information on configuring these directories, see the Kudu Configuration docs.


Identify and record the UUIDs of every master in the cluster, using the following command:
$ sudo -u kudu kudu local_replica cmeta print_replica_uuids --fs_wal_dir=<master_data_dir> <tablet_id> 2>/dev/null

master_data_dir

The reference masterâs previously recorded data directory.

tablet_id

Must be set to the string, 00000000000000000000000000000000.

For example

$ sudo -u kudu kudu local_replica cmeta print_replica_uuids --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data  00000000000000000000000000000000 2>/dev/null
80a82c4b8a9f4c819bab744927ad765c 2a73eeee5d47413981d9a1c637cce170 1c3f3094256347528d02ec107466aef3




Using the two previously-recorded lists of UUIDs (one for all live masters and one for all masters), determine and record (by process of elimination) the UUID of the dead master.





Perform the recovery


Format the data directory on the replacement master machine using the previously recorded UUID of the dead master. Use the following command sequence:
$ sudo -u kudu kudu fs format --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] --uuid=<uuid>

master_data_dir

The replacement masterâs previously recorded data directory.

uuid

The dead masterâs previously recorded UUID.

For example:

$ sudo -u kudu kudu fs format --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data --uuid=80a82c4b8a9f4c819bab744927ad765c


Copy the master data to the replacement master with the following command.
Important: If your Kudu cluster is secure, in addition to running as the Kudu UNIX user, you must authenticate as the Kudu service user prior
to running this command.
$ sudo -u kudu kudu local_replica copy_from_remote --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] <tablet_id> <reference_master>

master_data_dir

The replacement masterâs previously recorded data directory.

tablet_id

Must be set to the string, 00000000000000000000000000000000.

reference_master

The RPC address of the reference master. It must be a string of the form <hostname>:<port>.

hostname

The reference masterâs previously recorded hostname or alias.

port

The reference masterâs previously recorded RPC port number.



For example:

$ sudo -u kudu kudu local_replica copy_from_remote --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data 00000000000000000000000000000000 master-2:7051


If you are using Cloudera Manager, add the replacement Kudu master role now, but do not start it.


Override the empty value of the Master Address parameter for the new role with the replacement masterâs alias.


If you are using a non-default RPC port, add the port number (separated by a colon) as well.



If the cluster was set up with DNS aliases, reconfigure the DNS alias for the dead master to point at the replacement master.
If the cluster was set up without DNS aliases, perform the following steps:

Stop the remaining live masters.
Rewrite the Raft configurations on these masters to include the replacement master. See Step 4 of Perform the Migration for more details.


Start the replacement master.
Restart the remaining masters in the new multi-master deployment. While the masters are shut down, there will be an availability outage, but it should last only as long as it takes for
the masters to come back up.

To verify that all masters are working properly, consider performing the following sanity checks:


Using a browser, visit each masterâs web UI and navigate to the /masters page. All the masters should now be listed there with one master in the
LEADER role and the others in the FOLLOWER role. The contents of /masters on each master should be the
same.


Run a Kudu system check (ksck) on the cluster using the kudu command line tool. For more details, see Monitoring Cluster Health with ksck.







Removing Kudu Masters from a Multi-Master Deployment

In the event that a multi-master deployment has been overallocated nodes, the following steps should be taken to remove the unwanted masters.
Important:

In planning the new multi-master configuration, keep in mind that the number of masters should be odd and that three or five node master configurations are recommended.
Dropping the number of masters below the number of masters currently needed for a Raft majority can incur data loss. To mitigate this, ensure that the leader master is not removed
during this process.





Prepare for removal


Establish a maintenance window (one hour should be sufficient). During this time the Kudu cluster will be unavailable.
Identify the UUID and RPC address current leader of the multi-master deployment by visiting the /masters page of any masterâs web UI. This master must
not be removed during this process; its removal may result in severe data loss.
Stop all the Kudu processes in the entire cluster.
If you are using Cloudera Manager, remove the unwanted Kudu master from your cluster's Kudu service.




Perform the removal


Rewrite the Raft configuration on the remaining masters to include only the remaining masters. See Step 4 of Perform the Migration for more details.
Remove the data directories and WAL directory on the unwanted masters. This is a precaution to ensure that they cannot start up again and interfere with the new multi-master
deployment.
Modify the value of the master_addresses configuration parameter for the masters of the new multi-master deployment. See Kudu Configuration docs for the steps to modify a configuration parameter. If
migrating to a single-master deployment, the master_addresses flag should be omitted entirely.
Start all of the masters that were not removed.
Important: If you are using Cloudera Manager, skip the next step.

Modify the value of the tserver_master_addrs configuration parameter for the tablet servers to remove any unwanted masters. See Kudu Configuration docs for the steps to modify a configuration parameter.
Start all of the tablet servers.

To verify that all masters are working properly, consider performing the following sanity checks:


Using a browser, visit each masterâs web UI and navigate to the /masters page. All the masters should now be listed there with one master in the
LEADER role and the others in the FOLLOWER role. The contents of /masters on each master should be the
same.


Run a Kudu system check (ksck) on the cluster using the kudu command line tool. For more details, see Monitoring Cluster Health with ksck.







Changing Master Hostnames

When replacing dead masters, use DNS aliases to prevent long maintenance windows. If the cluster was set up without aliases, change the host names as described in this section.


Prepare for Hostname Changes

To prepare to change a hostname:

Establish a maintenance window during which the Kudu cluster will be unavailable. One hour should be sufficient.
On the Masters page in Kudu Web UI, note the UUID and RPC address of each master.
Stop all the Kudu processes in the cluster.
Set up the new hostnames to point to the masters and verify all servers and clients properly resolve them.




Perform Hostname Changes

To change hostnames:

Rewrite each masterâs Raft configuration with the following command, executed on each master host:
$ sudo -u kudu kudu local_replica cmeta rewrite_raft_config --fs_wal_dir=<master_wal_dir> [--fs_data_dirs=<master_data_dir>] 00000000000000000000000000000000 <all_masters>
For example:
$ sudo -u kudu kudu local_replica cmeta rewrite_raft_config --fs_wal_dir=/data/kudu/master/wal --fs_data_dirs=/data/kudu/master/data 00000000000000000000000000000000 4aab798a69e94fab8d77069edff28ce0:new-master-name-1:7051 f5624e05f40649b79a757629a69d061e:new-master-name-2:7051 988d8ac6530f426cbe180be5ba52033d:new-master-name-3:7051
Update the master address:

In an environment not managed by Cloudera Manager, change the gflag file of the masters so the master_addresses parameter
reflects the new hostnames.
In an environment managed by Cloudera Manager, specify the new hostname in the Master Address (server.address) field on each Kudu role.


Change the gflag file of the tablet servers to update the tserver_master_addrs parameter with the new hostnames. In an
environment managed by Cloudera Manager, this step is not needeed.
Start the masters.
To verify that all masters are working properly, perform the following sanity checks:

In each masterâs Web UI, click Masters on the Status Pages. All of the masters should be listed there with one master in the LEADER role field and the others in the FOLLOWER role field. The contents of Masters on all master should be the same.
Run the below command to verify all masters are up and listening. The UUIDs are the same and belong to the same master as before the hostname change:
$ sudo -u kudu kudu master list new-master-name-1:7051,new-master-name-2:7051,new-master-name-3:7051


Start all of the tablet servers.
Run a Kudu system check (ksck) on the cluster using the kudu command line tool. See Monitoring Cluster Health with ksck for more details. After startup, some tablets may be unavailable as it takes some time to initialize all of them.
If you have Kudu tables that are accessed from Impala, update the HMS database manually in the underlying database that provides the storage for HMS.

The following is an example SQL statement you run in the HMS database:
UPDATE TABLE_PARAMSSET PARAM_VALUE =
'new-master-name-1:7051,new-master-name-2:7051,new-master-name-3:7051'
WHERE PARAM_KEY = 'kudu.master_addresses'
AND PARAM_VALUE = 'master-1:7051,master-2:7051,master-3:7051';

In impala-shell, run:
INVALIDATE METADATA;
Verify updating the metadata worked by running a simple SELECT query on a Kudu-backed Impala table.







Best Practices when Adding New Tablet Servers

A common workflow when administering a Kudu cluster is adding additional tablet server instances, in an effort to increase storage capacity, decrease load or utilization on individual
hosts, increase compute power, and more.
By default, any newly added tablet servers will not be utilized immediately after their addition to the cluster. Instead, newly added tablet servers will only be utilized when new
tablets are created or when existing tablets need to be replicated, which can lead to imbalanced nodes. It's recommended to run the rebalancer CLI tool just after adding a new tablet server into the
cluster.
Avoid placing multiple tablet servers on a single node. Doing so nullifies the point of increasing the overall storage capacity of a Kudu cluster and increases the likelihood of tablet
unavailability when a single node fails (the latter drawback is not applicable if the cluster is properly configured to use the Rack
Awareness (Location Awareness) feature.
To add additional tablet servers to an existing cluster, the following steps can be taken to ensure tablet replicas are uniformly distributed across the cluster:

Ensure that Kudu is installed on the new machines being added to the cluster, and that the new instances have been correctly configured to point to the pre-existing cluster. Then,
start the new tablet server instances.
Verify that the new instances check in with the Kudu Master(s) successfully. A quick method for verifying whether they have successfully checked in with the existing Master instances
is to view the Kudu Master WebUI, specifically the /tablet-servers section, and validate that the newly added instances are registered, and have a heartbeat.
Once the tablet server(s) are successfully online and healthy, follow the steps to run the rebalancing tool
which spreads the existing tablet replicas to the newly added tablet servers.
After the rebalancer tool has completed, or even during its execution, you can check the health of the cluster using the ksck command-line utility.





Monitoring Cluster Health with ksck

The kudu CLI includes a tool called ksck that can be used for gathering information about the state of a Kudu cluster,
including checking its health. ksck will identify issues such as under-replicated tablets, unreachable tablet servers, or tablets without a leader.
ksck should be run from the command line as the Kudu admin user, and requires the full list of master addresses to be specified:
$ sudo -u kudu kudu cluster ksck master-01.example.com,master-02.example.com,master-03.example.com
To see a full list of the options available with ksck, use the --help flag. If the cluster is healthy, ksck will print information about the cluster, a success message, and return a zero (success) exit status.
Master Summary
               UUID               |       Address         | Status
----------------------------------+-----------------------+---------
 a811c07b99394df799e6650e7310f282 | master-01.example.com | HEALTHY
 b579355eeeea446e998606bcb7e87844 | master-02.example.com | HEALTHY
 cfdcc8592711485fad32ec4eea4fbfcd | master-02.example.com | HEALTHY

Tablet Server Summary
               UUID               |        Address         | Status
----------------------------------+------------------------+---------
 a598f75345834133a39c6e51163245db | tserver-01.example.com | HEALTHY
 e05ca6b6573b4e1f9a518157c0c0c637 | tserver-02.example.com | HEALTHY
 e7e53a91fe704296b3a59ad304e7444a | tserver-03.example.com | HEALTHY

Version Summary
 Version |      Servers
---------+-------------------------
  1.7.1  | all 6 server(s) checked

Summary by table
   Name   | RF | Status  | Total Tablets | Healthy | Recovering | Under-replicated | Unavailable
----------+----+---------+---------------+---------+------------+------------------+-------------
 my_table | 3  | HEALTHY | 8             | 8       | 0          | 0                | 0

                | Total Count
----------------+-------------
 Masters        | 3
 Tablet Servers | 3
 Tables         | 1
 Tablets        | 8
 Replicas       | 24
OK
If the cluster is unhealthy, for instance if a tablet server process has stopped, ksck will report the issue(s) and return a non-zero exit status, as shown
in the abbreviated snippet of ksck output below:
Tablet Server Summary
               UUID               |        Address         |   Status
----------------------------------+------------------------+-------------
 a598f75345834133a39c6e51163245db | tserver-01.example.com | HEALTHY
 e05ca6b6573b4e1f9a518157c0c0c637 | tserver-02.example.com | HEALTHY
 e7e53a91fe704296b3a59ad304e7444a | tserver-03.example.com | UNAVAILABLE
Error from 127.0.0.1:7150: Network error: could not get status from server: Client connection negotiation failed: client connection to 127.0.0.1:7150: connect: Connection refused (error 61) (UNAVAILABLE)

... (full output elided)

------------------
Errors:
------------------
Network error: error fetching info from tablet servers: failed to gather info for all tablet servers: 1 of 3 had errors
Corruption: table consistency check error: 1 out of 1 table(s) are not healthy

FAILED
Runtime error: ksck discovered errors
To verify data integrity, the optional --checksum_scan flag can be set, which will ensure the cluster has consistent data by scanning each tablet replica
and comparing results. The --tables or --tablets flags can be used to limit the scope of the checksum scan to specific tables or tablets,
respectively.
For example, checking data integrity on the my_table table can be done with the following command:
$ sudo -u kudu kudu cluster ksck --checksum_scan --tables my_table master-01.example.com,master-02.example.com,master-03.example.com
By default, ksck will attempt to use a snapshot scan of the table, so the checksum scan can be done while writes continue.
Finally, ksck also supports output in JSON format using the --ksck_format flag. JSON output contains the same information as
the plain text output, but in a format that can be used by other tools. See kudu cluster ksck --help for more information.



Changing Directory Configuration

For higher read parallelism and larger volumes of storage per server, you may want to configure servers to store data in multiple directories on different devices. Once a server is
started, you must go through the following steps to change the directory configuration.
You can add or remove data directories to an existing master or tablet server via the kudu fs update_dirs tool. Data is striped across data directories,
and when a new data directory is added, new data will be striped across the union of the old and new directories.
Note: Unless the --force flag is specified, Kudu will not allow for the removal of a directory across which tablets
are configured to spread data. If --force is specified, all tablets configured to use that directory will fail upon starting up and be replicated elsewhere.
Note: If the metadata directory
overlaps with a data directory, as was the default prior to Kudu 1.7, or if a non-default metadata directory is configured, the --fs_metadata_dir configuration must be
specified when running the kudu fs update_dirs tool.
Note: Only new tablet replicas, i.e. brand new tablets' replicas and replicas that are copied to the server for high availability, will use the new
directory. Existing tablet replicas on the server will not be rebalanced across the new directory.
Attention: All of the command line steps below should be executed as the Kudu UNIX user, typically kudu.

The tool can only run while the server is offline, so establish a maintenance window to update the server. The tool itself runs quickly, so this offline window should be brief, and as
such, only the server to update needs to be offline.
However, if the server is offline for too long (see the follower_unavailable_considered_failed_sec flag), the tablet replicas on it may be evicted from
their Raft groups. To avoid this, it may be desirable to bring the entire cluster offline while performing the update.

Run the tool with the desired directory configuration flags. For example, if a cluster was set up with --fs_wal_dir=/wals, ââfs_metadata_dir=/meta, and ââfs_data_dirs=/data/1,/data/2,/data/3, and /data/3 is to be removed (e.g. due to a disk
error), run the command:
$ sudo -u kudu kudu fs update_dirs --force --fs_wal_dir=/wals --fs_metadata_dir=/meta --fs_data_dirs=/data/1,/data/2
Modify the values of the fs_data_dirs flags for the updated sever. If using Cloudera Manager, make sure to only update the configurations of the updated
server, rather than of the entire Kudu service.
Once complete, the server process can be started. When Kudu is installed using system packages, service is typically used:
$ sudo service kudu-tserver start




Recovering from Disk Failure

Kudu nodes can only survive failures of disks on which certain Kudu directories are mounted. For more information about the different Kudu directory types, see the section on Directory Configurations.
The table below summarizes the resilience to disk failure in different releases of Apache Kudu.


Kudu Disk Failure Behavior


Node Type
Kudu Directory Type
Kudu Releases that Crash on Disk Failure




Master
All
All


Tablet Server
Directory containing WALs
All


Tablet Server
Directory containing tablet metadata
All


Tablet Server
Directory containing data blocks only
Pre-1.6.0





When a disk failure occurs that does not lead to a crash, Kudu will stop using the affected directory, shut down tablets with blocks on the affected directories, and automatically
re-replicate the affected tablets to other tablet servers. The affected server will remain alive and print messages to the log indicating the disk failure, for example:
E1205 19:06:24.163748 27115 data_dirs.cc:1011] Directory /data/8/kudu/data marked as failed
E1205 19:06:30.324795 27064 log_block_manager.cc:1822] Not using report from /data/8/kudu/data: IO error: Could not open container 0a6283cab82d4e75848f49772d2638fe: /data/8/kudu/data/0a6283cab82d4e75848f49772d2638fe.metadata: Read-only file system (error 30)
E1205 19:06:33.564638 27220 ts_tablet_manager.cc:946] T 4957808439314e0d97795c1394348d80 P 70f7ee61ead54b1885d819f354eb3405: aborting tablet bootstrap: tablet has data in a failed directory
While in this state, the affected node will avoid using the failed disk, leading to lower storage volume and reduced read parallelism. The administrator should schedule a brief window to
Changing Directory Configuration to exclude the failed disk.
When the disk is repaired, remounted, and ready to be reused by Kudu, take the following steps:

Make sure that the Kudu portion of the disk is completely empty.
Stop the tablet server.
Run the update_dirs tool. For example, to add /data/3, run the following:
$ sudo -u kudu kudu fs update_dirs --force --fs_wal_dir=/wals --fs_data_dirs=/data/1,/data/2,/data/3
Start the tablet server.
Run ksck to verify cluster health. For example:
$ sudo -u kudu kudu cluster ksck master-01.example.com

Note: Note that existing tablets will not stripe to the restored disk, but any new tablets will stripe to the restored disk.



Recovering from Full Disks

By default, Kudu reserves a small amount of space, 1% by capacity, in its directories. Kudu considers a disk full if there is less free space available than the reservation. Kudu nodes
can only tolerate running out of space on disks on which certain Kudu directories are mounted. For more information about the different Kudu directory types, see Directory Configurations. The table below describes this behavior for each type of directory. The behavior is uniform across masters and tablet
servers.



Kudu Directory Type
Crash on Full Disk?


Directory containing WALs
Yes


Directory containing tablet metadata
Yes


Directory containing data blocks only
No (see below)



Prior to Kudu 1.7.0, Kudu stripes tablet data across all directories, and will avoid writing data to full directories. Kudu will crash if all data directories are full.
In 1.7.0 and later, new tablets are assigned a disk group consisting of data directories. The number of data directories are as specified by the -fs_target_data_dirs_per_tablet flag with the default being 3. If Kudu is not configured with enough data directories for a full disk group, all data
directories are used. When a data directory is full, Kudu will stop writing new data to it and each tablet that uses that data directory will write new data to other data directories within its
group. If all data directories for a tablet are full, Kudu will crash. Periodically, Kudu will check if full data directories are still full, and will resume writing to those data directories if
space has become available.
If Kudu does crash because its data directories are full, freeing space on the full directories will allow the affected daemon to restart and resume writing. Note that it may be possible
for Kudu to free some space by running:
$ sudo -u kudu kudu fs check --repair
However, the above command may also fail if there is too little space left.
Itâs also possible to allocate additional data directories to Kudu in order to increase the overall amount of storage available. See the documentation on updating a nodeâs directory configuration for more information. Note that existing tablets will not use new data directories, so adding a
new data directory does not resolve issues with full disks.



Bringing a Tablet That Has Lost a Majority of Replicas Back Online

If a tablet has permanently lost a majority of its replicas, it cannot recover automatically and operator intervention is required. If the tablet servers hosting a majority of the
replicas are down (i.e. ones reported as "TS unavailable" by ksck), they should be recovered instead if possible.
Attention: The steps below may cause recent edits to the tablet to be lost, potentially resulting in permanent data loss. Only attempt the
procedure below if it is impossible to bring a majority back online.

Suppose a tablet has lost a majority of its replicas. The first step in diagnosing and fixing the problem is to examine the tablet's state using ksck:
$ sudo -u kudu kudu cluster ksck --tablets=e822cab6c0584bc0858219d1539a17e6 master-00,master-01,master-02
Connected to the Master
Fetched info from all 5 Tablet Servers
Tablet e822cab6c0584bc0858219d1539a17e6 of table 'my_table' is unavailable: 2 replica(s) not RUNNING
  638a20403e3e4ae3b55d4d07d920e6de (tserver-00:7150): RUNNING
  9a56fa85a38a4edc99c6229cba68aeaa (tserver-01:7150): bad state
    State:       FAILED
    Data state:  TABLET_DATA_READY
    Last status: <failure message>
  c311fef7708a4cf9bb11a3e4cbcaab8c (tserver-02:7150): bad state
    State:       FAILED
    Data state:  TABLET_DATA_READY
    Last status: <failure message>
This output shows that, for tablet e822cab6c0584bc0858219d1539a17e6, the two tablet replicas on tserver-01 and tserver-02 failed. The remaining replica is not the leader, so the leader replica failed as well. This means the chance of data loss is higher since the remaining replica on
tserver-00 may have been lagging. In general, to accept the potential data loss and restore the tablet from the remaining replicas, divide the tablet replicas into two
groups:

Healthy replicas: Those in RUNNING state as reported by ksck
Unhealthy replicas

For example, in the above ksck output, the replica on tablet server tserver-00 is healthy while the replicas on tserver-01 and tserver-02 are unhealthy. On each tablet server with a healthy replica, alter the consensus configuration to remove unhealthy
replicas. In the typical case of 1 out of 3 surviving replicas, there will be only one healthy replica, so the consensus configuration will be rewritten to include only the healthy replica.
$ sudo -u kudu kudu remote_replica unsafe_change_config tserver-00:7150 <tablet-id> <tserver-00-uuid>
where <tablet-id> is e822cab6c0584bc0858219d1539a17e6 and <tserver-00-uuid> is
the uuid of tserver-00, 638a20403e3e4ae3b55d4d07d920e6de.
Once the healthy replicas' consensus configurations have been forced to exclude the unhealthy replicas, the healthy replicas will be able to elect a leader. The tablet will become
available for writes though it will still be under-replicated. Shortly after the tablet becomes available, the leader master will notice that it is under-replicated, and will cause the tablet to
re-replicate until the proper replication factor is restored. The unhealthy replicas will be tombstoned by the master, causing their remaining data to be deleted.



Rebuilding a Kudu Filesystem Layout

In the event that critical files are lost, i.e. WALs or tablet-specific metadata, all Kudu directories on the server must be deleted and rebuilt to ensure correctness. Doing so will
destroy the copy of the data for each tablet replica hosted on the local server. Kudu will automatically re-replicate tablet replicas removed in this way, provided the replication factor is at least
three and all other servers are online and healthy.

Note: These steps use a tablet server as an example, but the steps are the same for Kudu master servers.

Warning: If multiple nodes need their FS layouts rebuilt, wait until all replicas previously hosted on each node have finished automatically
re-replicating elsewhere before continuing. Failure to do so can result in permanent data loss.
Attention: Before proceeding, ensure the contents of the directories are backed up, either as a copy or in the form of other tablet
replicas.


The first step to rebuilding a server with a new directory configuration is emptying all of the serverâs existing directories. For example, if a tablet server is configured with
--fs_wal_dir=/data/0/kudu-tserver-wal, --fs_metadata_dir=/data/0/kudu-tserver-meta, and --fs_data_dirs=/data/1/kudu-tserver,/data/2/kudu-tserver, the following commands will remove the WAL directoryâs and data directories' contents:
# Note: this will delete all of the data from the local tablet server.
$ rm -rf /data/0/kudu-tserver-wal/* /data/0/kudu-tserver-meta/* /data/1/kudu-tserver/* /data/2/kudu-tserver/*
If using Cloudera Manager, update the configurations for the rebuilt server to include only the desired directories. Make sure to only update the configurations of servers to which
changes were applied, rather than of the entire Kudu service.
After directories are deleted, the server process can be started with the new directory configuration. The appropriate sub-directories will be created by Kudu upon starting up.





Scaling Storage on Kudu Master and Tablet Servers in the Cloud

If you find that the size of your Kudu cloud deployment has exceeded previous expectations, or you simply wish to allocate more storage to Kudu, use the following set of high-level steps
as a guide to increasing storage on your Kudu master or tablet server hosts. You must work with your cluster's Hadoop administrators and the system administrators to complete this process. Replace
the file paths in the following steps to those relevant to your setup.


Run a consistency check on the cluster hosts. For instructions, see Monitoring Cluster Health with ksck.
On all Kudu hosts, create a new file system with the storage capacity you require. For example, /new/data/dir.
Shutdown cluster services. For a cluster managed by Cloudera Manager cluster, see Starting and Stopping a Cluster.
Copy the contents of your existing data directory, /current/data/dir, to the new filesystem at /new/data/dir.
Move your existing data directory, /current/data/dir, to a separate temporary location such as /tmp/data/dir.
Create a new /current/data/dir directory.
mkdir /current/data/dir
Mount /new/data/dir as /current/data/dir. Make changes to fstab as needed.
Perform steps 4-7 on all Kudu hosts.
Startup cluster services. For a cluster managed by Cloudera Manager cluster, see Starting and Stopping a Cluster.
Run a consistency check on the cluster hosts. For instructions, see Monitoring Cluster Health with ksck.
After 10 days, if everything is in working order on all the hosts, get approval from the Hadoop administrators to remove the /backup/data/dir
directory.






Migrating Kudu Data from One Directory to Another on the Same Host

Take the following steps to move the entire Kudu data from one directory to another.
Note:
The steps were verified on an environment where the master and the server instances were configured to write the WAL/Data to the same directory.


Stop the Kudu service.
Modify the directory configurations for the Master/Server instances.
Move the existing data from the old directory, to the new one.
Make sure the file/directory ownership is set to the kudu user.
Restart the Kudu service.
Run ksck and verify for the healthy status.




Minimizing Cluster Disruption During Temporary Planned Downtime of a Single Tablet Server

If a single tablet server is brought down temporarily in a healthy cluster, all tablets will remain available and clients will function as normal, after potential short delays due to
leader elections. However, if the downtime lasts for more than --follower_unavailable_considered_failed_sec (default 300) seconds, the tablet replicas on the down
tablet server will be replaced by new replicas on available tablet servers. This will cause stress on the cluster as tablets re-replicate and, if the downtime lasts long enough, significant reduction
in the number of replicas on the down tablet server. This may require the rebalancer to fix.
To work around this, in Kudu versions 1.11 onward, the kudu CLI contains a tool to put tablet servers into maintenance mode. While in this state, the
tablet serverâs replicas are not re-replicated due to its downtime alone, though re-replication may still occur in the event that the server in maintenance suffers from a disk failure or if a
follower replica on the tablet server falls too far behind its leader replica. Upon exiting maintenance, re-replication is triggered for any remaining under-replicated tablets.
The kudu tserver state enter_maintenance and kudu tserver state exit_maintenance tools are added to orchestrate tablet
server maintenance. The following can be run from a tablet server to put it into maintenance:
$ TS_UUID=$(sudo -u kudu kudu fs dump uuid --fs_wal_dir=<wal_dir> --fs_data_dirs=<data_dirs>)
$ sudo -u kudu kudu tserver state enter_maintenance <master_addresses> "$TS_UUID"
The tablet server maintenance mode is shown in the "Tablet Servers" page of the Kudu leader master's web UI, and in the output of kudu cluster ksck. To
exit maintenance mode, run the following command:
sudo -u kudu kudu tserver state exit_maintenance <master_addresses> "$TS_UUID"
In versions prior to 1.11, a different approach must be used to prevent unwanted re-replication. Increase --follower_unavailable_considered_failed_sec on
all tablet servers so the amount of time before re-replication starts is longer than the expected downtime of the tablet server, including the time it takes the tablet server to restart and bootstrap
its tablet replicas. To do this, run the following command for each tablet server:
$ sudo -u kudu kudu tserver set_flag <tserver_address> follower_unavailable_considered_failed_sec <num_seconds>
where <num_seconds> is the number of seconds that will encompass the downtime. Once the downtime is finished,
reset the flag to its original value.
$ sudo -u kudu kudu tserver set_flag <tserver_address> follower_unavailable_considered_failed_sec <original_value>
Attention: Be sure to reset the value of --follower_unavailable_considered_failed_sec to its original
value.
On Kudu versions prior to 1.8, the --force flag must be provided in the above set_flag commands.



Running Tablet Rebalancing Tool

The kudu CLI contains a rebalancing tool that can be used to rebalance tablet replicas among tablet servers. For each table, the tool attempts to balance
the number of replicas per tablet server. It will also, without unbalancing any table, attempt to even out the number of replicas per tablet server across the cluster as a whole.
The rebalancing tool should be run as the Kudu admin user, specifying all master addresses:
sudo -u kudu kudu cluster rebalance master-01.example.com,master-02.example.com,master-03.example.com
When run, the rebalancer will report on the initial tablet replica distribution in the cluster, log the replicas it moves, and print a final summary of the distribution when it
terminates:
Per-server replica distribution summary:
       Statistic       |   Value
-----------------------+-----------
 Minimum Replica Count | 0
 Maximum Replica Count | 24
 Average Replica Count | 14.400000

Per-table replica distribution summary:
 Replica Skew |  Value
--------------+----------
 Minimum      | 8
 Maximum      | 8
 Average      | 8.000000

I0613 14:18:49.905897 3002065792 rebalancer.cc:779] tablet e7ee9ade95b342a7a94649b7862b345d: 206a51de1486402bbb214b5ce97a633c -> 3b4d9266ac8c45ff9a5d4d7c3e1cb326 move scheduled
I0613 14:18:49.917578 3002065792 rebalancer.cc:779] tablet 5f03944529f44626a0d6ec8b1edc566e: 6e64c4165b864cbab0e67ccd82091d60 -> ba8c22ab030346b4baa289d6d11d0809 move scheduled
I0613 14:18:49.928683 3002065792 rebalancer.cc:779] tablet 9373fee3bfe74cec9054737371a3b15d: fab382adf72c480984c6cc868fdd5f0e -> 3b4d9266ac8c45ff9a5d4d7c3e1cb326 move scheduled

... (full output elided)

I0613 14:19:01.162802 3002065792 rebalancer.cc:842] tablet f4c046f18b174cc2974c65ac0bf52767: 206a51de1486402bbb214b5ce97a633c -> 3b4d9266ac8c45ff9a5d4d7c3e1cb326 move completed: OK

rebalancing is complete: cluster is balanced (moved 28 replicas)
Per-server replica distribution summary:
       Statistic       |   Value
-----------------------+-----------
 Minimum Replica Count | 14
 Maximum Replica Count | 15
 Average Replica Count | 14.400000

Per-table replica distribution summary:
 Replica Skew |  Value
--------------+----------
 Minimum      | 1
 Maximum      | 1
 Average      | 1.000000

If more details are needed in addition to the replica distribution summary, use the --output_replica_distribution_details flag. If added, the flag makes
the tool print per-table and per-tablet server replica distribution statistics as well.
Use the --report_only flag to get a report on table-wide and cluster-wide replica distribution statistics without starting any rebalancing activity.
The rebalancer can also be restricted to run on a subset of the tables by supplying the --tables flag. Note that, when running on a subset of tables, the
tool will not attempt to balance the cluster as a whole.
The length of time rebalancing is run for can be controlled with the flag --max_run_time_sec. By default, the rebalancer will run until the cluster is
balanced. To control the amount of resources devoted to rebalancing, modify the flag --max_moves_per_server. See kudu cluster rebalance
--help for more.
It's safe to stop the rebalancer tool at any time. When restarted, the rebalancer will continue rebalancing the cluster.
The rebalancer tool requires all registered tablet servers to be up and running to proceed with the rebalancing process in order to avoid possible conflicts and races with the automatic
re-replication and to keep replica placement optimal for current configuration of the cluster. If a tablet server becomes unavailable during the rebalancing session, the rebalancer will exit. As
noted above, it's safe to restart the rebalancer after resolving the issue with unavailable tablet servers.
The rebalancing tool can rebalance Kudu clusters running older versions as well, with some restrictions. Consult the following table for more information. In the table, "RF" stands for
"replication factor".





Version Range
Rebalances RF = 1 Tables?
Rebalances RF > 1 Tables?




v < 1.4.0
No
No


1.4.0 <= v < 1.7.1
No
Yes


v >= 1.7.1
Yes
Yes





If the rebalancer is running against a cluster where rebalancing replication factor one tables is not supported, it will rebalance all the other tables and the cluster as if those
singly-replicated tables did not exist.


Running Tablet Rebalancing Tool on Rack-Aware Cluster

As detailed in the Rack Awareness (Location Awareness) section, itâs possible to use the kuduÂ clusterÂ rebalance tool to establish the placement policy on a cluster. This might be necessary when the rack awareness feature is first configured or when
re-replication violated the placement policy. The rebalancing tool breaks its work into three phases:

The rack-aware rebalancer tries to establish the placement policy. Use the ââdisable_policy_fixer flag to skip this phase.
The rebalancer tries to balance load by location, moving tablet replicas between locations in an attempt to spread tablet replicas among locations evenly. The load of a location is
measured as the total number of replicas in the location divided by the number of tablet servers in the location. Use the ââdisable_cross_location_rebalancing flag to
skip this phase.
The rebalancer tries to balance the tablet replica distribution within each location, as if the location were a cluster on its own. Use the ââdisable_intra_location_rebalancing flag to skip this phase.

By using the ââreport_only flag, itâs also possible to check if all tablets in the cluster conform to the placement policy without attempting any replica
movement.



Running Tablet Rebalancing Tool in Cloudera Manager

To run the tablet rebalancer tool in Cloudera Manager:

Browse to Clusters > Kudu.
Click Actions and select Run Kudu Rebalancer Tool.

In Cloudera Manager, the rebalancer runs with the default flags.




Decommissioning or Permanently Removing a Tablet Server From a Cluster

Kudu does not currently support an automated way to remove a tablet server from a cluster permanently. Use the following steps to manually remove a tablet server:

Ensure the cluster is in good health using ksck. See Checking Cluster Health with ksck.
If the tablet server contains any replicas of tables with replication factor 1, these replicas must be manually moved off the tablet server prior to shutting it down. Use the
kudu tablet change_config move_replica tool for this.
Shut down the tablet server. After -follower_unavailable_considered_failed_sec, which defaults to 5 minutes, Kudu will begin to re-replicate the tablet
serverâs replicas to other servers. Wait until the process is finished. Progress can be monitored using ksck.
Once all the copies are complete, ksck will continue to report the tablet server as unavailable. The cluster will otherwise operate fine without the
tablet server. To completely remove it from the cluster so ksck shows the cluster as completely healthy, restart the masters. In the case of a single master, this will
cause cluster downtime. With multi-master, restart the masters in sequence to avoid cluster downtime.

Important: Do not shut down multiple tablet servers at once. To remove multiple tablet servers from the cluster, follow the above instructions
for each tablet server, ensuring that the previous tablet server is removed from the cluster and ksck is healthy before shutting down the next.



Using cluster names in the kudu command line tool

When using the kudu command line tool, it can be difficult to remember the precise list of Kudu master RPC addresses needed to communicate with a cluster,
especially when managing multiple clusters. As an alternative, the command line tool can identify clusters by name. To use this functionality:

Create a new directory to store the Kudu configuration file.
Export the path to this directory in the KUDU_CONFIGenvironment variable.
Create a file called kudurc in the new directory.
Populate kudurc as follows, substituting your own cluster names and RPC addresses:
clusters_info:
  cluster_name1:
    master_addresses: ip1:port1,ip2:port2,ip3:port3
  cluster_name2:
    master_addresses: ip4:port4
When using the kudu command line tool, replace the list of Kudu master RPC addresses with the cluster name, prepended with the character @.
$ sudo -u kudu kudu ksck @cluster_name1
Note: Cluster names may be used as input in any invocation of the kudu command line tool that expects a list of Kudu
master RPC addresses.





Categories: Administrators | Kudu | All Categories



Configuration


Developing Applications with Kudu


















About Cloudera
Resources
Contact
Careers
Press
Documentation

United States: +1 888 789 1488
Outside the US: +1 650 362 0488



Â© 2021 Cloudera, Inc. All rights reserved. Apache Hadoop and associated open source project names are trademarks of the Apache Software Foundation. For a complete list of trademarks, click here.
If this documentation includes code, including but not limited to, code examples, Cloudera makes this available to you under the terms of the Apache License, Version 2.0, including any required
notices. A copy of the Apache License Version 2.0 can be found here.










Terms & ConditionsÂ  | Â Privacy Policy

Page generated SeptemberÂ 29,Â 2021.












