Distributed Computing with WorkersCloudera Docs
Distributed Computing with Workers
Cloudera Machine Learning provides basic support for
    launching multiple engine instances, known as workers, from a single
    interactive session. Any R or Python session can be used to spawn workers.
    These workers can be configured to run a script (e.g. a Python file) or a
    command when they start up. 
Workers can be launched using the launch_workers
      function. Other supported functions are list_workers and
      stop_workers. Output from all the workers is displayed
      in the workbench console of the session that launched them. These workers
      are terminated when the session exits.
Using Workers for Machine Learning
The simplest example of using this feature would involve launching
      multiple workers from a session, where each one prints 'hello world' and
      then terminates right after. To extend this example, you can remove the
      print command and configure the workers to run a more elaborate script
      instead. For example, you can set up a queue of parameters (inputs to a
      function) in your main interactive session, and then configure the workers
      to run a script that pulls parameters off the queue, applies a function,
      and keeps doing this until the parameter queue is empty. This generic idea
      can be applied to multiple real-world use-cases. For example, if the queue
      is a list of URLs and the workers apply a function that scrapes a URL and
      saves it to a database, CML can easily be used to do parallelized web
      crawling.
Hyperparameter optimization is a common task in machine learning, and
      workers can use the same parameter queue pattern described above to
      perform this task. In this case, the parameter queue would be a list of
      possible values of the hyperparameters of a machine learning model. Each
      worker would apply a function that trains a machine learning model. The
      workers run until the queue is empty, and save snapshots of the model and
      its performance. 

Workers APIThis section lists the functions available as part of the workers     API.Worker Network CommunicationThis section demonstrates some trivial     examples of how two worker engines communicate with the master     engine.