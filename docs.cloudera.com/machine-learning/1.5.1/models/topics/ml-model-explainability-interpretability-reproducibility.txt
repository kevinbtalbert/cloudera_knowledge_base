Model explainability, interpretability, and reproducibilityCloudera Docs
Model explainability, interpretability, and reproducibility
Models are often seen as a black box: data goes in, something happens, and a prediction
    comes out. This lack of transparency is challenging on a number of levels and is often
    represented in loosely related terms explainability, interpretability, and
    reproducibility.

Explainability: Indicates the description of the internal mechanics of an Machine
        Learning (ML) model in human terms
Interpretability: Indicates the ability to:
Understand the relationship between model inputs, features and outputs
Predict the response to changes in inputs

Reproducibility: Indicates the ability to reproduce the output of a model in a
    consistent fashion for the same inputs

To solve these challenges, CML provides an end-to-end model governance and monitoring workflow
      that gives organizations increased visibility into their machine learning workflows and aims
      to eliminate the blackbox nature of most machine learning models.
The following image shows the end-to-end producltion ML workflow:Figure 1. Production ML Workflow



Parent topic: Challenges with model governance