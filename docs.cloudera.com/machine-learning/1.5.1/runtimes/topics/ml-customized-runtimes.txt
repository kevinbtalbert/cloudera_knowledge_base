Customized RuntimesCloudera Docs
Customized Runtimes
This topic explains how custom Runtimes work and when they should be used.
By
         default, Cloudera Machine Learning Runtimes are preloaded with a few
         common packages and libraries for R, Python, and Scala. In addition to these, Cloudera Machine Learning also allows you to install any other packages
         or libraries that are required by your projects. However, directly installing a package to
         a project as described above might not always be feasible. For example, packages that
         require root access to be installed, or that must be installed to a path outside /home/cdsw (outside the project mount), cannot
         be installed directly from the workbench. 
For such
         circumstances, Cloudera Machine Learning allows you to extend the base
         Docker image and create a new Docker image with all the libraries and packages you require.
         Site administrators can then add this new image in the allowlist for use in projects.
         
noteYou will need to remove any unnecessary Cloudera sources or repositories that are
         inaccessible because of the paywall.
PBJ Custom Runtimes can be built on top of any Ubuntu base image, and users have to install
         the kernel themselves. However, non-PBJ Runtime images can only be built on top of
         Cloudera-released non-PBJ Runtime images, and users cannot change the kernel.
Note that
         this approach can also be used to accelerate project setup across the deployment. For
         example, if you want multiple projects on your deployment to have access to some common
         dependencies (package or software or driver) out of the box, or even if a package just has
         a complicated setup, it might be easier to simply provide users with a Runtime that has
         already been customized for their project(s). 
Related Resources

The Cloudera Engineering Blog post on Customizing Docker Images in Cloudera Machine Learning describes an end-to-end example on
            how to build and publish a customized Docker image and use it as an engine in Cloudera Machine Learning.
For an example of how to extend the base engine image to include Conda, see
               Installing Additional Packages. 


Creating Customized ML RuntimesThis section walks you through the steps required to create your own custom ML       Runtimes based on one of the Cloudera provided ML Runtime images. LimitationsThis topic lists some limitations associated with customized ML Runtime images. Add Docker registry credentialsTo enable Cloudera Machine Learning to fetch custom engines from a   secure repository, as Administrator you need to add Docker registry credentials.