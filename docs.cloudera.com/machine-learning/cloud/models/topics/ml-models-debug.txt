Debugging Issues with ModelsCloudera Docs
Debugging Issues with Models

This topic describes some common issues to watch out for during
      different stages of the model build and deployment process.
As a general rule, if your model spends too long in any of the
      afore-mentioned stages, check the resource consumption statistics for the
      cluster. When the cluster starts to run out of resources, often models
      will spend some time in a queue before they can be executed.
Resource consumption by active models on a
      deployment can be tracked by site administrators on the
          Admin > 
          Models page. 
Building
Live progress for this stage can be tracked on the model's Build
        tab. It shows the details of the build process that creates a new Docker image for the
        model. Potential issues: 
If you specified a custom build script (cdsw-build.sh), ensure that
            the commands inside the script complete successfully. 
If you are in an environment with restricted network connectivity, you might need to
            manually upload dependencies to your project and install them from local files. 


Pushing
Once the model has been built, it is copied to an internal Docker
        registry to make it available to all the Cloudera Machine Learning
        hosts. Depending on network speeds, your model may spend some time in
        this stage.

Deploying
If you see issues occurring when Cloudera Machine Learning is
        attempting to start the model, use the following guidelines to begin troubleshooting:

Make sure your model code works in a workbench session. To do
              this, launch a new session, run your model file, and then
              interactively call your target function with the input object. For
              a simple example, see the Creating and Deploying a
                Model.


Ensure that you do not have any syntax errors. For Python, make sure you have the
              kernel with the appropriate Python version (Python 2 or Python 3) selected for the
              syntax you have used.


Make sure that your cdsw-build.sh file provides
              a complete set of dependencies. Dependencies manually installed
              during a session on the workbench are not carried over to your
              model. This is to ensure a clean, isolated, build for each model. 


If your model accesses resources such as data on the CDH cluster
              or an external database make sure that those resources can accept
              the load your model may exert on them.



Deployed
Once a model is up and running, you can track some basic logs and statistics on the model's
          Monitoring page. In case issues arise:

Check that you are handling bad input from users. If your function throws an
              exception, Cloudera Machine Learning will restart your model to attempt to get
              back to a known good state. The user will see an unexpected model shutdown error.
For most transient issues, model replicas will respond by restarting on their own
              before they actually crash. This auto-restart behavior should help keep the model
              online as you attempt to debug runtime issues.


Make runtime troubleshooting easier by printing errors and output to
                stderr and stdout. You can catch these on each
              model's Monitoring tab. Be careful not to log sensitive data
              here.


The Monitoring tab also displays the status of each replica
              and will show if the replica cannot be scheduled due to a lack of cluster resources.
              It will also display how many requests have been served/dropped by each replica.




Related informationEngines for Experiments and ModelsCreating and Deploying a ModelTechnical Metrics for Models