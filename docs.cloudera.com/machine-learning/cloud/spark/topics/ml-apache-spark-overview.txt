Apache Spark 2 and Spark 3 on CMLCloudera Docs
Apache Spark 2 and Spark 3 on CML

Apache Spark is a general purpose framework for distributed computing that offers high
      performance for both batch and stream processing. It exposes APIs for Java, Python, R, and
      Scala, as well as an interactive shell for you to run jobs.
In Cloudera Machine Learning (CML), Spark and its dependencies are bundled directly into the
      CML engine Docker image.
CML supports fully-containerized execution of Spark workloads via Spark's support for the
      Kubernetes cluster backend. Users can interact with Spark both interactively and in batch
      mode. 



Dependency Management: In both batch and interactive modes, dependency management,
      including for Spark executors, is transparently managed by CML and Kubernetes. No extra
      required configuration is required. In interactive mode, CML leverages your cloud provider for
      scalable project storage, and in batch mode, CML manages dependencies though container
      images.
Autoscaling: CML also supports native cloud autoscaling via Kubernetes. When clusters
      do not have the required capacity to run workloads, they can automatically scale up additional
      nodes. Administrators can configure auto-scaling upper limits, which determine how large a
      compute cluster can grow. Since compute costs increase as cluster size increases, having a way
      to configure upper limits gives administrators a method to stay within a budget. Autoscaling
      policies can also account for heterogeneous node types such as GPU nodes. 
Dynamic Resource Allocation: If a Spark job requires increasing memory or CPU
      resources as it executes a job, Spark can automatically increase the allocation of these
      resources. Likewise, the resources are automatically returned to the cluster when they are no
      longer needed. This mechanism is especially useful when multiple applications are sharing the
      resources of a cluster.
Workload Isolation: In CML, each project is owned by a user or team. Users can launch
      multiple sessions in a project. Workloads are launched within a separate Kubernetes namespace
      for each user, thus ensuring isolation between users at the K8s level.
Observability: Monitoring of Spark workloads, such as resources being consumed by
      Spark executors, can be performed using Grafana dashboards. For more information, see
      Monitoring and Alerts and Monitoring ML Workspaces.
     

Related informationMonitoring and AlertsMonitoring ML Workspaces