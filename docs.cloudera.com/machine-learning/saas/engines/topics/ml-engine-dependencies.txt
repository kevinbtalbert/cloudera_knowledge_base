Engine DependenciesCloudera Docs
Engine Dependencies
This topic describes the options available to you for mounting a
    project's dependencies into its engine environment. Depending on your
    projects or user preferences, one or more of these methods may be more
    appropriate for your deployment. 
importantEven though experiments and models are created within the scope of a
      project, the engines they use are completely isolated from those used by sessions or jobs
      launched within the same project. For details, see Engines for Experiments and
        Models.

Installing Packages Directly Within Projects



Creating a Customized Engine with the Required Package(s)


Directly installing a package to a project as described above might
            not always be feasible. For example, packages that require root
            access to be installed, or that must be installed to a path outside
              /home/cdsw (outside the project mount), cannot be
            installed directly from the workbench. For such circumstances,
            Cloudera recommends you extend the base Cloudera Machine Learning
            engine image to build a customized image with all the required
            packages installed to it. 
This approach can also be used to accelerate project setup across
            the deployment. For example, if you want multiple projects on your
            deployment to have access to some common dependencies out of the box
            or if a package just has a complicated setup, it might be easier to
            simply provide users with an engine environment that has already
            been customized for their project(s). 
For detailed instructions with an example, see Configuring
              the Engine Environment.

Managing Dependencies for Spark 2 Projects

With Spark projects, you can add external packages to Spark
            executors on startup. To add external dependencies to Spark jobs,
            specify the libraries you want added by using the appropriate
            configuration parameters in a
              spark-defaults.conf file. 
For a list of the relevant properties and examples, see Spark
              Configuration Files.

Managing Dependencies for Experiments and Models

To allow for versioned experiments and models,
            Cloudera Machine Learning executes each experiment and model in a
            completely isolated engine. Every time a model or experiment is
            kicked off, Cloudera Machine Learning creates a new isolated Docker
            image where the model or experiment is executed. These engines are
            built by extending the project's designated default engine image to
            include the code to be executed and any dependencies as specified. 
For details on how this process works and how to
            configure these environments, see Engines for Experiments and
              Models.



Related informationEngines for Experiments and ModelsInstalling Additional PackagesSpark Configuration FilesConfiguring the Engine Environment