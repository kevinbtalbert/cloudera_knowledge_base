Using the Spark shellCloudera Docs
Using the Spark shell
Using Spark, you can create an Iceberg table followed by schema evolution, partition
        specification, and partition evolution.
You must configure the Spark shell as such you have included the valid Spark runtime
            version. Run the following command in your Spark shell to create a new
                Iceberg table

spark.sql("CREATE TABLE spark_catalog.default.sample_1 ( id bigint
                        COMMENT 'unique id', data string) USING iceberg");

Navigate accordingly in the Atlas UI to view the changes.
The following images provide information about Iceberg table creation
                    process.










Run the following command in your Spark shell to create a Schema
                            Evolution in a new table. For example - sample_2.


spark.sql("CREATE TABLE spark_catalog.default.sample_2 ( id bigint COMMENT
                    'unique id', data string) USING iceberg"); 

Navigate accordingly in the Atlas UI to view the changes.

The following image provide information about Iceberg schema evolution
                    process.




Run the following command in your Spark shell to include a
                        column:


spark.sql("ALTER TABLE spark_catalog.default.sample_2 ADD COLUMN  (add_col_1
                    string )");

Navigate accordingly in the Atlas UI to view the changes. 

The following images provide information about Iceberg schema creation
                    process.







Run the following command in your Spark shell to include the second
                        column:


spark.sql("ALTER TABLE spark_catalog.default.sample_2 ADD COLUMN  (add_col_2
                    string )");

Navigate accordingly in the Atlas UI to view the changes. 

The following image provide information about Iceberg schema creation
                    process.




Run the following command in your Spark shell to create a
                            Partition Specification in a new table
                        (sample_3):


spark.sql("CREATE TABLE spark_catalog.default.sample_3 (id bigint,data
                    string,category string,ts timestamp) USING iceberg PARTITIONED BY (bucket(16,
                    id), days(ts), category)"); 

Navigate accordingly in the Atlas UI to view the changes. 

The following images provide information about Iceberg partition specification
                    process.




Run the following command in your Spark shell to create a
                        Partition Evolution in a new table (sample_3):

spark.sql("ALTER TABLE spark_catalog.default.sample_3 ADD PARTITION FIELD
                    years(ts)");

Navigate accordingly in the Atlas UI to view the changes. 

The following images provide information about Iceberg partition evolution
                    process.







