Setting up Atlas Kafka import toolCloudera Docs
Setting up Atlas Kafka import tool
You can use the Atlas-Kafka import tool to load Atlas with Kafka topics.
You must first set up the tool and later run the tool manually to create or update the
            Kafka topic entities in Atlas. The tool uses client configuration to fetch the required
            configuration, like the Atlas endpoint and Zookeeper.importantYou must run
                the tool on the Kafka node.
The Kafka type definition in Atlas contains multiple fields. The import tool fills out
            the following field values:


clusterName - Contains the value provided by the
                        atlas.metadata.namespace property in the application
                    configuration file. The default value is cm.


topic, name,
                        description, URI - Contains
                    the topic name.


qualifiedName - Contains the topic name and the
                        cluserName which is joined by ‘@’. For instance,
                        my-topic@cm. This serves as the unique identifier for
                    topics.


partitionCount - Displays the number of
                    partitions of the topic.


To set up the Atlas - Kafka import tool, follow these steps:

Select the Atlas service in Cloudera Manager.
Deploy client configs: Actions > Deploy Client
                    Configuration.noteIf kerberos authentication is enabled in Zookeeper, you must
                    run the tool as the Kafka kerberos user and set up the Ranger policies for the
                    Kafka user. 
If Ranger is enabled, create a Ranger policy with the user running the tool in
                    cm_atlas to allow the <user> to create, update,
                delete, and read Kafka entities:
Log into Ranger UI.
Navigate to cm_atlas policies.
Select the policy which has create_entity and
                            delete_entity permissions.
Add the kerberos user that is used with the import-kafka.sh
                        tool.

SSH into a host where the client configuration is deployed.
Run kinit as kafka if Kerberos is used to set up the Ticket Granting Ticket
                (TGT).
Set JAVA_HOME. noteUse export
                        JAVA_HOME=/usr/java/default in this scenario.
Run the command /opt/cloudera/parcels/CDH/lib/atlas/hook-bin/import-kafka.sh
                 to import Kafka topics into Atlas.


