ISR managementCloudera Docs
ISR management
Learn more about in-sync replica management.
An in-sync replica (ISR) set for a topic partition contains all follower replicas that are
      caught-up with the leader partition, and are situated on a broker that is alive. 

If a replica lags “too far” behind from the partition leader, it is removed from the ISR
        set. The definition of what is too far is controlled by the configuration setting
          replica.lag.time.max.ms. If a follower hasn't sent any fetch requests or
        hasn't consumed up to the leaders log end offset for at least this time, the leader removes
        the follower from the ISR set.
num.replica.fetchers is a cluster-wide configuration setting that
        controls how many fetcher threads are in a broker. These threads are responsible for
        replicating messages from a source broker (that is, where partition leader resides).
        Increasing this value results in higher I/O parallelism and fetcher throughput. Of course,
        there is a trade-off: brokers use more CPU and network.
replica.fetch.min.bytes controls the minimum number of bytes to fetch
        from a follower replica. If there is not enough bytes, wait up to
          replica.fetch.wait.max.ms.
replica.fetch.wait.max.ms controls how long to sleep before checking for
        new messages from a fetcher replica. This value should be less than
          replica.lag.time.max.ms, otherwise the replica is kicked out of the ISR
        set.
To check the ISR set for topic partitions, run the following command:
        kafka-topics --zookeeper ${ZOOKEEPER_HOSTNAME}:2181/kafka --describe --topic ${TOPIC}

If a partition leader dies, a new leader is selected from the ISR set. There will be no
        data loss. If there is no ISR, unclean leader election can be used with the risk of
        data-loss. 
Unclean leader election occurs if unclean.leader.election.enable is set
        to true. By default, this is set to false. 


Parent topic: Broker Tuning