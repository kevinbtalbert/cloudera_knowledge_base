Known Issues in HueCloudera Docs
Known Issues in Hue
Learn about the known issues in Hue, the impact or changes to the functionality, and
    the workaround.
Known issues in 7.2.17


CDPD-56888: Renaming a folder with special characters results in
            a duplicate folder with a new name on AWS S3. 
On AWS S3, if you try to rename a folder with special characters
            in its name, a new folder is created as a copy of the original folder with its contents.
            Also, you may not be able to delete the folder containing special characters.
You can rename or delete a directory having special
            characters using the HDFS commands as follows:
SSH into your CDP environment host.
To delete a directory within your S3 bucket, run the following
                command:hdfs dfs -rm -r [***COMPLETE-PATH-TO-S3-BUCKET***]/[***DIRECTORY-NAME***]
To rename a folder, create a new directory and run the following command to move
                files from the source directory to the target
                directory:hdfs dfs -mkdir [***DIRECTORY-NAME***]hdfs dfs -mv [***COMPLETE-PATH-TO-S3-BUCKET***]/[***SOURCE-DIRECTORY***] [***COMPLETE-PATH-TO-S3-BUCKET***]/[***TARGET-DIRECTORY***]



CDPD-48146: Error while browsing S3 buckets or ADLS containers
            from the left-assist panel
You may see the following error while trying to access the S3
            buckets or ADLS containers from the left-assist panel in Hue: Failed to
              retrieve buckets: :1:0: syntax error.
Access the S3 buckets or ADLS containers using the File
            Browser.


CDPD-54376: Clicking the home button on the File Browser page
            redirects to HDFS user directory
When you are previewing a file on any supported filesystem, such
            as S3 or ABFS, and you click on the Home button, you are
            redirected to the HDFS user home directory instead of the user home directory on the
            said filesystem.
None.



Known issues in 7.2.16


CDPD-54714: SSO does not work while logging in from the Hue
            UI
Due to a missing configuration in Cloudera Manager, SSO does not
            work when you have enabled Knox as an authentication backend and when Hue is in HA
            mode.
See Authenticating Hue users with Knox SSO.


CDPD-41136: Importing files from the local workstation is
            disabled by default
Cloudera has disabled the functionality to import files from
            your local workstation into Hue because it may cause errors. You may not see the Local
            File option in the Type drop-down menu on the Importer page by
            default.
You can enable the functionality to import files from your
            local workstation by specifying the following parameter in the Hue Service
              Advanced Configuration Snippet (Safety Valve) for hue_safety_valve.ini
            field using Cloudera Manager:[indexer]
enable_direct_upload=true


CDPD-42619: Unable to import a large CSV file from the local
            workstation
You may see an error message while importing a CSV file into Hue
            from your workstation, stating that you cannot import files of size more than 200
            KB.
Upload the file to S3 or ABFS and then import it into Hue
            using the Importer.


CDPD-43293: Unable to import Impala table using Importer
Creating Impala tables using the Hue Importer may fail.
If you have both Hive and Impala services installed on
            your cluster, then you can import the table using by selecting the Hive dialect from Tables > Sources. If only Impala service is installed on your cluster, then go to Cloudera Manager > Clusters > Hue > Configurations and add the following line in the Hue Service Advanced
              Configuration Snippet (Safety Valve) for hue_safety_valve.ini
            field:[beeswax]
max_number_of_sessions=1



Known issues before 7.2.16


Hue Importer is not supported in the Data Engineering
            template
When you create a Data Hub cluster using the Data Engineering
            template, the Importer application is not supported in Hue.Figure 1. Hue web UI showing Importer icon on the left assist panel






Unsupported features


CDPD-59595: Spark SQL does not work with all Livy servers that
            are configured for High Availability
SparkSQL support in Hue with Livy servers in HA mode is not
            supported. Hue does not automatically connect to one of the Livy servers. You must
            specify the Livy server in the Hue Advanced Configuration Snippet as
            follows:[desktop]
[spark]
livy_server_url=http(s)://[***LIVY-FOR-SPARK3-SERVER-HOST***]:[***LIVY-FOR-SPARK3-SERVER-PORT***] Moreover,
            you may see the following error in Hue when you submit a SparkSQL query:
              Expecting value: line 2 column 1 (char 1). This happens
            when the Livy server does not respond to the request from Hue.
Specify all different Livy servers in the
              livy_server_url property one at a time and use the one which does not
            cause the issue.

Importing and exporting Oozie workflows across clusters and between different CDH
            versions is not supported

You can export Oozie workflows, schedules, and bundles from Hue and import them only
              within the same cluster if the cluster is unchanged. You can migrate bundle and
              coordinator jobs with their workflows only if their arguments have not changed between
              the old and the new cluster. For example, hostnames, NameNode, Resource Manager names,
              YARN queue names, and all the other parameters defined in the
                workflow.xml and job.properties files.
Using the import-export feature to migrate data between clusters is not recommended.
              To migrate data between different versions of CDH, for example, from CDH 5 to CDP 7,
              you must take the dump of the Hue database on the old cluster, restore it on the new
              cluster, and set up the database in the new environment. Also, the authentication
              method on the old and the new cluster should be the same because the Oozie workflows
              are tied to a user ID, and the exact user ID needs to be present in the new
              environment so that when a user logs into Hue, they can access their respective
              workflows.
noteMigrating Oozie workflows from HDP clusters is not supported.


INSIGHT-3707: Query history displays "Result Expired"
            message
You see the "Result Expired" message under the Query History
            column on the Queries tab for queries which were run back to back.
            This is a known behaviour.
None.




Parent topic: Known Issues In Cloudera Runtime 7.2.17