Known Issues in Apache KafkaCloudera Docs
Known Issues in Apache Kafka
Learn about the known issues in Apache Kafka, the impact or changes to the
    functionality, and the workaround.
Known Issues

OPSAPS-59553: SMM's bootstrap server config should be updated based on Kafka's
            listeners

SMM does not show any metrics for Kafka or Kafka Connect when multiple listeners are
              set in Kafka.

Workaround: SMM cannot identify multiple listeners and still points to bootstrap
            server using the default broker port (9093 for SASL_SSL). You would have to override
            bootstrap server URL (hostname:port as set in the listeners for broker) in the following
              path:Cloudera Manager > SMM > Configuration > Streams Messaging Manager Rest Admin
              Server Advanced Configuration Snippet (Safety Valve) for
              streams-messaging-manager.yaml > Save Changes > Restart SMM.

The offsets.topic.replication.factor property
            must be less than or equal to the number of live brokers
The offsets.topic.replication.factor broker
            configuration is now enforced upon auto topic creation. Internal auto topic creation
            will fail with a GROUP_COORDINATOR_NOT_AVAILABLE error until the
            cluster size meets this replication factor requirement.
None


Requests fail when sending to a nonexistent topic with
              auto.create.topics.enable set to true
The first few produce requests fail when
            sending to a nonexistent topic with auto.create.topics.enable set to
            true.
Increase the number of retries in the producer
            configuration setting retries.


KAFKA-2561: Performance degradation when SSL Is enabled
In some configuration scenarios, significant performance
            degradation can occur when SSL is enabled. The impact varies depending on your CPU, JVM
            version, Kafka configuration, and message size. Consumers are typically more affected
            than producers.
Configure brokers and clients with
              ssl.secure.random.implementation = SHA1PRNG. It often reduces this
            degradation drastically, but its effect is CPU and JVM dependent.


OPSAPS-43236: Kafka garbage collection logs are written to the
            process directory
By default Kafka garbage collection logs are written to the
            agent process directory. Changing the default path for these log files is currently
            unsupported.
None


CDPD-45183: Kafka Connect active topics might be visible to
            unauthorised users
The Kafka Connect active topics endpoint
                (/connectors/[***CONNECTOR NAME***]/topics) and
            the Connect Cluster page on the SMM UI disregard the user permissions configured for the
            Kafka service in Ranger. As a result, all active topics of connectors might become
            visible to users who do not have permissions to view them. Note that user permission
            configured for Kafka Connect in Ranger are not affected by this issue and are correctly
            applied.
None.


RANGER-3809: Idempotent Kafka producer fails to initialize due
            to an authorization failure
 Kafka producers that have idempotence enabled require the
            Idempotent Write permission to be set on the cluster resource in Ranger. If permission
            is not given, the client fails to initialize and an error similar to the following is
            thrown:
            org.apache.kafka.common.KafkaException: Cannot execute transactional method because we are in an error state
    at org.apache.kafka.clients.producer.internals.TransactionManager.maybeFailWithError(TransactionManager.java:1125)
    at org.apache.kafka.clients.producer.internals.TransactionManager.maybeAddPartition(TransactionManager.java:442)
    at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1000)
    at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
    at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:800)
    .
    .
    .
Caused by: org.apache.kafka.common.errors.ClusterAuthorizationException: Cluster authorization failed.
Idempotence
            is enabled by default for clients in Kafka 3.0.1, 3.1.1, and any version after 3.1.1.
            This means that any client updated to 3.0.1, 3.1.1, or any version after 3.1.1 is
            affected by this issue.
This issue has two workarounds, do either of the following:
Explicitly disable idempotence for the producers. This can be done by setting
              enable.idempotence to false.
Update your policies in Ranger and ensure that producers have Idempotent Write
              permission on the cluster resource.



DBZ-4990: The Debezium Db2 Source connector does not support
            schema evolution
The Debezium Db2 Source connector does not support the evolution
            (updates) of schemas. In addition, schema change events are not emitted to the schema
            change topic if there is a change in the schema of a table that is in capture mode. For
            more information, see DBZ-4990.
None.



Unsupported Features



The following Kafka features are not supported in Cloudera Data Platform:
Only Java and .Net based clients are supported. Clients developed with C, C++,
                  Python, and other languages are currently not supported.
The Kafka default authorizer is not supported. This includes setting ACLs and
                  all related APIs, broker functionality, and command-line tools.
Kafka KRaft in this release of Cloudera Runtime is in technical preview and does
                  not support the following:
Deployments with multiple log directories. This includes deployments that
                      use JBOD for storage.
Delegation token based authentication.
Migrating an already running Kafka service from ZooKeeper to KRaft.
Atlas Integration.





Limitations



Collection of Partition Level Metrics May Cause Cloudera
              Managerâ€™s Performance to Degrade

If the Kafka service operates with a large number of partitions, collection of
                partition level metrics may cause Cloudera Manager's performance to degrade.
If you are observing performance degradation and your cluster is operating with a
                high number of partitions, you can choose to disable the collection of partition
                level metrics. important If you are using SMM to monitor Kafka or
                  Cruise Control for rebalancing Kafka partitions, be aware that both SMM and Cruise
                  Control rely on partition level metrics. If partition level metric collection is
                  disabled, SMM will not be able to display information about partitions. In
                  addition, Cruise Control will not operate properly. 
Complete the following steps to turn off the collection of partition level metrics:
Obtain the Kafka service name:
In Cloudera Manager, Select the Kafka service.
Select any available chart, and select Open in Chart Builder
                        from the configuration icon drop-down.
Find $SERVICENAME= near the top of the display.The
                          Kafka service name is the value of
                        $SERVICENAME.

Turn off the collection of partition level metrics:
Go to Hosts > Hosts
                            Configuration.
Find and configure the Cloudera Manager Agent Monitoring
                          Advanced Configuration Snippet (Safety Valve) configuration
                          property.Enter the following to turn off the collection of partition
                          level
                          metrics:[KAFKA_SERVICE_NAME]_feature_send_broker_topic_partition_entity_update_enabled=false
Replace
                            [KAFKA_SERVICE_NAME] with the service name of Kafka
                          obtained in step 1. The service name should always be in lower
                        case.
Click Save Changes.








Parent topic: Known Issues In Cloudera Runtime 7.2.17