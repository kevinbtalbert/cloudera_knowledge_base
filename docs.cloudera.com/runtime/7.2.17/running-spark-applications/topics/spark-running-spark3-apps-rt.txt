Running Apache Spark 3.3.2 applicationsCloudera Docs
Running Apache Spark 3.3.2 applications
 You can run Apache Spark 3 applications locally or distributed across a cluster,
    either by using an interactive shell or by submitting an application. Running Spark applications
    interactively is commonly performed during the data-exploration phase and for ad hoc analysis. 
noteSpark 3.3 is the first Spark version with the log4j2 dependency.
      Previous versions contained the log4j1 dependency. If you are using custom logging related
      changes, you must rewrite the original log4j properties files using log4j2 syntax such as XML,
      JSON, YAML, or properties format.
Unsupported connectors
This release does not support the following connectors:
SparkR
Oozie


Limitations of Spark in CDP
Limitations of Spark (in comparison to Apache Spark 3.3) in CDP are described below:
spark.sql.orc.compression.codec config doesn't accept
              zsdt value.
spark.sql.avro.compression.codec config doesn't accept
              zstandard value.
Specifying avroSchemaUrl is not supported in datasource options.


The Spark 3 job commands
With Spark 3, you use slightly different command names than with Spark 2, so that you can
        run both versions of Spark side-by-side without conflicts: 


spark3-submit instead of spark-submit. 



spark3-shell instead of spark-shell. 



pyspark3 instead of pyspark. 


 For development and test purposes, you can also configure each host so that invoking the
        Spark 2 command name runs the corresponding Spark 3 executable. 

Canary test for pyspark3 command
 The following example shows a simple pyspark3 session that refers to the
        SparkContext, calls the collect() function which runs a Spark 3 job, and
        writes data to HDFS. This sequence of operations helps to check if there are obvious
        configuration issues that prevent Spark 3 jobs from working at all. For the HDFS path for
        the output directory, substitute a path that exists on your own system. 
$ hdfs dfs -mkdir /user/jdoe/spark
$ pyspark3
...
SparkSession available as 'spark'.
>>> strings = ["one","two","three"]
>>> s2 = sc.parallelize(strings)
>>> s3 = s2.map(lambda word: word.upper())
>>> s3.collect()
['ONE', 'TWO', 'THREE']
>>> s3.saveAsTextFile('hdfs:///user/jdoe/spark/canary_test')
>>> quit()
$ hdfs dfs -ls /user/jdoe/spark
Found 1 items
drwxr-xr-x   - jdoe spark-users  0 2016-08-26 14:41 /user/jdoe/spark/canary_test
$ hdfs dfs -ls /user/jdoe/spark/canary_test
Found 3 items
-rw-r--r--   3 jdoe spark-users  0 2016-08-26 14:41 /user/jdoe/spark/canary_test/_SUCCESS
-rw-r--r--   3 jdoe spark-users  4 2016-08-26 14:41 /user/jdoe/spark/canary_test/part-00000
-rw-r--r--   3 jdoe spark-users 10 2016-08-26 14:41 /user/jdoe/spark/canary_test/part-00001
$ hdfs dfs -cat /user/jdoe/spark/canary_test/part-00000
ONE
$ hdfs dfs -cat /user/jdoe/spark/canary_test/part-00001
TWO
THREE

Fetching Spark 3 Maven Dependencies
 The Maven coordinates are a combination of groupId, artifactId and version. The groupId
        and artifactId are the same as for the upstream Apache Spark project. For example, for
          spark-core, groupId is org.apache.spark, and artifactId
        is spark-core_2.12, both the same as the upstream project. The version is
        different for the Cloudera packaging, it contains the upstream Spark version as well as the
        CDP version: [**artifactId***]-[***UPSTREAM SPARK
            VERSION***].[***CDP VERSION***]-[***CDP BUILD
            NUMBER***]. For example,
          spark-core_2.12-3.3.0.7.2.16.0-123.

Accessing the Spark 3 History Server
 The Spark 3 history server is available on port 18089, rather than port 18088 as with the
        Spark 2 history server. 


