Overview of Hadoop archivesCloudera Docs
Overview of Hadoop
      archives
Storing a large number of small files in HDFS leads to inefficient utilization of
      space – the namespace is overutilized while the disk space might be underutilized. Hadoop
      Archives (HAR) address this limitation by efficiently packing small files into large files
      without impacting the file access.
The Hadoop Distributed File System (HDFS) is designed to store and process large
                (terabytes) data sets. For example, a large production cluster may have 14 PB of
                disk space and store 60 million files.
However, storing a large
         number of small files in HDFS is inefficient. A file is generally considered to be "small"
         when its size is substantially less than the HDFS block size. Files and blocks are name
         objects in HDFS, meaning that they occupy namespace (space on the NameNode). The namespace
         capacity of the system is therefore limited by the physical memory of the NameNode.
When there are many small files stored in the system, these small files occupy a
                large portion of the namespace. As a consequence, the disk space is underutilized
                because of the namespace limitation. In one real-world example, a production cluster
                had 57 million files less than 256 MB in size, with each of these files taking up
                one block on the NameNode. These small files used up 95% of the namespace but
                occupied only 30% of the cluster disk space.
Hadoop Archives (HAR) can be used to address the namespace limitations associated
                with storing many small files. HAR packs a number of small files into large files so
                that the original files can be accessed transparently (without expanding the
                files).
HAR increases the scalability of the system by reducing the namespace usage and
                decreasing the operation load in the NameNode. This improvement is orthogonal to
                memory optimization in the NameNode and distributing namespace management across
                multiple NameNodes.
Hadoop Archive is also compatible with MapReduce — it allows parallel access to
                the original files by MapReduce jobs.

Parent topic: Optimizing NameNode disk space with Hadoop archives