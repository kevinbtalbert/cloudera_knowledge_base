Extracting, transforming, and loading data with Cloudera MorphlinesCloudera Docs
Extracting, transforming, and loading data with Cloudera Morphlines
Cloudera Morphlines is an open-source framework that reduces the time and skills
    required to build or change Search indexing applications. 
A morphline is a rich configuration file that simplifies defining an extraction,
      transformation, and loading (ETL) transformation chain. Use these chains to consume any kind
      of data from any data source, process the data, and load the results into Cloudera Search.
      Executing in a small, embeddable Java runtime system, morphlines can be used for near
      real-time applications as well as batch processing applications. The following diagram shows
      the process flow:



Morphlines can be seen as an evolution of Unix pipelines, where the data model is generalized
      to work with streams of generic records, including arbitrary binary payloads. Morphlines can
      be embedded into Hadoop components such as Search, MapReduce, Hive, and Sqoop.
The framework ships with a set of frequently used high-level transformation and I/O commands
      that can be combined in application-specific ways. The plug-in system allows you to add new
      transformations and I/O commands and integrates existing functionality and third-party
      systems.
This integration enables the following:
Rapid Hadoop ETL application prototyping
Complex stream and event processing in real time
Flexible log file analysis
Integration of multiple heterogeneous input schemas and file formats
Reuse of ETL logic building blocks across Search applications

The high-performance Cloudera runtime compiles a morphline, processing all commands for a
      morphline in the same thread and adding no artificial overhead. For high scalability, you can
      deploy many morphline instances on a cluster in many MapReduce tasks.
The following components run morphlines:

MapReduceIndexerTool
Lily HBase Indexer

Cloudera also provides a corresponding Cloudera Search Tutorial.
Data Morphlines support
Morphlines manipulate continuous or arbitrarily large streams of
        records. The data model can be described as follows: A record is a set
        of named fields where each field has an ordered list of one or more
        values. A value can be any Java Object. That is, a record is essentially
        a hash table where each hash table entry contains a String key and a
        list of Java Objects as values. (The implementation uses Guavaâ€™s
          ArrayListMultimap, which is a
          ListMultimap). Note that a field can have multiple
        values and any two records need not use common field names. This
        flexible data model corresponds exactly to the characteristics of the
        Solr/Lucene data model, meaning a record can be seen as a
          SolrInputDocument. A field with zero values is
        removed from the record - fields with zero values effectively do not
        exist.
Not only structured data, but also arbitrary binary data can be passed
        into and processed by a morphline. By convention, a record can contain
        an optional field named _attachment_body, which can be
        a Java java.io.InputStream or Java
          byte[]. Optionally, such binary input data can be
        characterized in more detail by setting the fields named
          _attachment_mimetype (such as
          application/pdf) and
          _attachment_charset (such as UTF-8)
        and _attachment_name (such as
        cars.pdf), which assists in detecting and parsing the
        data type.
This generic data model is useful to support a wide range of
        applications.
importantCloudera Search does not support
    contrib modules, such as DataImportHandler. Spark, MapReduce and Lily
    HBase indexers are not contrib modules but part of the Cloudera Search product itself,
    therefore they are supported.

How Morphlines act on data
A command transforms a record into zero or more records. Commands can access all record
        fields. For example, commands can parse fields, set fields, remove fields, rename fields,
        find and replace values, split a field into multiple fields, split a field into multiple
        values, or drop records. Often, regular expression based pattern matching is used as part of
        the process of acting on fields. The output records of a command are passed to the next
        command in the chain. A command has a Boolean return code, indicating success or
        failure.
For example, consider the case of a multi-line input record: A command could take this
        multi-line input record and divide the single record into multiple output records, one for
        each line. This output could then later be further divided using regular expression
        commands, splitting each single line record out into multiple fields in application specific
        ways.
A command can extract, clean, transform, join, integrate, enrich and decorate records in
        many other ways. For example, a command can join records with external data sources such as
        relational databases, key-value stores, local files or IP Geo lookup tables. It can also
        perform tasks such as DNS resolution, expand shortened URLs, fetch linked metadata from
        social networks, perform sentiment analysis and annotate the record accordingly,
        continuously maintain statistics for analytics over sliding windows, compute exact or
        approximate distinct values and quantiles.
A command can also consume records and pass them to external systems. For example, a
        command can load records into Solr or write them to a MapReduce Reducer or pass them into an
        online dashboard. The following diagram illustrates some pathways along which data might
        flow with the help of morphlines:




Morphline characteristics
A command can contain nested commands. Thus, a morphline is a tree of commands, akin to a
        push-based data flow engine or operator tree in DBMS query execution engines.
A morphline has no notion of persistence, durability, distributed computing, or host
        failover. A morphline is basically just a chain of in-memory transformations in the current
        thread. There is no need for a morphline to manage multiple processes, hosts, or threads
        because this is already addressed by host systems such as MapReduce or Storm. However, a
        morphline does support passing notifications on the control plane to command subtrees. Such
        notifications include BEGIN_TRANSACTION, COMMIT_TRANSACTION, ROLLBACK_TRANSACTION,
        SHUTDOWN.
The morphline configuration file is implemented using the HOCON format (Human-Optimized
        Config Object Notation). HOCON is basically JSON slightly adjusted for configuration file
        use cases. HOCON syntax is defined at HOCON github page and is also used by Akka and Play.

How Morphlines are implemented
Cloudera Search includes several maven modules that contain morphline commands for
        integration with Apache Solr including SolrCloud, flexible log file analysis, single-line
        records, multi-line records, CSV files, regular expression based pattern matching and
        extraction, operations on record fields for assignment and comparison, operations on record
        fields with list and set semantics, if-then-else conditionals, string and timestamp
        conversions, scripting support for dynamic Java code, a small rules engine, logging, metrics
        and counters, integration with Avro, integration with Apache Tika parsers, integration with
        Apache Hadoop Sequence Files, auto-detection of MIME types from binary data using Apache
        Tika, and decompression and unpacking of arbitrarily nested container file formats, among
        others. 


